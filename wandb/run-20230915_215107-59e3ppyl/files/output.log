加载数据...
['a stirring , funny and finally transporting re-imagining of beauty and the beast and 1930s horror films', 'apparently reassembled from the cutting-room floor of any given daytime soap .', "they presume their audience wo n't sit still for a sociology lesson , however entertainingly presented , so they trot out the conventional science-fiction elements of bug-eyed monsters and futuristic women in skimpy clothes .", 'this is a visually stunning rumination on love , memory , history and the war between art and commerce .', "jonathan parker 's bartleby should have been the be-all-end-all of the modern-office anomie films ."]
[1, 0, 0, 1, 1]
Time usage: 0:00:13
Some weights of the model checkpoint at /home/huyiwen/pretrained/bert-base-uncased-SST-2 were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
BERT_Model(
  (bert): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0-11): 12 x BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (fc): Linear(in_features=768, out_features=192, bias=True)
  (fc1): Linear(in_features=192, out_features=2, bias=True)
)
cuda
biLSTM(
  (Embedding): Embedding(30522, 300)
  (lstm): LSTM(300, 300, batch_first=True, bidirectional=True)
  (fc1): LinearDecomMPO(
    mpo=True, in_features=600, out_features=192, bias=True
    (tensor_set): ParameterList(
        (0): Parameter containing: [torch.float32 of size 1x10x6x60 (cuda:0)]
        (1): Parameter containing: [torch.float32 of size 60x2x2x240 (cuda:0)]
        (2): Parameter containing: [torch.float32 of size 240x1x1x240 (cuda:0)]
        (3): Parameter containing: [torch.float32 of size 240x3x2x80 (cuda:0)]
        (4): Parameter containing: [torch.float32 of size 80x10x8x1 (cuda:0)]
    )
  )
  (fc2): LinearDecomMPO(
    mpo=True, in_features=192, out_features=2, bias=True
    (tensor_set): ParameterList(
        (0): Parameter containing: [torch.float32 of size 1x6x2x12 (cuda:0)]
        (1): Parameter containing: [torch.float32 of size 12x2x1x16 (cuda:0)]
        (2): Parameter containing: [torch.float32 of size 16x1x1x16 (cuda:0)]
        (3): Parameter containing: [torch.float32 of size 16x2x1x8 (cuda:0)]
        (4): Parameter containing: [torch.float32 of size 8x8x1x1 (cuda:0)]
    )
  )
)
10,843,098 total parameters.
Epoch [1/30]
base_loss tensor(25.5383, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(3900.4453, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(22.7486, device='cuda:0') distillation_loss tensor(10052.1699, device='cuda:0')
base_loss tensor(20.5865, device='cuda:0') distillation_loss tensor(6317.2373, device='cuda:0')
base_loss tensor(11.8991, device='cuda:0') distillation_loss tensor(8880.0527, device='cuda:0')
base_loss tensor(17.9499, device='cuda:0') distillation_loss tensor(9541.6719, device='cuda:0')
base_loss tensor(15.8651, device='cuda:0') distillation_loss tensor(10383.8936, device='cuda:0')
base_loss tensor(18.3094, device='cuda:0') distillation_loss tensor(7077.4614, device='cuda:0')
base_loss tensor(26.0766, device='cuda:0') distillation_loss tensor(6553.4482, device='cuda:0')
base_loss tensor(22.5552, device='cuda:0') distillation_loss tensor(9951.3457, device='cuda:0')
base_loss tensor(19.5265, device='cuda:0') distillation_loss tensor(8467.0537, device='cuda:0')
base_loss tensor(18.4960, device='cuda:0') distillation_loss tensor(6250.1987, device='cuda:0')
base_loss tensor(14.5660, device='cuda:0') distillation_loss tensor(7326.9058, device='cuda:0')
base_loss tensor(22.8030, device='cuda:0') distillation_loss tensor(9192.2832, device='cuda:0')
base_loss tensor(16.3946, device='cuda:0') distillation_loss tensor(6163.0308, device='cuda:0')
base_loss tensor(23.3161, device='cuda:0') distillation_loss tensor(8563.0410, device='cuda:0')
base_loss tensor(13.3374, device='cuda:0') distillation_loss tensor(5617.4512, device='cuda:0')
base_loss tensor(17.8360, device='cuda:0') distillation_loss tensor(10317.3887, device='cuda:0')
base_loss tensor(19.5882, device='cuda:0') distillation_loss tensor(7106.1982, device='cuda:0')
base_loss tensor(16.7167, device='cuda:0') distillation_loss tensor(10176.8779, device='cuda:0')
base_loss tensor(23.5336, device='cuda:0') distillation_loss tensor(6514.9746, device='cuda:0')
base_loss tensor(18.8915, device='cuda:0') distillation_loss tensor(8049.5645, device='cuda:0')
base_loss tensor(21.0498, device='cuda:0') distillation_loss tensor(6804.4756, device='cuda:0')
base_loss tensor(12.4502, device='cuda:0') distillation_loss tensor(6556.1221, device='cuda:0')
base_loss tensor(12.9869, device='cuda:0') distillation_loss tensor(6314.5586, device='cuda:0')
base_loss tensor(17.3656, device='cuda:0') distillation_loss tensor(7536.7935, device='cuda:0')
base_loss tensor(19.7131, device='cuda:0') distillation_loss tensor(5669.5728, device='cuda:0')
base_loss tensor(22.5154, device='cuda:0') distillation_loss tensor(7473.5469, device='cuda:0')
base_loss tensor(16.7653, device='cuda:0') distillation_loss tensor(6454.2974, device='cuda:0')
base_loss tensor(25.2890, device='cuda:0') distillation_loss tensor(9819.2754, device='cuda:0')
base_loss tensor(27.2110, device='cuda:0') distillation_loss tensor(9186.3691, device='cuda:0')
Iter:      0,  Train Loss: 7.8e+03,  Train Acc: 37.50%,  Val Loss: 1.6e+04,  Val Acc: 50.19%,  Time: 0:00:06 *,  LR: [0.0049863047384206835]
base_loss tensor(21.4905, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(7354.1279, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(367.6223, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(395862.6250, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(25.9778, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(25763.4492, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(45.8530, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(8181.4502, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(24.4929, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(1491.3138, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(12.0684, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(886.8766, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(10.0736, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(1470.4961, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(8.5310, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(971.7329, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(3.2380, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(383.0669, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(18.6537, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(496.4966, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(6.3763, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(153.2243, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(5.6001, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(135.5474, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(6.6457, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(112.9346, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(5.2901, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(118.8668, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(5.6347, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(72.0020, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(6.4332, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(115.2993, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(4.5384, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(66.6113, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(4.2480, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(120.8516, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(3.2472, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(63.8522, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(2.3567, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(61.7222, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(2.2217, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(44.4436, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(2.1184, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(29.0403, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(2.4180, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(31.0921, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(1.7668, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(30.6821, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(2.2642, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(44.4806, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(1.7333, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(26.6872, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(1.1336, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(23.5346, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(1.4697, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(26.5807, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(2.2426, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(36.2960, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(1.5916, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(28.8704, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(1.8117, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(32.1417, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(2.0316, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(25.9194, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(2.1365, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(31.2616, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(2.0440, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(24.4246, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(2.1200, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(27.7624, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(1.6567, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(26.6964, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(1.5108, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(24.4709, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(1.9487, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(29.7970, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(1.5557, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(23.8380, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.9780, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(29.3368, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(1.4542, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(15.9504, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(1.0960, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(16.5085, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(1.5332, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(22.5170, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(1.2410, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(14.6290, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(1.2182, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(14.6247, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(1.1056, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(15.4278, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.7843, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(15.8452, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.7120, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(13.0344, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(1.0468, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(16.0707, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8296, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.1688, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8135, device='cuda:0') distillation_loss tensor(11.9290, device='cuda:0')
base_loss tensor(0.7056, device='cuda:0') distillation_loss tensor(12.6894, device='cuda:0')
base_loss tensor(0.7646, device='cuda:0') distillation_loss tensor(13.4876, device='cuda:0')
base_loss tensor(0.6796, device='cuda:0') distillation_loss tensor(12.6898, device='cuda:0')
base_loss tensor(0.7281, device='cuda:0') distillation_loss tensor(12.0868, device='cuda:0')
base_loss tensor(0.7538, device='cuda:0') distillation_loss tensor(11.5109, device='cuda:0')
base_loss tensor(0.7058, device='cuda:0') distillation_loss tensor(10.7082, device='cuda:0')
base_loss tensor(0.8132, device='cuda:0') distillation_loss tensor(12.3896, device='cuda:0')
base_loss tensor(0.8803, device='cuda:0') distillation_loss tensor(12.7433, device='cuda:0')
base_loss tensor(0.7443, device='cuda:0') distillation_loss tensor(11.7522, device='cuda:0')
base_loss tensor(0.7922, device='cuda:0') distillation_loss tensor(11.4459, device='cuda:0')
base_loss tensor(0.8016, device='cuda:0') distillation_loss tensor(12.1056, device='cuda:0')
base_loss tensor(0.7746, device='cuda:0') distillation_loss tensor(13.6064, device='cuda:0')
base_loss tensor(0.8394, device='cuda:0') distillation_loss tensor(12.0778, device='cuda:0')
base_loss tensor(0.7768, device='cuda:0') distillation_loss tensor(11.6658, device='cuda:0')
base_loss tensor(0.8128, device='cuda:0') distillation_loss tensor(11.9272, device='cuda:0')
base_loss tensor(0.6978, device='cuda:0') distillation_loss tensor(11.5472, device='cuda:0')
base_loss tensor(0.6426, device='cuda:0') distillation_loss tensor(12.2053, device='cuda:0')
base_loss tensor(0.7469, device='cuda:0') distillation_loss tensor(11.9113, device='cuda:0')
base_loss tensor(0.7330, device='cuda:0') distillation_loss tensor(11.3713, device='cuda:0')
base_loss tensor(0.7320, device='cuda:0') distillation_loss tensor(13.0057, device='cuda:0')
base_loss tensor(0.7176, device='cuda:0') distillation_loss tensor(12.1355, device='cuda:0')
base_loss tensor(0.7424, device='cuda:0') distillation_loss tensor(12.6996, device='cuda:0')
base_loss tensor(0.6966, device='cuda:0') distillation_loss tensor(12.0428, device='cuda:0')
base_loss tensor(0.7230, device='cuda:0') distillation_loss tensor(11.3613, device='cuda:0')
base_loss tensor(0.8791, device='cuda:0') distillation_loss tensor(13.0016, device='cuda:0')
base_loss tensor(0.7461, device='cuda:0') distillation_loss tensor(11.2834, device='cuda:0')
base_loss tensor(0.7398, device='cuda:0') distillation_loss tensor(11.6147, device='cuda:0')
base_loss tensor(0.7255, device='cuda:0') distillation_loss tensor(10.6357, device='cuda:0')
Iter:     50,  Train Loss: 2.5e+01,  Train Acc: 50.00%,  Val Loss: 2.5e+01,  Val Acc: 50.69%,  Time: 0:00:12 *,  LR: [0.003969463130731265]
base_loss tensor(0.6446, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(14.0681, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.7344, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.8901, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.6147, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.8801, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.6970, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.3461, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.7881, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.8431, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.7461, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.5446, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.7452, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(13.6837, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.7223, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.3261, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8192, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.3046, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.7116, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.9271, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.6858, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.7824, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.7660, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.9406, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8221, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(13.0791, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.6227, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.7214, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.7906, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.7550, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.7819, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.7443, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.7688, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.3179, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.7423, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(11.7708, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.7171, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(13.3119, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.7724, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.3802, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8052, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.5068, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8914, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.5572, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.7775, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.2121, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8227, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.4279, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.9419, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(13.0313, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.7950, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.7320, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8365, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.8319, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.7188, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(13.0738, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.7326, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.8523, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8996, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.2084, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.7986, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.6580, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.9025, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(11.1380, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.9228, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.8433, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.9353, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.3986, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8367, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.9840, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.7943, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.7080, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8177, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.7924, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.7626, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.2385, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.7634, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(13.0012, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8326, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.2581, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.7333, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.2735, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8985, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(11.7377, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.7554, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.7149, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8810, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(13.5680, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8114, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.5812, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.7570, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(11.6972, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.6513, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.9964, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8360, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.0771, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.9464, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.5325, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8951, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(11.3395, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.9015, device='cuda:0') distillation_loss tensor(12.0628, device='cuda:0')
base_loss tensor(0.8352, device='cuda:0') distillation_loss tensor(11.2438, device='cuda:0')
base_loss tensor(0.9563, device='cuda:0') distillation_loss tensor(11.9159, device='cuda:0')
base_loss tensor(0.9135, device='cuda:0') distillation_loss tensor(11.3422, device='cuda:0')
base_loss tensor(0.6818, device='cuda:0') distillation_loss tensor(11.3109, device='cuda:0')
base_loss tensor(0.8606, device='cuda:0') distillation_loss tensor(10.9212, device='cuda:0')
base_loss tensor(0.8875, device='cuda:0') distillation_loss tensor(10.6275, device='cuda:0')
base_loss tensor(0.8143, device='cuda:0') distillation_loss tensor(11.6013, device='cuda:0')
base_loss tensor(0.9189, device='cuda:0') distillation_loss tensor(12.1683, device='cuda:0')
base_loss tensor(0.9945, device='cuda:0') distillation_loss tensor(11.2999, device='cuda:0')
base_loss tensor(0.8645, device='cuda:0') distillation_loss tensor(11.1470, device='cuda:0')
base_loss tensor(0.6610, device='cuda:0') distillation_loss tensor(11.0710, device='cuda:0')
base_loss tensor(0.6964, device='cuda:0') distillation_loss tensor(12.5594, device='cuda:0')
base_loss tensor(0.7796, device='cuda:0') distillation_loss tensor(11.0439, device='cuda:0')
base_loss tensor(0.9880, device='cuda:0') distillation_loss tensor(11.5288, device='cuda:0')
base_loss tensor(0.7622, device='cuda:0') distillation_loss tensor(11.3453, device='cuda:0')
base_loss tensor(0.8933, device='cuda:0') distillation_loss tensor(11.4267, device='cuda:0')
base_loss tensor(0.8611, device='cuda:0') distillation_loss tensor(11.8961, device='cuda:0')
base_loss tensor(0.8372, device='cuda:0') distillation_loss tensor(10.7062, device='cuda:0')
base_loss tensor(0.9439, device='cuda:0') distillation_loss tensor(11.3734, device='cuda:0')
base_loss tensor(0.9070, device='cuda:0') distillation_loss tensor(10.3799, device='cuda:0')
base_loss tensor(0.8177, device='cuda:0') distillation_loss tensor(11.5910, device='cuda:0')
base_loss tensor(0.8094, device='cuda:0') distillation_loss tensor(11.5305, device='cuda:0')
base_loss tensor(0.7798, device='cuda:0') distillation_loss tensor(11.1194, device='cuda:0')
base_loss tensor(0.7939, device='cuda:0') distillation_loss tensor(11.2248, device='cuda:0')
base_loss tensor(0.8476, device='cuda:0') distillation_loss tensor(11.7686, device='cuda:0')
base_loss tensor(0.8172, device='cuda:0') distillation_loss tensor(11.4307, device='cuda:0')
base_loss tensor(0.7695, device='cuda:0') distillation_loss tensor(11.0784, device='cuda:0')
base_loss tensor(0.8369, device='cuda:0') distillation_loss tensor(10.9037, device='cuda:0')
Iter:    100,  Train Loss: 2.4e+01,  Train Acc: 46.88%,  Val Loss: 2.4e+01,  Val Acc: 50.03%,  Time: 0:00:17 *,  LR: [0.001483158392310497]
base_loss tensor(0.7777, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.4886, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.6365, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.5314, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8699, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(11.3618, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8991, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(13.5955, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8273, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.0722, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8309, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(13.2992, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.6778, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.2215, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch [2/30]
base_loss tensor(0.7938, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.6913, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8431, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.4994, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8586, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.9004, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.7715, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.7239, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8949, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(13.1791, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.7580, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.3399, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8060, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.3699, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.7988, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.9155, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8419, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.1433, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.7126, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.3871, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.7586, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(11.6362, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8249, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(11.7368, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.9015, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.4011, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8799, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(11.8730, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(1.0884, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.4182, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.9170, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(13.7875, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.9496, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.9558, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8159, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.2496, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.6722, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.3231, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8144, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.8500, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8983, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.6219, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.7359, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.6192, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8473, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.7083, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(1.0006, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.6621, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.9057, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.6565, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.9473, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(11.7150, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8274, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.5740, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.9115, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(11.9792, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss
base_loss tensor(0.7453, device='cuda:0') distillation_loss tensor(10.1156, device='cuda:0')or(12.5258, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.7998, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.2297, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.9096, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.8726, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8349, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.5211, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8924, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.6152, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.7768, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(11.9791, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8036, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.0841, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8359, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.5093, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8318, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.4425, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.7682, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.2075, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8462, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(11.7820, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8363, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.5867, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.7947, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.4016, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8634, device='cuda:0') distillation_loss tensor(11.9622, device='cuda:0')
base_loss tensor(0.8578, device='cuda:0') distillation_loss tensor(10.9915, device='cuda:0')
base_loss tensor(0.9822, device='cuda:0') distillation_loss tensor(11.8438, device='cuda:0')
base_loss tensor(0.8229, device='cuda:0') distillation_loss tensor(10.7243, device='cuda:0')
base_loss tensor(0.8031, device='cuda:0') distillation_loss tensor(10.9422, device='cuda:0')
base_loss tensor(0.8673, device='cuda:0') distillation_loss tensor(11.0296, device='cuda:0')
base_loss tensor(0.8252, device='cuda:0') distillation_loss tensor(10.3934, device='cuda:0')
base_loss tensor(0.8197, device='cuda:0') distillation_loss tensor(12.0615, device='cuda:0')
base_loss tensor(0.7956, device='cuda:0') distillation_loss tensor(11.8692, device='cuda:0')
base_loss tensor(0.9124, device='cuda:0') distillation_loss tensor(11.0855, device='cuda:0')
base_loss tensor(0.8925, device='cuda:0') distillation_loss tensor(11.0550, device='cuda:0')
base_loss tensor(0.9848, device='cuda:0') distillation_loss tensor(11.4149, device='cuda:0')
base_loss tensor(0.8309, device='cuda:0') distillation_loss tensor(11.7845, device='cuda:0')
base_loss tensor(0.7923, device='cuda:0') distillation_loss tensor(10.9762, device='cuda:0')
base_loss tensor(0.8208, device='cuda:0') distillation_loss tensor(11.6159, device='cuda:0')
base_loss tensor(0.9568, device='cuda:0') distillation_loss tensor(11.6811, device='cuda:0')
base_loss tensor(0.7863, device='cuda:0') distillation_loss tensor(11.3254, device='cuda:0')
base_loss tensor(0.7715, device='cuda:0') distillation_loss tensor(11.5782, device='cuda:0')
base_loss tensor(0.7453, device='cuda:0') distillation_loss tensor(10.1156, device='cuda:0')or(12.5258, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8559, device='cuda:0') distillation_loss tensor(10.6220, device='cuda:0')
base_loss tensor(0.8111, device='cuda:0') distillation_loss tensor(10.5102, device='cuda:0')
base_loss tensor(0.7920, device='cuda:0') distillation_loss tensor(11.8132, device='cuda:0')
base_loss tensor(0.8191, device='cuda:0') distillation_loss tensor(11.7870, device='cuda:0')
base_loss tensor(0.9235, device='cuda:0') distillation_loss tensor(11.2826, device='cuda:0')
base_loss tensor(0.8836, device='cuda:0') distillation_loss tensor(11.6618, device='cuda:0')
base_loss tensor(0.8889, device='cuda:0') distillation_loss tensor(11.8297, device='cuda:0')
base_loss tensor(0.7761, device='cuda:0') distillation_loss tensor(11.5741, device='cuda:0')
base_loss tensor(0.9304, device='cuda:0') distillation_loss tensor(11.3874, device='cuda:0')
base_loss tensor(0.8668, device='cuda:0') distillation_loss tensor(11.2238, device='cuda:0')
Iter:    150,  Train Loss: 2.6e+01,  Train Acc: 57.81%,  Val Loss: 2.3e+01,  Val Acc: 49.86%,  Time: 0:00:24 *,  LR: [1.3695261579316776e-05]
base_loss tensor(0.7132, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(13.1532, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.7712, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.3992, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8676, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.6408, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.7767, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.6525, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.7816, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.0869, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8433, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.4822, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8138, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.3343, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.9161, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.2822, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.7569, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.0494, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8328, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.4936, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8708, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(11.8396, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.7508, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(11.9349, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8651, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.5707, device='cuda:0', grad_fn=<MseLossBackward0>)
base_loss tensor(0.8698, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(12.4142, device='cuda:0', grad_fn=<MseLossBackward0>)
Traceback (most recent call last):
  File "/home/huyiwen/CV/bilstm/distill.py", line 72, in <module>
    student_train(T_model, S_model, cfg, train_loader, test_loader)
  File "/home/huyiwen/CV/bilstm/student.py", line 114, in student_train
    label = label.to(config.device)
  File "/home/huyiwen/miniconda3/envs/kd/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/huyiwen/miniconda3/envs/kd/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/huyiwen/CV/bilstm/models/lstm_mpo.py", line 192, in forward
    lstm_out, hidden = self.lstm(x, hidden)
  File "/home/huyiwen/miniconda3/envs/kd/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/huyiwen/miniconda3/envs/kd/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/huyiwen/miniconda3/envs/kd/lib/python3.10/site-packages/torch/nn/modules/rnn.py", line 879, in forward
    result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
KeyboardInterrupt