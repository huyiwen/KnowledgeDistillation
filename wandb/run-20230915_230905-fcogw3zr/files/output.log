加载数据...
['a stirring , funny and finally transporting re-imagining of beauty and the beast and 1930s horror films', 'apparently reassembled from the cutting-room floor of any given daytime soap .', "they presume their audience wo n't sit still for a sociology lesson , however entertainingly presented , so they trot out the conventional science-fiction elements of bug-eyed monsters and futuristic women in skimpy clothes .", 'this is a visually stunning rumination on love , memory , history and the war between art and commerce .', "jonathan parker 's bartleby should have been the be-all-end-all of the modern-office anomie films ."]
[1, 0, 0, 1, 1]
Time usage: 0:00:14
Some weights of the model checkpoint at /home/huyiwen/pretrained/bert-base-uncased-SST-2 were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
BERT_Model(
  (bert): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0-11): 12 x BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (fc): Linear(in_features=768, out_features=192, bias=True)
  (fc1): Linear(in_features=192, out_features=2, bias=True)
)
cuda
biLSTM(
  (Embedding): Embedding(30522, 300)
  (lstm): LSTM(300, 300, batch_first=True, bidirectional=True)
  (fc1): Linear(in_features=600, out_features=192, bias=True)
  (fc2): Linear(in_features=192, out_features=2, bias=True)
)
10,717,178 total parameters.
Epoch [1/30]
Iter:      0,  Train Loss:   1.2,  Train Acc: 51.56%,  Val Loss:   1.2,  Val Acc: 49.92%,  Time: 0:00:03 *,  LR: 0.0049863047384206835
Iter:     50,  Train Loss:   1.2,  Train Acc: 48.44%,  Val Loss:   1.2,  Val Acc: 53.27%,  Time: 0:00:06 ,  LR: 0.003969463130731265
Iter:    100,  Train Loss:   1.1,  Train Acc: 56.25%,  Val Loss:   1.2,  Val Acc: 55.46%,  Time: 0:00:09 *,  LR: 0.001483158392310497
Epoch [2/30]
Iter:    150,  Train Loss:   1.2,  Train Acc: 71.88%,  Val Loss:   1.2,  Val Acc: 57.66%,  Time: 0:00:12 *,  LR: 1.3695261579316776e-05
Iter:    200,  Train Loss:   1.2,  Train Acc: 54.69%,  Val Loss:   1.2,  Val Acc: 52.44%,  Time: 0:00:14 ,  LR: 0.0010305368692688577
Epoch [3/30]
Iter:    250,  Train Loss:   1.2,  Train Acc: 67.19%,  Val Loss:   1.2,  Val Acc: 62.05%,  Time: 0:00:17 ,  LR: 0.0035168416076895672
Iter:    300,  Train Loss:   1.2,  Train Acc: 57.81%,  Val Loss:   1.2,  Val Acc: 61.89%,  Time: 0:00:19 ,  LR: 0.00498630473842109
Epoch [4/30]
Iter:    350,  Train Loss:   1.2,  Train Acc: 53.12%,  Val Loss:   1.2,  Val Acc: 52.61%,  Time: 0:00:22 ,  LR: 0.003969463130731505
Iter:    400,  Train Loss:   1.2,  Train Acc: 59.38%,  Val Loss:   1.2,  Val Acc: 54.81%,  Time: 0:00:24 ,  LR: 0.0014831583923104268
Epoch [5/30]
Iter:    450,  Train Loss:   1.2,  Train Acc: 68.75%,  Val Loss:   1.2,  Val Acc: 56.34%,  Time: 0:00:27 *,  LR: 1.3695261579316776e-05
Iter:    500,  Train Loss:   1.2,  Train Acc: 57.81%,  Val Loss:   1.2,  Val Acc: 64.14%,  Time: 0:00:29 ,  LR: 0.001030536869268783
Epoch [6/30]
Iter:    550,  Train Loss:   1.1,  Train Acc: 67.19%,  Val Loss:   1.2,  Val Acc: 57.61%,  Time: 0:00:31 ,  LR: 0.003516841607689862
Iter:    600,  Train Loss:   1.2,  Train Acc: 78.12%,  Val Loss:   1.2,  Val Acc: 65.18%,  Time: 0:00:33 ,  LR: 0.004986304738421189
Iter:    650,  Train Loss:   1.2,  Train Acc: 67.19%,  Val Loss:   1.2,  Val Acc: 50.08%,  Time: 0:00:35 ,  LR: 0.003969463130731101
Epoch [7/30]
Iter:    700,  Train Loss:   1.2,  Train Acc: 64.06%,  Val Loss:   1.2,  Val Acc: 68.37%,  Time: 0:00:39 *,  LR: 0.0014831583923106796
Iter:    750,  Train Loss:   1.2,  Train Acc: 65.62%,  Val Loss:   1.2,  Val Acc: 67.60%,  Time: 0:00:41 ,  LR: 1.3695261579316776e-05
Epoch [8/30]
Iter:    800,  Train Loss:   1.1,  Train Acc: 71.88%,  Val Loss:   1.2,  Val Acc: 67.87%,  Time: 0:00:43 ,  LR: 0.0010305368692690847
Iter:    850,  Train Loss:   1.1,  Train Acc: 79.69%,  Val Loss:   1.2,  Val Acc: 68.81%,  Time: 0:00:45 ,  LR: 0.0035168416076899185
Epoch [9/30]
Iter:    900,  Train Loss:   1.2,  Train Acc: 75.00%,  Val Loss:   1.1,  Val Acc: 69.80%,  Time: 0:00:48 *,  LR: 0.004986304738420682
Iter:    950,  Train Loss:   1.1,  Train Acc: 78.12%,  Val Loss:   1.1,  Val Acc: 71.22%,  Time: 0:00:51 *,  LR: 0.003969463130730603
Epoch [10/30]
Iter:   1000,  Train Loss:   1.1,  Train Acc: 75.00%,  Val Loss:   1.1,  Val Acc: 70.79%,  Time: 0:00:53 ,  LR: 0.0014831583923105131
Iter:   1050,  Train Loss:   1.1,  Train Acc: 82.81%,  Val Loss:   1.1,  Val Acc: 72.10%,  Time: 0:00:57 *,  LR: 1.3695261579316776e-05
Epoch [11/30]
Iter:   1100,  Train Loss:   1.1,  Train Acc: 87.50%,  Val Loss:   1.1,  Val Acc: 72.76%,  Time: 0:00:59 ,  LR: 0.0010305368692689761
Iter:   1150,  Train Loss:   1.1,  Train Acc: 82.81%,  Val Loss:   1.1,  Val Acc: 71.72%,  Time: 0:01:02 ,  LR: 0.003516841607689587
Epoch [12/30]
Iter:   1200,  Train Loss:   1.1,  Train Acc: 89.06%,  Val Loss:   1.2,  Val Acc: 72.98%,  Time: 0:01:04 ,  LR: 0.004986304738421493
Iter:   1250,  Train Loss:   1.1,  Train Acc: 81.25%,  Val Loss:   1.1,  Val Acc: 73.70%,  Time: 0:01:06 ,  LR: 0.00396946313073123
Iter:   1300,  Train Loss:   1.2,  Train Acc: 85.94%,  Val Loss:   1.1,  Val Acc: 71.88%,  Time: 0:01:09 ,  LR: 0.001483158392310376
Epoch [13/30]
Iter:   1350,  Train Loss:   1.1,  Train Acc: 87.50%,  Val Loss:   1.1,  Val Acc: 73.70%,  Time: 0:01:11 ,  LR: 1.3695261579316776e-05
Iter:   1400,  Train Loss:   1.1,  Train Acc: 85.94%,  Val Loss:   1.1,  Val Acc: 74.68%,  Time: 0:01:14 ,  LR: 0.0010305368692691602
Epoch [14/30]
Iter:   1450,  Train Loss:   1.2,  Train Acc: 84.38%,  Val Loss:   1.1,  Val Acc: 73.09%,  Time: 0:01:16 ,  LR: 0.003516841607690171
Iter:   1500,  Train Loss:   1.1,  Train Acc: 84.38%,  Val Loss:   1.1,  Val Acc: 73.70%,  Time: 0:01:19 ,  LR: 0.004986304738420884
Epoch [15/30]
Iter:   1550,  Train Loss:   1.1,  Train Acc: 87.50%,  Val Loss:   1.1,  Val Acc: 74.63%,  Time: 0:01:21 ,  LR: 0.003969463130730895
Iter:   1600,  Train Loss:   1.1,  Train Acc: 85.94%,  Val Loss:   1.1,  Val Acc: 73.09%,  Time: 0:01:23 ,  LR: 0.0014831583923109566
Epoch [16/30]
Iter:   1650,  Train Loss:   1.1,  Train Acc: 92.19%,  Val Loss:   1.1,  Val Acc: 75.62%,  Time: 0:01:25 ,  LR: 1.3695261579316776e-05
Iter:   1700,  Train Loss:   1.2,  Train Acc: 81.25%,  Val Loss:   1.1,  Val Acc: 74.14%,  Time: 0:01:27 ,  LR: 0.0010305368692690444
Epoch [17/30]
Iter:   1750,  Train Loss:   1.2,  Train Acc: 92.19%,  Val Loss:   1.1,  Val Acc: 75.40%,  Time: 0:01:30 ,  LR: 0.0035168416076916554
Iter:   1800,  Train Loss:   1.1,  Train Acc: 84.38%,  Val Loss:   1.1,  Val Acc: 73.92%,  Time: 0:01:32 ,  LR: 0.0049863047384203826
Iter:   1850,  Train Loss:   1.1,  Train Acc: 92.19%,  Val Loss:   1.1,  Val Acc: 75.62%,  Time: 0:01:34 *,  LR: 0.003969463130730366
Epoch [18/30]
Iter:   1900,  Train Loss:   1.2,  Train Acc: 92.19%,  Val Loss:   1.1,  Val Acc: 76.28%,  Time: 0:01:36 ,  LR: 0.0014831583923107237
Iter:   1950,  Train Loss:   1.1,  Train Acc: 84.38%,  Val Loss:   1.1,  Val Acc: 75.67%,  Time: 0:01:39 ,  LR: 1.3695261579316776e-05
Epoch [19/30]
Iter:   2000,  Train Loss:   1.1,  Train Acc: 89.06%,  Val Loss:   1.1,  Val Acc: 74.85%,  Time: 0:01:41 ,  LR: 0.0010305368692689059
Iter:   2050,  Train Loss:   1.1,  Train Acc: 84.38%,  Val Loss:   1.1,  Val Acc: 74.85%,  Time: 0:01:43 ,  LR: 0.0035168416076912156
Epoch [20/30]
Iter:   2100,  Train Loss:   1.1,  Train Acc: 82.81%,  Val Loss:   1.1,  Val Acc: 75.73%,  Time: 0:01:46 *,  LR: 0.00498630473841977
Iter:   2150,  Train Loss:   1.1,  Train Acc: 84.38%,  Val Loss:   1.1,  Val Acc: 76.06%,  Time: 0:01:48 ,  LR: 0.003969463130732069
Epoch [21/30]
Iter:   2200,  Train Loss:   1.1,  Train Acc: 89.06%,  Val Loss:   1.1,  Val Acc: 75.40%,  Time: 0:01:51 ,  LR: 0.0014831583923105868
Iter:   2250,  Train Loss:   1.1,  Train Acc: 92.19%,  Val Loss:   1.1,  Val Acc: 75.56%,  Time: 0:01:53 ,  LR: 1.3695261579316776e-05
Epoch [22/30]
Iter:   2300,  Train Loss:   1.1,  Train Acc: 85.94%,  Val Loss:   1.1,  Val Acc: 75.73%,  Time: 0:01:55 ,  LR: 0.0010305368692693907
Iter:   2350,  Train Loss:   1.2,  Train Acc: 93.75%,  Val Loss:   1.1,  Val Acc: 76.28%,  Time: 0:01:57 ,  LR: 0.003516841607690843
Epoch [23/30]
Iter:   2400,  Train Loss:   1.1,  Train Acc: 92.19%,  Val Loss:   1.1,  Val Acc: 74.74%,  Time: 0:01:59 ,  LR: 0.004986304738421898
Iter:   2450,  Train Loss:   1.1,  Train Acc: 92.19%,  Val Loss:   1.1,  Val Acc: 76.55%,  Time: 0:02:02 ,  LR: 0.003969463130731678
Iter:   2500,  Train Loss:   1.0,  Train Acc: 92.19%,  Val Loss:   1.1,  Val Acc: 76.99%,  Time: 0:02:05 ,  LR: 0.0014831583923111669
Epoch [24/30]
Iter:   2550,  Train Loss:   1.1,  Train Acc: 96.88%,  Val Loss:   1.1,  Val Acc: 76.50%,  Time: 0:02:07 ,  LR: 1.3695261579316776e-05
Iter:   2600,  Train Loss:   1.2,  Train Acc: 93.75%,  Val Loss:   1.1,  Val Acc: 77.32%,  Time: 0:02:09 ,  LR: 0.0010305368692686526
Epoch [25/30]
Iter:   2650,  Train Loss:   1.0,  Train Acc: 93.75%,  Val Loss:   1.1,  Val Acc: 77.05%,  Time: 0:02:11 ,  LR: 0.003516841607690539
Iter:   2700,  Train Loss:   1.2,  Train Acc: 92.19%,  Val Loss:   1.1,  Val Acc: 77.05%,  Time: 0:02:14 *,  LR: 0.004986304738418673
Epoch [26/30]
Iter:   2750,  Train Loss:   1.2,  Train Acc: 93.75%,  Val Loss:   1.1,  Val Acc: 77.87%,  Time: 0:02:16 ,  LR: 0.003969463130731092
Iter:   2800,  Train Loss:   1.1,  Train Acc: 93.75%,  Val Loss:   1.1,  Val Acc: 76.99%,  Time: 0:02:18 ,  LR: 0.0014831583923110307
Epoch [27/30]
Iter:   2850,  Train Loss:   1.2,  Train Acc: 93.75%,  Val Loss:   1.1,  Val Acc: 77.27%,  Time: 0:02:21 ,  LR: 1.3695261579316776e-05
Iter:   2900,  Train Loss:   1.1,  Train Acc: 90.62%,  Val Loss:   1.1,  Val Acc: 75.34%,  Time: 0:02:23 ,  LR: 0.0010305368692697578
Epoch [28/30]
Iter:   2950,  Train Loss:   1.1,  Train Acc: 96.88%,  Val Loss:   1.1,  Val Acc: 78.58%,  Time: 0:02:25 ,  LR: 0.003516841607690035
Iter:   3000,  Train Loss:   1.2,  Train Acc: 92.19%,  Val Loss:   1.1,  Val Acc: 78.31%,  Time: 0:02:28 ,  LR: 0.004986304738423509
Iter:   3050,  Train Loss:   1.0,  Train Acc: 96.88%,  Val Loss:   1.2,  Val Acc: 77.54%,  Time: 0:02:30 ,  LR: 0.003969463130735082
Epoch [29/30]
Iter:   3100,  Train Loss:   1.2,  Train Acc: 89.06%,  Val Loss:   1.1,  Val Acc: 78.14%,  Time: 0:02:32 ,  LR: 0.0014831583923094
Iter:   3150,  Train Loss:   1.0,  Train Acc: 93.75%,  Val Loss:   1.1,  Val Acc: 78.42%,  Time: 0:02:35 ,  LR: 1.3695261579316776e-05
Epoch [30/30]
Iter:   3200,  Train Loss:   1.1,  Train Acc: 98.44%,  Val Loss:   1.1,  Val Acc: 77.32%,  Time: 0:02:37 ,  LR: 0.0010305368692683993
Iter:   3250,  Train Loss:   1.2,  Train Acc: 93.75%,  Val Loss:   1.1,  Val Acc: 78.09%,  Time: 0:02:39 *,  LR: 0.003516841607689722