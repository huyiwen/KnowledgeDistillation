
加载数据...
tensor([[  101,  4205,  5472,  ...,     0,     0,     0],
        [  101,  2019,  4024,  ...,     0,     0,     0],
        [  101,  2045,  1005,  ...,     0,     0,     0],
        ...,
        [  101,  2035,  1996,  ...,     0,     0,     0],
        [  101, 11552,  2135,  ...,     0,     0,     0],
        [  101,  1037,  4121,  ...,     0,     0,     0]])
Time usage: 0:00:11
Some weights of the model checkpoint at /home/huyiwen/pretrained/bert-base-uncased-SST-2 were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
BERT_Model(
  (bert): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0-11): 12 x BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (fc): Linear(in_features=768, out_features=192, bias=True)
  (fc1): Linear(in_features=192, out_features=2, bias=True)
)
cuda
biLSTM(
  (Embedding): Embedding(30522, 300)
  (lstm): LSTM(300, 300, batch_first=True, bidirectional=True)
  (fc1): Linear(in_features=600, out_features=192, bias=True)
  (fc2): Linear(in_features=192, out_features=2, bias=True)
)
10,717,178 total parameters.
Epoch [1/30]
s_logits tensor([[0.4773, 0.5227],
        [0.4840, 0.5160],
        [0.4748, 0.5252],
        [0.4847, 0.5153],
        [0.4798, 0.5202],
        [0.4893, 0.5107],
        [0.4852, 0.5148],
        [0.4929, 0.5071],
        [0.4747, 0.5253],
        [0.4861, 0.5139],
        [0.4815, 0.5185],
        [0.5015, 0.4985],
        [0.4974, 0.5026],
        [0.4883, 0.5117],
        [0.4966, 0.5034],
        [0.4848, 0.5152],
        [0.4911, 0.5089],
        [0.4943, 0.5057],
        [0.4831, 0.5169],
        [0.4812, 0.5188],
        [0.4877, 0.5123],
        [0.4851, 0.5149],
        [0.4872, 0.5128],
        [0.4819, 0.5181],
        [0.4877, 0.5123],
        [0.4821, 0.5179],
        [0.5041, 0.4959],
        [0.4794, 0.5206],
        [0.4903, 0.5097],
        [0.4899, 0.5101],
        [0.4875, 0.5125],
        [0.4926, 0.5074],
        [0.4905, 0.5095],
        [0.4951, 0.5049],
        [0.4869, 0.5131],
        [0.4880, 0.5120],
        [0.4870, 0.5130],
        [0.4922, 0.5078],
        [0.4858, 0.5142],
        [0.4865, 0.5135],
        [0.4834, 0.5166],
        [0.4867, 0.5133],
        [0.4930, 0.5070],
        [0.4832, 0.5168],
        [0.4877, 0.5123],
        [0.4843, 0.5157],
        [0.4855, 0.5145],
        [0.4865, 0.5135],
        [0.4893, 0.5107],
        [0.4866, 0.5134],
        [0.4911, 0.5089],
        [0.4856, 0.5144],
        [0.4889, 0.5111],
        [0.4826, 0.5174],
        [0.4836, 0.5164],
        [0.4897, 0.5103],
        [0.4882, 0.5118],
        [0.4888, 0.5112],
        [0.4863, 0.5137],
        [0.4895, 0.5105],
        [0.4830, 0.5170],
        [0.4989, 0.5011],
        [0.4815, 0.5185],
        [0.4785, 0.5215]], device='cuda:0', grad_fn=<SoftmaxBackward0>) label tensor([0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,
        0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0,
        1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1], device='cuda:0')
t_logits tensor([[9.9947e-01, 5.3368e-04],
        [1.2205e-02, 9.8779e-01],
        [9.9808e-01, 1.9192e-03],
        [9.9885e-01, 1.1547e-03],
        [3.9347e-03, 9.9607e-01],
        [5.3743e-03, 9.9463e-01],
        [9.5874e-01, 4.1255e-02],
        [3.5135e-03, 9.9649e-01],
        [9.2223e-01, 7.7773e-02],
        [4.1820e-03, 9.9582e-01],
        [9.9900e-01, 9.9894e-04],
        [9.9904e-01, 9.6125e-04],
        [9.1609e-01, 8.3912e-02],
        [3.0861e-03, 9.9691e-01],
        [4.1088e-03, 9.9589e-01],
        [9.9472e-01, 5.2836e-03],
        [1.4192e-02, 9.8581e-01],
        [1.5545e-02, 9.8446e-01],
        [4.5848e-02, 9.5415e-01],
        [5.4886e-03, 9.9451e-01],
        [9.9874e-01, 1.2551e-03],
        [9.9950e-01, 5.0455e-04],
        [9.9912e-01, 8.7586e-04],
        [9.9855e-01, 1.4496e-03],
        [3.8550e-03, 9.9615e-01],
        [3.0349e-03, 9.9697e-01],
        [9.9906e-01, 9.3514e-04],
        [9.9930e-01, 7.0369e-04],
        [4.0615e-03, 9.9594e-01],
        [4.2186e-03, 9.9578e-01],
        [4.2164e-03, 9.9578e-01],
        [9.9280e-01, 7.2048e-03],
        [9.9821e-01, 1.7895e-03],
        [9.9936e-01, 6.4397e-04],
        [3.5035e-03, 9.9650e-01],
        [9.9912e-01, 8.8046e-04],
        [9.9697e-01, 3.0259e-03],
        [9.9921e-01, 7.8953e-04],
        [9.9807e-01, 1.9271e-03],
        [9.9935e-01, 6.5100e-04],
        [4.0775e-03, 9.9592e-01],
        [9.7800e-01, 2.1997e-02],
        [9.1303e-03, 9.9087e-01],
        [2.9660e-03, 9.9703e-01],
        [7.3085e-03, 9.9269e-01],
        [9.9474e-01, 5.2644e-03],
        [9.6431e-01, 3.5686e-02],
        [9.9511e-01, 4.8911e-03],
        [9.9947e-01, 5.2820e-04],
        [9.9789e-01, 2.1140e-03],
        [9.9562e-01, 4.3801e-03],
        [9.9917e-01, 8.3110e-04],
        [5.5824e-03, 9.9442e-01],
        [3.1015e-03, 9.9690e-01],
        [5.6073e-03, 9.9439e-01],
        [9.6293e-01, 3.7073e-02],
        [1.6173e-02, 9.8383e-01],
        [1.1644e-02, 9.8836e-01],
        [7.2993e-03, 9.9270e-01],
        [9.9913e-01, 8.7073e-04],
        [4.8140e-03, 9.9519e-01],
        [9.9937e-01, 6.2513e-04],
        [5.6990e-03, 9.9430e-01],
        [5.8538e-03, 9.9415e-01]], device='cuda:0')
base_loss tensor(0.6930, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(0.2418, device='cuda:0', grad_fn=<MseLossBackward0>)
==> name Embedding.weight torch.Size([30522, 300]) tensor([[-2.9262e-05,  3.3261e-06, -1.2510e-05,  ...,  2.6411e-05,
          9.3781e-06, -2.2252e-05],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]], device='cuda:0')
==> name lstm.weight_ih_l0 torch.Size([1200, 300]) tensor([[-1.6675e-05, -1.2395e-04,  1.2947e-05,  ...,  2.6398e-05,
         -7.8243e-05, -3.9246e-06],
        [ 1.7894e-05,  2.1899e-05, -1.7055e-05,  ..., -1.9407e-06,
          2.9978e-05,  7.4290e-06],
        [-1.9433e-05, -4.1803e-05, -7.2696e-07,  ...,  1.3892e-05,
          1.0950e-06, -7.2214e-07],
        ...,
        [-1.1859e-05, -2.4304e-05, -4.5703e-06,  ...,  3.4159e-05,
         -4.0184e-05,  1.7461e-05],
        [ 3.7486e-05,  9.1287e-06, -3.0394e-05,  ...,  4.5073e-05,
          1.5995e-05,  2.1748e-05],
        [ 7.7779e-06,  1.6416e-05,  8.6093e-07,  ..., -8.8693e-08,
          4.1222e-06, -2.4020e-05]], device='cuda:0')
==> name lstm.weight_hh_l0 torch.Size([1200, 300]) tensor([[-3.7336e-06, -2.0494e-06,  4.5468e-06,  ..., -2.3412e-06,
          5.6244e-06,  6.9529e-06],
        [-2.5878e-06,  1.2885e-06, -5.6715e-06,  ..., -3.1671e-06,
         -3.8238e-06,  7.0945e-07],
        [ 8.8602e-07, -1.7575e-06,  3.7479e-07,  ..., -1.8463e-06,
         -8.4626e-07, -2.3475e-06],
        ...,
        [-5.9021e-06, -5.6931e-07, -4.9867e-06,  ..., -1.9351e-06,
          4.2306e-06, -1.9776e-06],
        [-2.2010e-06,  3.1025e-06,  7.8324e-08,  ...,  5.9722e-07,
          2.1278e-06,  3.9274e-06],
        [ 3.6668e-07,  3.8130e-06, -1.2545e-06,  ...,  3.4301e-06,
          4.1163e-06, -9.4094e-06]], device='cuda:0')
==> name lstm.bias_ih_l0 torch.Size([1200]) tensor([-3.3297e-05, -4.2846e-05, -1.7954e-06,  ..., -5.3846e-06,
        -1.3373e-05,  4.4864e-05], device='cuda:0')
==> name lstm.bias_hh_l0 torch.Size([1200]) tensor([-3.3297e-05, -4.2846e-05, -1.7954e-06,  ..., -5.3846e-06,
        -1.3373e-05,  4.4864e-05], device='cuda:0')
==> name lstm.weight_ih_l0_reverse torch.Size([1200, 300]) tensor([[ 2.7366e-05, -3.3096e-05,  7.1395e-06,  ...,  2.5695e-05,
          1.9459e-06, -1.1778e-05],
        [ 4.0687e-06,  7.5088e-05,  8.8975e-05,  ..., -7.3885e-05,
         -5.3952e-05, -3.6013e-05],
        [-3.8625e-06, -3.2122e-05, -3.6415e-05,  ...,  4.8187e-05,
         -3.0782e-05,  1.7536e-05],
        ...,
        [ 5.5659e-06, -2.1730e-05, -6.3470e-06,  ...,  2.4458e-05,
         -1.5605e-05, -8.4151e-06],
        [ 3.1863e-05,  8.4200e-06,  6.1444e-06,  ...,  1.9935e-05,
          1.7056e-05,  1.8474e-05],
        [ 1.8698e-05, -1.2767e-05, -2.4974e-05,  ..., -3.4304e-05,
         -5.9073e-05,  3.4120e-05]], device='cuda:0')
==> name lstm.weight_hh_l0_reverse torch.Size([1200, 300]) tensor([[-1.3184e-06,  3.5331e-06, -3.3625e-06,  ...,  2.1929e-06,
          1.5977e-06, -1.1688e-07],
        [-6.2862e-06, -5.6571e-06,  4.4191e-07,  ..., -9.4331e-06,
         -6.9160e-07,  1.1785e-06],
        [-1.2721e-06,  6.7328e-07,  1.4128e-06,  ..., -1.5895e-07,
         -3.1779e-07,  1.2732e-05],
        ...,
        [ 1.7936e-06,  1.9392e-06,  2.5891e-06,  ...,  2.0255e-06,
         -9.3464e-09, -3.8600e-06],
        [-2.9443e-06,  2.3512e-06, -2.4960e-07,  ...,  3.1394e-06,
          2.5342e-06, -3.4491e-06],
        [ 4.4323e-06, -5.3956e-06, -3.9798e-06,  ..., -1.3551e-06,
          9.7803e-06,  1.3611e-05]], device='cuda:0')
==> name lstm.bias_ih_l0_reverse torch.Size([1200]) tensor([-2.8508e-05,  1.6215e-05, -5.2606e-06,  ..., -5.0651e-06,
         1.9243e-05, -3.4533e-05], device='cuda:0')
==> name lstm.bias_hh_l0_reverse torch.Size([1200]) tensor([-2.8508e-05,  1.6215e-05, -5.2606e-06,  ..., -5.0651e-06,
         1.9243e-05, -3.4533e-05], device='cuda:0')
==> name fc1.weight torch.Size([192, 600]) tensor([[-6.1222e-04, -1.2122e-04, -2.4883e-04,  ..., -9.7706e-05,
         -1.1009e-04,  1.4417e-04],
        [-7.6041e-04, -1.8912e-04, -1.3293e-04,  ..., -7.7427e-05,
          1.9338e-04,  3.7533e-04],
        [ 2.4233e-05,  3.9308e-04, -3.0887e-04,  ...,  3.8933e-06,
         -6.0404e-05,  4.6579e-05],
        ...,
        [ 2.2092e-04,  1.7718e-04, -1.2586e-04,  ...,  1.0850e-04,
         -3.4027e-05,  1.1426e-05],
        [-7.8210e-05, -2.3422e-04, -1.1100e-04,  ...,  1.0322e-04,
          9.4698e-05,  2.3552e-04],
        [-2.9087e-04, -4.5295e-04,  2.4391e-05,  ...,  6.6775e-05,
          4.8996e-05,  5.0734e-05]], device='cuda:0')
==> name fc1.bias torch.Size([192]) tensor([ 5.6226e-04, -8.3838e-04,  2.1182e-03, -2.2384e-04, -6.7815e-04,
         2.1834e-04, -1.0497e-03,  1.5927e-04,  3.5988e-04,  1.2712e-03,
         3.1422e-03,  1.8132e-04,  7.2148e-04, -1.2059e-03, -3.1657e-04,
        -9.2604e-04,  6.8268e-04, -3.3557e-04, -9.3199e-05, -1.7811e-03,
        -7.5199e-04,  1.0350e-03,  1.6216e-03, -3.6291e-04,  5.6178e-04,
        -6.8055e-04,  1.7480e-03, -4.0759e-04,  2.9809e-04, -6.4658e-04,
        -1.3758e-04,  1.7868e-03, -2.5742e-03,  1.5758e-03, -9.4705e-04,
         5.6664e-04, -3.7312e-04,  8.2918e-04,  1.6207e-03, -4.7709e-04,
        -6.0320e-04,  6.7917e-04, -9.2833e-04,  2.0032e-04, -1.5557e-04,
         3.3028e-03, -2.9500e-04,  2.3483e-04, -6.9188e-04, -1.5995e-03,
         2.3309e-04,  3.3670e-03, -9.5246e-04,  9.9878e-04,  2.0571e-03,
         2.4971e-04, -2.5101e-03, -1.9184e-03, -3.7852e-04,  2.1922e-03,
        -1.4773e-04,  6.1039e-04, -1.7346e-04,  3.5857e-05, -5.3284e-04,
         1.7087e-03, -1.2520e-03, -9.6073e-04,  1.1754e-05, -8.6337e-04,
         1.2090e-04, -7.1399e-04, -1.0485e-03, -1.0953e-03, -1.7877e-03,
         1.5292e-03, -5.2487e-04, -9.6671e-04,  3.6639e-06, -2.8813e-04,
         2.1270e-03,  2.3279e-04, -1.4480e-04,  2.2699e-04,  2.2739e-04,
         2.1705e-04,  4.3080e-05, -5.3212e-04, -9.9161e-04, -1.8334e-04,
         1.8800e-03, -5.2364e-04, -1.5536e-03,  4.8151e-04, -1.3552e-03,
         4.1212e-04, -1.4631e-03,  2.8984e-04, -9.5717e-04, -1.2059e-04,
        -9.0790e-04, -1.1553e-03,  1.6405e-04,  8.3838e-04,  4.8298e-04,
        -7.7702e-04,  1.5311e-03,  2.2114e-03, -5.0622e-04, -8.4281e-04,
         9.9350e-05,  2.2083e-04, -2.7688e-04,  5.8869e-05,  5.6864e-04,
         8.0735e-04, -3.5500e-04, -8.0482e-04, -2.8249e-03,  2.6637e-04,
         4.7386e-04,  4.3225e-04,  3.7250e-04,  1.5984e-03,  9.0510e-05,
         2.5155e-03,  2.0997e-03, -1.6328e-04, -3.7548e-04,  1.5611e-07,
        -7.3706e-04,  3.7850e-04, -1.8924e-06, -2.4401e-04,  6.6921e-04,
        -1.0575e-03, -8.8469e-04,  1.7223e-03,  1.6766e-03,  4.1782e-04,
         7.7968e-05,  1.4380e-03, -4.0099e-04,  9.0340e-04,  9.5663e-04,
         9.0456e-04,  1.7577e-03, -2.9195e-04,  1.4660e-04,  9.6813e-04,
        -5.9849e-04, -2.3997e-04,  1.0621e-03,  1.3919e-03,  2.0983e-04,
        -1.6358e-05, -8.8070e-04, -1.0369e-03, -5.6056e-04,  1.0839e-03,
        -1.9759e-04, -1.1272e-03, -1.7065e-03, -5.6697e-04, -3.4022e-03,
        -1.1707e-04, -5.4513e-05, -2.2927e-03,  2.6006e-03, -9.4482e-04,
        -3.3527e-04,  1.3174e-04,  1.8242e-03, -2.6258e-04, -7.6088e-04,
        -7.5749e-06,  6.0920e-04, -2.2731e-03, -5.0994e-04, -1.0497e-03,
         5.7521e-06, -9.7125e-05,  1.7239e-03,  3.2278e-04,  1.9563e-04,
         6.1977e-04, -1.8846e-04,  1.6054e-03, -4.0660e-04,  4.7450e-04,
        -1.1165e-03, -2.5992e-03], device='cuda:0')
==> name fc2.weight torch.Size([2, 192]) tensor([[ 1.7879e-03, -4.1202e-04, -2.1791e-04, -7.3727e-04,  1.7946e-04,
          4.8238e-04, -2.0071e-03,  6.7500e-04, -5.3779e-04, -4.0945e-04,
         -2.6392e-03,  2.0022e-04,  2.3794e-03, -2.1262e-03, -7.5070e-04,
         -5.5976e-04, -1.3993e-03,  6.6398e-04, -2.8159e-03, -1.5120e-03,
         -4.9779e-04,  4.2740e-05,  9.9930e-04, -1.2094e-03, -2.0129e-03,
         -8.8216e-04, -1.6633e-03, -2.8212e-03,  6.3889e-04, -7.2198e-04,
          1.0110e-03, -1.2019e-04,  4.5017e-04,  2.5039e-04,  1.9362e-04,
         -4.7815e-06, -6.1127e-04, -2.5583e-03,  3.6804e-03, -1.1078e-03,
         -9.1065e-05,  8.0682e-05, -3.7936e-04, -1.0781e-03, -1.6828e-03,
         -1.1605e-03, -1.4576e-03, -8.6264e-04, -2.2924e-03, -1.1118e-03,
         -4.3894e-04, -1.2199e-03, -6.7209e-04,  2.8635e-03,  6.8026e-04,
         -1.8984e-03, -1.7025e-03, -7.6391e-04, -2.3677e-03, -1.5905e-03,
          1.6667e-03,  8.7365e-04, -6.4790e-04, -1.7849e-03, -7.8167e-04,
         -6.5100e-05, -1.7521e-03, -1.8528e-03,  2.0941e-03, -1.1530e-03,
         -7.2064e-04,  5.3780e-04, -1.0912e-03, -3.4117e-03,  9.3167e-04,
         -1.0794e-03, -3.1996e-03,  4.8885e-04, -1.3619e-03,  9.8990e-05,
          2.7476e-03, -9.3050e-06,  1.3290e-04,  2.6470e-04,  1.6701e-03,
          1.5050e-03, -1.0331e-03, -3.7589e-04, -2.1216e-03,  1.4595e-03,
          4.5562e-04, -8.7872e-05,  9.8735e-04,  9.0171e-04, -1.0505e-03,
         -1.0863e-03, -1.1471e-03,  6.2910e-05,  1.2930e-03, -2.2724e-05,
         -2.3723e-03, -2.8043e-03,  3.5108e-04, -2.2102e-03, -4.9466e-04,
          2.3494e-04, -1.2089e-03, -3.1345e-04, -3.2074e-04,  1.5090e-03,
          1.6277e-03, -1.1097e-03, -4.8228e-04, -1.4633e-05, -1.0873e-03,
         -1.0418e-03, -5.9683e-04,  4.3621e-05, -2.4141e-03,  9.2349e-04,
         -8.5254e-04, -6.2169e-04, -1.3683e-03, -1.1531e-03,  6.7771e-04,
          7.9125e-04, -9.7131e-04,  8.6021e-04, -1.7339e-03, -4.6574e-05,
         -2.7080e-03,  5.9197e-04, -1.2788e-04,  1.2279e-03, -1.2319e-03,
         -2.1349e-03, -2.7079e-03, -1.8478e-03, -1.7191e-03,  8.7790e-04,
          8.0337e-04, -3.1977e-03, -3.4166e-04,  1.8053e-03, -1.7161e-03,
         -1.3710e-03,  1.9466e-03, -2.1500e-03, -2.0574e-03, -1.8873e-03,
         -1.2536e-03, -1.4355e-03, -1.3824e-03, -3.3010e-04, -3.2285e-04,
          9.3988e-04,  9.5269e-04, -1.7340e-03,  6.0726e-04, -7.4714e-04,
          1.2354e-03, -9.8766e-04, -1.8522e-03, -1.3854e-03, -1.8945e-03,
          2.0072e-03, -2.6406e-04, -2.2931e-03,  2.0499e-03,  2.4298e-03,
          1.0827e-03,  2.1119e-04, -3.8032e-04, -1.2249e-03, -2.0009e-03,
          1.3886e-04, -1.6770e-04, -3.3605e-03,  4.7470e-04,  8.0897e-05,
         -6.8334e-04, -1.0976e-03, -3.0774e-04,  4.9955e-04, -3.1148e-03,
         -8.6201e-04, -1.4547e-03, -1.4840e-03,  1.5398e-03, -9.7668e-04,
         -4.7168e-03, -3.0252e-03],
        [-3.3862e-04, -2.4798e-03, -9.4974e-05,  3.5939e-03, -3.0549e-03,
         -9.6501e-04,  5.1605e-05, -4.8926e-04,  1.3200e-03,  2.0482e-03,
         -1.0741e-03,  1.7753e-03,  1.1571e-03,  2.1757e-03,  5.0867e-04,
          4.8363e-03,  1.2775e-03,  5.7188e-05,  4.3019e-04, -2.4323e-04,
         -7.6616e-04, -2.3951e-05,  3.1663e-03,  2.1331e-03,  1.2858e-03,
          2.8639e-03,  2.8198e-03,  7.0588e-04, -4.6493e-04, -1.0054e-03,
          2.1212e-04, -2.8470e-03,  3.2434e-03,  1.4555e-03,  1.2798e-03,
          1.8817e-03,  3.0302e-03,  3.0902e-03, -3.6872e-04,  6.2014e-04,
          1.5085e-03,  1.4414e-03,  2.8513e-03,  3.1408e-04,  1.5240e-03,
         -2.4643e-03, -1.5020e-04, -6.9982e-04,  1.7137e-03,  1.4804e-03,
         -1.7083e-04,  4.8464e-03, -6.1548e-03,  3.4118e-03, -1.9598e-03,
          9.9112e-04,  3.1902e-03,  2.7243e-03, -2.3882e-03,  5.1984e-03,
          6.4509e-04,  1.4631e-03,  1.0678e-03,  1.9861e-03, -1.7998e-03,
         -5.8933e-04,  2.3875e-03,  1.1027e-03,  5.3787e-05,  1.6540e-03,
          5.0364e-04,  1.4069e-03,  2.7224e-03, -1.0771e-03,  2.4728e-04,
          9.1989e-04,  2.4299e-03, -1.4258e-03,  4.0731e-03, -2.7414e-05,
          1.0029e-03, -1.1740e-03, -8.5796e-04,  2.3453e-04, -3.4133e-03,
         -7.3866e-04, -8.8398e-04, -2.3376e-04,  1.1347e-03,  1.0237e-03,
          2.7168e-03,  6.7578e-04,  2.7405e-03,  2.3939e-03,  1.9553e-03,
          8.7024e-04, -4.5636e-03, -1.3422e-03,  1.4116e-03,  1.6244e-03,
         -5.4993e-04, -5.4802e-05, -1.0632e-03,  1.2193e-03, -4.5191e-04,
         -3.0772e-04,  1.7902e-04,  4.5121e-03,  1.2392e-03,  4.0483e-04,
         -2.4519e-04,  6.5639e-04,  1.9619e-03,  9.0869e-04, -1.0817e-03,
          6.1588e-04,  3.3961e-03, -2.5266e-03,  7.9908e-04, -1.6668e-03,
          6.1220e-05, -1.1881e-03, -1.2198e-03,  1.5439e-03, -1.0079e-03,
          3.0711e-03,  3.1618e-03, -4.1840e-04,  2.7750e-06,  2.9047e-03,
          1.8240e-03,  1.2155e-03, -1.5911e-03, -2.3541e-03,  1.9289e-03,
          9.5083e-04,  3.2583e-03,  3.4183e-03, -1.2775e-03,  1.3142e-03,
          2.6831e-04, -6.9520e-04, -3.9194e-04,  2.7112e-03,  1.1826e-04,
          5.5439e-05,  1.5069e-03,  2.2979e-03,  1.5182e-03,  2.4701e-03,
          1.0646e-03, -5.6630e-05,  2.1681e-03,  3.6227e-03,  3.6477e-04,
          6.5558e-04,  1.1570e-03, -1.6519e-03,  1.3268e-03,  9.8197e-04,
          2.0600e-03,  1.4937e-03,  7.8636e-04,  5.3136e-04,  3.3823e-03,
         -1.6268e-03,  1.1460e-03,  1.7367e-03,  4.5674e-03,  1.9005e-03,
          1.3297e-03,  8.4268e-04,  2.3400e-03,  4.4879e-04,  1.7891e-03,
          2.5367e-04,  1.9117e-03,  5.4626e-04,  4.0413e-04,  3.0111e-04,
          1.4644e-03,  3.0637e-04,  1.5539e-03,  1.2403e-03,  1.3062e-03,
         -2.0083e-03,  3.9305e-04, -1.1966e-03,  1.0769e-03,  3.5024e-03,
          1.2179e-03,  8.3861e-04]], device='cuda:0')
==> name fc2.bias torch.Size([2]) tensor([-0.0211,  0.0211], device='cuda:0')
tensor([[-0.0024,  0.0885],
        [-0.0032,  0.0607],
        [-0.0047,  0.0962],
        [ 0.0119,  0.0729],
        [-0.0047,  0.0761],
        [ 0.0087,  0.0516],
        [-0.0047,  0.0543],
        [ 0.0364,  0.0650],
        [-0.0047,  0.0965],
        [ 0.0167,  0.0721],
        [-0.0047,  0.0695],
        [ 0.0470,  0.0409],
        [ 0.0434,  0.0538],
        [ 0.0226,  0.0694],
        [ 0.0432,  0.0569],
        [ 0.0106,  0.0713],
        [ 0.0386,  0.0742],
        [ 0.0238,  0.0465],
        [-0.0047,  0.0629],
        [-0.0047,  0.0705],
        [ 0.0297,  0.0790],
        [ 0.0022,  0.0616],
        [ 0.0020,  0.0533],
        [ 0.0087,  0.0812],
        [ 0.0130,  0.0623],
        [-0.0047,  0.0669],
        [ 0.0408,  0.0244],
        [-0.0047,  0.0775],
        [ 0.0362,  0.0749],
        [ 0.0111,  0.0514],
        [ 0.0298,  0.0798],
        [ 0.0076,  0.0374],
        [ 0.0037,  0.0418],
        [ 0.0333,  0.0529],
        [ 0.0341,  0.0865],
        [ 0.0113,  0.0593],
        [ 0.0129,  0.0648],
        [ 0.0285,  0.0598],
        [-0.0038,  0.0531],
        [-0.0047,  0.0495],
        [-0.0047,  0.0616],
        [ 0.0161,  0.0693],
        [ 0.0250,  0.0529],
        [-0.0047,  0.0626],
        [-0.0047,  0.0443],
        [ 0.0021,  0.0651],
        [ 0.0062,  0.0641],
        [ 0.0115,  0.0656],
        [ 0.0147,  0.0574],
        [-0.0047,  0.0488],
        [ 0.0278,  0.0634],
        [ 0.0112,  0.0689],
        [ 0.0092,  0.0536],
        [-0.0047,  0.0648],
        [-0.0047,  0.0610],
        [-0.0015,  0.0396],
        [ 0.0224,  0.0696],
        [ 0.0058,  0.0508],
        [-0.0008,  0.0538],
        [ 0.0085,  0.0505],
        [-0.0047,  0.0635],
        [ 0.0358,  0.0402],
        [-0.0047,  0.0692],
        [ 0.0059,  0.0918]], device='cuda:0', grad_fn=<SqueezeBackward1>)
Iter:      0,  Train Loss:  0.24,  Train Acc: 48.44%,  Val Loss:  0.22,  Val Acc: 51.18%,  Time: 0:00:02 *,  LR: 0.9972609476841366
s_logits tensor([[0.4682, 0.5318],
        [0.4528, 0.5472],
        [0.4708, 0.5292],
        [0.4659, 0.5341],
        [0.4724, 0.5276],
        [0.4661, 0.5339],
        [0.4499, 0.5501],
        [0.4740, 0.5260],
        [0.4671, 0.5329],
        [0.4670, 0.5330],
        [0.4618, 0.5382],
        [0.4621, 0.5379],
        [0.4651, 0.5349],
        [0.4651, 0.5349],
        [0.4650, 0.5350],
        [0.4683, 0.5317],
        [0.4613, 0.5387],
        [0.4680, 0.5320],
        [0.4591, 0.5409],
        [0.4757, 0.5243],
        [0.4648, 0.5352],
        [0.4657, 0.5343],
        [0.4643, 0.5357],
        [0.4608, 0.5392],
        [0.4699, 0.5301],
        [0.4827, 0.5173],
        [0.4592, 0.5408],
        [0.4680, 0.5320],
        [0.4683, 0.5317],
        [0.4686, 0.5314],
        [0.4654, 0.5346],
        [0.4513, 0.5487],
        [0.4732, 0.5268],
        [0.4649, 0.5351],
        [0.4820, 0.5180],
        [0.4653, 0.5347],
        [0.4582, 0.5418],
        [0.4667, 0.5333],
        [0.4414, 0.5586],
        [0.4623, 0.5377],
        [0.4608, 0.5392],
        [0.4639, 0.5361],
        [0.4622, 0.5378],
        [0.4645, 0.5355],
        [0.4517, 0.5483],
        [0.4581, 0.5419],
        [0.4794, 0.5206],
        [0.4658, 0.5342],
        [0.4524, 0.5476],
        [0.4606, 0.5394],
        [0.4609, 0.5391],
        [0.4719, 0.5281],
        [0.4611, 0.5389],
        [0.4733, 0.5267],
        [0.4818, 0.5182],
        [0.4581, 0.5419],
        [0.4640, 0.5360],
        [0.4593, 0.5407],
        [0.4491, 0.5509],
        [0.4612, 0.5388],
        [0.4442, 0.5558],
        [0.4633, 0.5367],
        [0.4623, 0.5377],
        [0.4660, 0.5340]], device='cuda:0', grad_fn=<SoftmaxBackward0>) label tensor([0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1,
        1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0,
        1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1], device='cuda:0')
t_logits tensor([[3.6535e-03, 9.9635e-01],
        [8.5200e-02, 9.1480e-01],
        [9.9759e-01, 2.4075e-03],
        [9.8347e-01, 1.6529e-02],
        [9.9656e-01, 3.4396e-03],
        [9.9897e-01, 1.0284e-03],
        [9.9876e-01, 1.2386e-03],
        [8.9474e-01, 1.0526e-01],
        [1.7154e-02, 9.8285e-01],
        [7.8416e-03, 9.9216e-01],
        [9.9947e-01, 5.3270e-04],
        [9.9902e-01, 9.7864e-04],
        [9.9658e-01, 3.4199e-03],
        [7.4760e-03, 9.9252e-01],
        [5.5121e-03, 9.9449e-01],
        [9.9818e-01, 1.8217e-03],
        [9.9763e-01, 2.3679e-03],
        [9.9828e-01, 1.7159e-03],
        [9.9196e-01, 8.0375e-03],
        [9.8732e-01, 1.2684e-02],
        [9.9913e-01, 8.7289e-04],
        [9.9762e-01, 2.3799e-03],
        [2.9597e-03, 9.9704e-01],
        [9.9868e-01, 1.3227e-03],
        [9.8777e-01, 1.2229e-02],
        [3.2997e-02, 9.6700e-01],
        [4.0559e-03, 9.9594e-01],
        [1.0727e-02, 9.8927e-01],
        [1.6889e-02, 9.8311e-01],
        [9.9938e-01, 6.1934e-04],
        [3.1060e-03, 9.9689e-01],
        [9.9907e-01, 9.3411e-04],
        [9.9672e-01, 3.2779e-03],
        [4.5648e-03, 9.9544e-01],
        [3.7807e-02, 9.6219e-01],
        [5.6310e-03, 9.9437e-01],
        [9.8587e-01, 1.4132e-02],
        [9.8950e-01, 1.0499e-02],
        [3.9312e-03, 9.9607e-01],
        [4.4445e-03, 9.9556e-01],
        [9.9902e-01, 9.7928e-04],
        [9.9541e-01, 4.5851e-03],
        [9.9492e-01, 5.0788e-03],
        [9.9911e-01, 8.9490e-04],
        [4.4977e-03, 9.9550e-01],
        [5.4439e-03, 9.9456e-01],
        [9.9627e-01, 3.7299e-03],
        [4.3933e-03, 9.9561e-01],
        [9.9934e-01, 6.6125e-04],
        [9.9890e-01, 1.0952e-03],
        [3.5763e-03, 9.9642e-01],
        [3.7101e-03, 9.9629e-01],
        [3.5931e-03, 9.9641e-01],
        [5.6526e-03, 9.9435e-01],
        [9.9926e-01, 7.4279e-04],
        [3.3738e-03, 9.9663e-01],
        [9.9906e-01, 9.4135e-04],
        [9.7151e-01, 2.8491e-02],
        [9.8060e-02, 9.0194e-01],
        [9.9738e-01, 2.6226e-03],
        [4.0014e-03, 9.9600e-01],
        [9.9899e-01, 1.0121e-03],
        [9.9566e-01, 4.3449e-03],
        [2.7041e-03, 9.9730e-01]], device='cuda:0')
base_loss tensor(0.6973, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(0.2455, device='cuda:0', grad_fn=<MseLossBackward0>)
==> name Embedding.weight torch.Size([30522, 300]) tensor([[-5.9844e-07,  9.0305e-06,  1.1644e-05,  ..., -4.1284e-06,
         -3.8461e-06,  3.3242e-06],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]], device='cuda:0')
==> name lstm.weight_ih_l0 torch.Size([1200, 300]) tensor([[-5.0411e-05,  2.3301e-05, -8.5200e-07,  ..., -5.1328e-05,
         -2.0233e-05,  1.3085e-05],
        [-1.9180e-05,  1.2583e-05, -9.7413e-06,  ...,  1.8037e-05,
          3.3330e-05,  4.5852e-06],
        [-3.9269e-06,  8.6265e-06,  7.0550e-06,  ...,  1.4774e-06,
         -2.6895e-06, -1.5057e-07],
        ...,
        [-7.0634e-06, -2.4678e-05,  4.5584e-05,  ...,  1.4237e-05,
          1.6924e-05,  5.6989e-06],
        [ 3.1832e-05, -6.9445e-06, -4.1989e-05,  ..., -3.1437e-05,
          1.8249e-05, -9.9994e-06],
        [ 1.3401e-05, -3.6896e-05,  1.1714e-05,  ..., -3.9225e-07,
          9.3496e-06,  1.2033e-05]], device='cuda:0')
==> name lstm.weight_hh_l0 torch.Size([1200, 300]) tensor([[ 4.3073e-06, -8.0334e-06, -5.3261e-06,  ..., -8.7768e-06,
         -6.4169e-06,  3.8692e-07],
        [-6.5958e-06,  1.7024e-06, -2.0342e-06,  ..., -9.6872e-07,
         -2.4247e-06, -1.1002e-05],
        [ 7.2159e-06,  3.7779e-06,  2.3290e-07,  ..., -2.1673e-06,
         -6.7728e-07,  2.9166e-06],
        ...,
        [ 7.5933e-07,  1.3226e-07, -4.2701e-08,  ..., -8.6365e-07,
         -3.1177e-06, -1.7374e-06],
        [-4.8799e-06,  1.7436e-06,  9.8917e-06,  ...,  2.4316e-06,
         -2.7131e-07, -1.1234e-06],
        [ 8.1740e-06, -7.1898e-07,  2.9980e-06,  ...,  8.1460e-08,
         -2.5249e-06,  5.0263e-06]], device='cuda:0')
==> name lstm.bias_ih_l0 torch.Size([1200]) tensor([-4.8397e-05,  5.7957e-05, -1.6952e-05,  ..., -3.2312e-05,
        -2.5627e-05, -4.7659e-06], device='cuda:0')
==> name lstm.bias_hh_l0 torch.Size([1200]) tensor([-4.8397e-05,  5.7957e-05, -1.6952e-05,  ..., -3.2312e-05,
        -2.5627e-05, -4.7659e-06], device='cuda:0')
==> name lstm.weight_ih_l0_reverse torch.Size([1200, 300]) tensor([[ 1.9156e-05,  1.3805e-05,  1.8118e-05,  ...,  3.5599e-05,
          4.6705e-06, -6.2237e-06],
        [-1.4819e-05, -4.0515e-05, -2.2583e-05,  ...,  4.6452e-06,
         -3.8223e-05,  2.1037e-05],
        [ 1.8980e-05, -5.3133e-05, -4.5401e-05,  ..., -1.2067e-05,
          1.0249e-05, -9.8551e-06],
        ...,
        [-6.2214e-06,  4.9438e-05,  3.1369e-05,  ...,  1.9238e-05,
          2.2020e-05,  1.0998e-05],
        [ 4.7947e-05, -4.1271e-05,  6.4602e-06,  ..., -2.0174e-05,
          4.0474e-05, -3.2529e-05],
        [-1.2235e-05, -2.0386e-05, -3.8667e-05,  ..., -1.7756e-06,
         -4.7454e-06,  7.5849e-06]], device='cuda:0')
==> name lstm.weight_hh_l0_reverse torch.Size([1200, 300]) tensor([[-1.7252e-06,  2.6328e-06, -1.9190e-06,  ..., -6.1278e-06,
         -5.1106e-06,  4.0897e-06],
        [ 4.8871e-06, -7.8028e-07,  9.9835e-06,  ...,  3.1459e-06,
          1.4089e-06, -4.1636e-06],
        [ 3.8702e-06, -3.3579e-06,  2.9747e-06,  ...,  7.0436e-06,
          2.0438e-06,  7.8229e-07],
        ...,
        [-2.7031e-06,  1.0209e-06, -4.5974e-06,  ..., -9.1825e-06,
         -3.0975e-07,  7.3078e-06],
        [ 1.2719e-06,  2.9803e-06, -2.6161e-06,  ..., -4.1938e-06,
         -4.3949e-06, -4.6445e-06],
        [ 4.9553e-06, -1.2744e-06,  2.8508e-06,  ..., -8.7168e-06,
          2.0376e-06,  1.0857e-05]], device='cuda:0')
==> name lstm.bias_ih_l0_reverse torch.Size([1200]) tensor([-8.9664e-06,  2.3229e-05, -1.1544e-05,  ..., -1.0131e-05,
         1.2707e-06, -9.8852e-06], device='cuda:0')
==> name lstm.bias_hh_l0_reverse torch.Size([1200]) tensor([-8.9664e-06,  2.3229e-05, -1.1544e-05,  ..., -1.0131e-05,
         1.2707e-06, -9.8852e-06], device='cuda:0')
==> name fc1.weight torch.Size([192, 600]) tensor([[-1.7637e-04, -2.1960e-05, -1.4838e-04,  ..., -2.3947e-04,
         -1.3613e-04,  1.2474e-04],
        [-1.4653e-04,  6.1773e-05, -7.1442e-05,  ..., -1.4751e-04,
         -1.7743e-04,  1.2808e-04],
        [-2.6159e-04,  2.0810e-04,  2.5133e-05,  ..., -1.3189e-04,
         -1.1496e-05,  1.2942e-04],
        ...,
        [-9.2801e-05, -5.3980e-05, -9.4943e-05,  ..., -1.0784e-05,
         -1.0021e-04, -2.2025e-05],
        [ 1.1051e-04,  1.4896e-04, -9.9213e-06,  ...,  2.5723e-05,
          1.0733e-04, -4.9076e-05],
        [-3.2570e-05,  2.3386e-04, -2.1102e-04,  ..., -3.8629e-04,
         -1.4802e-04,  5.3023e-05]], device='cuda:0')
==> name fc1.bias torch.Size([192]) tensor([-2.5962e-03, -1.8606e-03,  1.6033e-03, -6.0247e-04,  3.6004e-04,
        -1.1938e-03, -6.2164e-04,  9.0134e-04,  1.2262e-03,  6.0923e-04,
        -4.7965e-04,  8.1605e-04, -2.5489e-04, -2.9659e-03, -8.4912e-04,
        -8.0760e-04,  1.1711e-03, -7.0765e-04, -7.3337e-04, -3.9205e-03,
        -1.3194e-03,  2.5340e-03, -1.0481e-03, -3.1792e-04, -1.9189e-03,
        -3.9422e-04,  1.6696e-03, -2.5812e-03, -1.1406e-04,  6.1580e-04,
        -1.6432e-03,  2.6709e-03,  4.4492e-04,  1.5443e-03, -2.1694e-03,
         8.5800e-04, -9.0722e-04,  9.3021e-04, -9.8546e-04, -1.2303e-03,
        -1.1130e-03,  7.3212e-04,  2.8918e-04,  3.4098e-04, -5.2351e-04,
         4.8336e-04, -1.9713e-03, -9.8929e-04,  6.7080e-04, -8.7771e-04,
         2.7536e-03,  3.2169e-03, -2.1293e-03,  3.6028e-04, -3.5937e-03,
         5.7870e-04, -1.1541e-03, -3.0499e-03,  2.8135e-05,  1.1109e-03,
         3.4062e-04,  6.2964e-04, -7.3370e-04, -1.2692e-05,  1.2260e-03,
         1.9758e-03, -8.6533e-04, -2.1514e-03, -4.5167e-04, -3.2260e-03,
         2.1334e-03,  5.0760e-04, -1.8873e-03, -6.7389e-04, -2.7798e-03,
         9.1784e-04, -1.6368e-04,  3.3346e-04,  1.0498e-03, -2.4099e-03,
        -1.4004e-03,  7.3408e-04, -1.3085e-03,  1.3720e-04,  2.7664e-03,
        -2.0796e-04, -3.7659e-05, -1.9916e-04, -1.7525e-03, -8.1732e-04,
         3.3645e-03,  1.4652e-03, -7.1947e-04,  9.1910e-04, -1.7643e-03,
         2.0339e-03,  1.7112e-03, -1.8816e-03, -3.2595e-04, -2.0578e-04,
        -1.2587e-03, -1.2098e-03,  1.8257e-04,  9.1618e-04, -1.6706e-03,
         1.5402e-03,  1.2796e-03,  1.4852e-03,  2.5565e-03,  2.9941e-04,
        -1.3465e-03,  1.2558e-03, -2.5436e-03,  1.0542e-03, -3.0130e-04,
        -1.4297e-04, -2.8716e-03, -1.0623e-04, -3.6316e-03, -2.3929e-04,
        -3.0515e-03, -3.8973e-04, -1.8353e-04,  1.7324e-03,  9.3684e-04,
         2.3579e-03,  4.7510e-03, -3.0396e-03, -1.0216e-03,  1.7639e-03,
        -1.4979e-03,  1.0355e-03, -1.5596e-03,  1.6458e-03, -1.4412e-03,
        -8.7705e-04, -1.8330e-03,  3.3196e-03,  3.5064e-03,  3.9385e-03,
         2.5286e-03,  3.5748e-03,  1.1992e-03,  9.2716e-04,  1.3385e-03,
         1.0113e-03,  4.2087e-04, -5.3910e-04,  1.2744e-03,  1.2116e-03,
        -1.6818e-03, -1.2862e-03,  3.0308e-03,  5.9888e-04,  1.0987e-03,
         5.2733e-04, -1.8535e-03, -2.3390e-03,  3.9229e-05, -7.4438e-04,
        -2.0482e-03,  2.2153e-04, -4.1680e-03, -4.2105e-04, -2.5349e-03,
         5.9658e-05,  1.7763e-03, -1.2368e-03,  8.8769e-04, -4.7654e-06,
        -6.8363e-04, -3.9106e-04,  1.5485e-03, -4.7645e-04,  3.3680e-04,
         8.6888e-04,  8.6697e-04, -1.5635e-03, -2.7754e-04,  5.3035e-04,
         8.5621e-04,  3.3205e-04,  1.3001e-03,  6.3655e-04,  1.9683e-03,
        -5.5242e-04,  1.6677e-03,  4.2408e-04,  3.9446e-04,  9.5194e-04,
        -1.1687e-03, -2.9957e-03], device='cuda:0')
==> name fc2.weight torch.Size([2, 192]) tensor([[-2.3986e-03, -1.8856e-03, -3.0385e-03, -1.4083e-03,  1.1924e-04,
         -3.1455e-03, -9.0692e-04, -8.7044e-04, -1.0826e-03, -1.8940e-03,
         -2.3901e-03, -2.1889e-03, -1.4726e-03, -2.8537e-03, -7.5612e-03,
         -1.1635e-03, -4.2051e-03, -2.0720e-03, -7.4372e-04, -4.2126e-03,
         -3.6964e-03, -1.1488e-03, -1.5368e-03, -3.3833e-03, -2.3962e-03,
         -2.1197e-03,  8.3579e-04, -4.0369e-03, -9.4963e-04, -1.9842e-03,
         -1.6560e-03, -3.0604e-03, -4.0417e-03, -1.7048e-04, -2.8472e-03,
          2.0868e-04, -3.3284e-04, -2.6671e-03, -1.5402e-03, -2.1907e-03,
         -3.6574e-04, -1.7807e-04, -2.4894e-03, -2.9924e-03, -1.4751e-03,
          1.1329e-04, -1.6807e-03, -5.8801e-04, -1.2904e-04, -2.4691e-03,
         -3.4470e-03, -2.4693e-03, -2.5081e-03,  4.3937e-04, -3.2093e-04,
         -1.0888e-03,  5.7870e-04, -1.0827e-03, -1.7375e-03, -5.1792e-04,
         -3.8411e-03, -9.8153e-04, -3.7575e-03, -8.2940e-04, -1.9474e-03,
         -9.3923e-04, -1.7677e-03, -4.7013e-03, -2.5794e-05, -2.9853e-03,
          1.6660e-04, -1.6995e-03, -1.8100e-03, -1.6526e-03, -8.2805e-04,
         -1.7767e-03, -8.5341e-04, -6.8516e-04,  3.7633e-04,  1.2318e-03,
         -2.0997e-03,  3.6178e-04, -1.1357e-03, -3.3181e-04, -5.1474e-04,
         -5.1369e-04, -2.3040e-03, -4.9161e-05, -1.8969e-03, -6.1518e-04,
          1.0699e-04, -1.9590e-03, -8.7371e-04, -1.2741e-03, -2.3857e-03,
         -3.9632e-03, -4.7443e-04, -2.8026e-03,  3.5215e-04, -7.0873e-04,
         -6.3900e-03, -4.1363e-03, -1.1476e-03, -2.2976e-03, -1.5379e-04,
         -1.4124e-03, -2.0612e-03,  5.7165e-04, -2.5456e-04, -1.6944e-03,
          1.5572e-03, -6.9549e-04,  1.1658e-03, -1.5488e-03, -8.9435e-04,
         -1.4823e-03, -4.8974e-03, -7.8299e-04, -4.3131e-03, -4.0979e-04,
         -2.2506e-03,  2.1466e-04, -4.2074e-03, -1.5690e-03, -3.9122e-03,
         -2.6978e-03, -3.5445e-03, -2.0862e-03, -8.3160e-04, -4.1882e-03,
         -3.5779e-03, -7.4993e-04, -4.3174e-03, -2.4708e-03, -2.8044e-03,
         -1.2316e-03, -3.4233e-03, -1.2773e-03, -2.7843e-03, -1.7694e-03,
         -8.6078e-05, -3.2126e-03,  1.8244e-05, -4.5034e-03, -2.8170e-03,
         -1.8488e-03, -1.3152e-03, -4.6645e-03, -1.5937e-04, -8.5502e-04,
         -2.0319e-03, -2.4337e-03,  1.3450e-03, -2.8862e-03, -2.6065e-06,
         -3.9681e-05, -2.8784e-03, -2.9599e-04,  5.1662e-04,  6.0216e-04,
         -7.0274e-04, -1.4427e-04,  1.0702e-03, -3.9293e-03, -4.9167e-03,
         -4.2605e-03, -1.6191e-03,  8.8320e-04, -3.3925e-03, -9.3194e-04,
         -1.6262e-03, -8.3842e-04, -8.8805e-04, -1.6863e-03, -6.3042e-03,
         -1.4979e-03, -2.7473e-03, -4.2999e-03, -3.6179e-03, -5.7649e-04,
         -3.0822e-03, -2.3487e-03, -3.0205e-05, -1.6891e-03,  1.9857e-03,
          1.3289e-03, -1.9345e-03, -7.7310e-07,  6.4692e-04, -4.6411e-04,
         -3.7663e-03, -5.6916e-03],
        [ 1.1103e-03,  1.7684e-03,  1.5257e-03,  1.5835e-05,  4.0205e-03,
          2.1608e-03,  5.4099e-04,  3.2757e-04,  1.4604e-03, -4.9700e-04,
          1.5977e-03,  1.1272e-03,  1.1428e-03,  1.4381e-03, -1.5331e-05,
         -2.0474e-04,  1.2009e-03,  1.4260e-03,  1.0436e-03,  3.5882e-03,
         -8.6004e-04,  9.3284e-04, -1.2210e-04,  1.8084e-03,  9.2515e-04,
          1.8603e-03,  1.3869e-03,  6.3336e-05,  1.5194e-03, -4.1494e-04,
          1.0061e-03,  2.9513e-03,  1.6425e-03,  1.9454e-03,  2.0457e-03,
          1.0487e-03,  1.1763e-03,  3.8488e-03,  1.9402e-03,  6.3826e-04,
          6.8283e-04,  1.2562e-03,  3.1655e-03,  3.2412e-03,  1.5685e-03,
          1.0219e-03,  1.0061e-03,  1.2280e-04,  6.0246e-04,  3.5134e-04,
          4.8020e-03,  7.1282e-04,  8.5677e-04, -7.0619e-04,  4.0930e-03,
          1.3878e-05,  2.1153e-03,  2.0431e-03,  2.3378e-03,  1.7088e-03,
          1.1553e-03,  1.6347e-03,  2.0900e-03,  1.9222e-04,  2.9181e-03,
          2.5775e-03,  5.1261e-04,  3.1876e-03,  6.9917e-04,  1.8360e-03,
          2.3652e-03,  7.9176e-04,  3.1061e-03,  1.7313e-03,  1.7587e-03,
          1.0762e-03,  1.3488e-03,  5.4130e-04,  6.8213e-03,  2.4036e-03,
          4.2170e-03,  2.2909e-03,  7.7772e-04,  1.6486e-03, -5.6543e-04,
          7.8623e-04,  3.4112e-04,  6.2008e-04,  3.4786e-03,  2.1340e-03,
          4.1392e-03, -4.0364e-05,  1.0397e-06,  2.4079e-03, -2.5479e-03,
          5.2265e-03,  4.4978e-03,  1.2404e-03,  2.2006e-03,  8.6338e-04,
          1.9086e-03, -5.0854e-04, -3.8347e-04,  1.6052e-03,  2.7545e-03,
          1.9738e-03,  1.0385e-03,  3.9633e-03,  2.6502e-03, -7.7422e-04,
          2.0466e-03,  1.0691e-05,  1.8594e-03, -2.9587e-04,  8.4402e-04,
          8.3844e-04,  4.3630e-03,  7.5473e-04,  1.2245e-03,  2.2381e-03,
          9.5501e-04, -6.8394e-04,  2.3659e-03,  2.6083e-03,  3.6042e-03,
          2.4228e-03,  6.6466e-03, -3.4501e-04, -1.0976e-03,  1.3984e-03,
          3.7127e-03,  2.5284e-03, -1.3336e-03,  3.7315e-03,  9.5541e-04,
          1.1247e-03,  9.4080e-04,  3.0854e-03,  6.0862e-03,  4.8385e-04,
          1.2427e-03,  4.3413e-03,  2.5282e-03,  5.1836e-03,  4.0414e-03,
          1.3848e-03,  1.3397e-03,  1.9065e-03,  3.8724e-03,  1.5208e-03,
          2.0510e-03,  1.9226e-03,  1.6034e-03,  2.0152e-03,  7.6998e-04,
          9.6069e-04,  1.8157e-03,  1.9644e-04,  5.2841e-04,  1.9583e-03,
          1.9265e-03, -6.9518e-04,  3.9099e-03,  1.4916e-03,  1.4171e-03,
          4.5194e-04,  1.3284e-03,  1.2483e-03,  2.6988e-03, -4.9759e-04,
          1.7591e-03,  5.4391e-04,  3.1815e-03,  2.1783e-05,  2.4603e-03,
          4.9730e-03,  3.5538e-03,  6.7773e-04,  1.4969e-03,  2.4363e-04,
          3.2017e-03,  2.5379e-03,  1.2058e-03, -2.7073e-04,  3.0358e-03,
         -6.8210e-07,  1.5174e-03, -1.7050e-04, -1.7123e-04,  8.5156e-04,
          2.3230e-03, -1.7158e-03]], device='cuda:0')
==> name fc2.bias torch.Size([2]) tensor([-0.0500,  0.0500], device='cuda:0')
tensor([[-1.9620e-02,  1.0787e-01],
        [-3.8082e-02,  1.5118e-01],
        [ 5.4876e-03,  1.2253e-01],
        [-3.4136e-02,  1.0264e-01],
        [-5.1093e-02,  5.9445e-02],
        [-2.8507e-02,  1.0732e-01],
        [-5.5256e-02,  1.4584e-01],
        [-4.8225e-03,  9.9111e-02],
        [-2.0743e-02,  1.1110e-01],
        [-4.5812e-02,  8.6409e-02],
        [-4.3181e-02,  1.0999e-01],
        [-1.4806e-02,  1.3708e-01],
        [-4.5406e-02,  9.4481e-02],
        [-2.8924e-02,  1.1103e-01],
        [-4.1739e-02,  9.8673e-02],
        [-2.5819e-02,  1.0121e-01],
        [-3.2346e-02,  1.2267e-01],
        [-2.7493e-02,  1.0081e-01],
        [-5.4100e-02,  1.0992e-01],
        [ 3.6651e-03,  1.0107e-01],
        [-6.4918e-02,  7.6274e-02],
        [-3.1556e-02,  1.0595e-01],
        [-7.8622e-03,  1.3534e-01],
        [-4.5536e-02,  1.1141e-01],
        [-4.1207e-02,  7.9228e-02],
        [ 1.6686e-03,  7.0902e-02],
        [-5.5900e-02,  1.0763e-01],
        [ 3.5092e-03,  1.3162e-01],
        [ 4.8240e-03,  1.3199e-01],
        [-2.3307e-02,  1.0261e-01],
        [ 5.2392e-03,  1.4372e-01],
        [-3.5858e-02,  1.5943e-01],
        [-1.7499e-02,  8.9634e-02],
        [-4.6817e-02,  9.3701e-02],
        [ 1.8318e-02,  9.0530e-02],
        [-2.2705e-02,  1.1648e-01],
        [-9.7700e-02,  6.9946e-02],
        [-4.6010e-02,  8.7583e-02],
        [-7.1142e-02,  1.6437e-01],
        [-2.8161e-02,  1.2299e-01],
        [-4.1458e-02,  1.1566e-01],
        [-2.9136e-02,  1.1549e-01],
        [-5.5945e-02,  9.5491e-02],
        [-2.3273e-02,  1.1885e-01],
        [-5.8531e-02,  1.3532e-01],
        [-1.3623e-02,  1.5449e-01],
        [ 9.1746e-03,  9.1715e-02],
        [-3.5943e-02,  1.0112e-01],
        [-9.1854e-02,  9.9075e-02],
        [-8.9272e-02,  6.8485e-02],
        [-4.2895e-02,  1.1365e-01],
        [-3.9843e-03,  1.0840e-01],
        [-4.7495e-02,  1.0833e-01],
        [-4.0324e-02,  6.6631e-02],
        [-2.9866e-02,  4.3052e-02],
        [-2.8873e-02,  1.3895e-01],
        [-1.7196e-02,  1.2719e-01],
        [-5.4976e-02,  1.0808e-01],
        [-4.8120e-02,  1.5607e-01],
        [-1.9707e-02,  1.3585e-01],
        [-5.3287e-02,  1.7101e-01],
        [ 1.5720e-02,  1.6282e-01],
        [-1.4124e-04,  1.5080e-01],
        [-2.8114e-02,  1.0826e-01]], device='cuda:0',
       grad_fn=<SqueezeBackward1>)
Iter:     50,  Train Loss:  0.25,  Train Acc: 46.88%,  Val Loss:  0.22,  Val Acc: 48.38%,  Time: 0:00:04 *,  LR: 0.7938926261462523
s_logits tensor([[0.4907, 0.5093],
        [0.4757, 0.5243],
        [0.4689, 0.5311],
        [0.4598, 0.5402],
        [0.4535, 0.5465],
        [0.4798, 0.5202],
        [0.4907, 0.5093],
        [0.4817, 0.5183],
        [0.4859, 0.5141],
        [0.4725, 0.5275],
        [0.4672, 0.5328],
        [0.4840, 0.5160],
        [0.4549, 0.5451],
        [0.4638, 0.5362],
        [0.4604, 0.5396],
        [0.4694, 0.5306],
        [0.4710, 0.5290],
        [0.4739, 0.5261],
        [0.4799, 0.5201],
        [0.4748, 0.5252],
        [0.4844, 0.5156],
        [0.4812, 0.5188],
        [0.4593, 0.5407],
        [0.4686, 0.5314],
        [0.4793, 0.5207],
        [0.4823, 0.5177],
        [0.4695, 0.5305],
        [0.4595, 0.5405],
        [0.4615, 0.5385],
        [0.4630, 0.5370],
        [0.4732, 0.5268],
        [0.4626, 0.5374],
        [0.4679, 0.5321],
        [0.4666, 0.5334],
        [0.4775, 0.5225],
        [0.4762, 0.5238],
        [0.4486, 0.5514],
        [0.4521, 0.5479],
        [0.4766, 0.5234],
        [0.4643, 0.5357],
        [0.4496, 0.5504],
        [0.4595, 0.5405],
        [0.4827, 0.5173],
        [0.4755, 0.5245],
        [0.4557, 0.5443],
        [0.4672, 0.5328],
        [0.4753, 0.5247],
        [0.4748, 0.5252],
        [0.4548, 0.5452],
        [0.4893, 0.5107],
        [0.4567, 0.5433],
        [0.4716, 0.5284],
        [0.4789, 0.5211],
        [0.4771, 0.5229],
        [0.4658, 0.5342],
        [0.4788, 0.5212],
        [0.4745, 0.5255],
        [0.4778, 0.5222],
        [0.4728, 0.5272],
        [0.4883, 0.5117],
        [0.4658, 0.5342],
        [0.4773, 0.5227],
        [0.4556, 0.5444],
        [0.4599, 0.5401]], device='cuda:0', grad_fn=<SoftmaxBackward0>) label tensor([1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1,
        0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1,
        0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0], device='cuda:0')
t_logits tensor([[4.1866e-03, 9.9581e-01],
        [9.9868e-01, 1.3215e-03],
        [3.6225e-03, 9.9638e-01],
        [3.5698e-03, 9.9643e-01],
        [9.9670e-01, 3.3039e-03],
        [2.1083e-02, 9.7892e-01],
        [9.9898e-01, 1.0237e-03],
        [2.1109e-02, 9.7889e-01],
        [9.7855e-01, 2.1445e-02],
        [9.9921e-01, 7.8884e-04],
        [4.6751e-03, 9.9532e-01],
        [9.9860e-01, 1.4011e-03],
        [9.8929e-01, 1.0715e-02],
        [9.9938e-01, 6.2266e-04],
        [9.9847e-01, 1.5339e-03],
        [3.1471e-03, 9.9685e-01],
        [1.9165e-02, 9.8084e-01],
        [2.8864e-03, 9.9711e-01],
        [5.1817e-03, 9.9482e-01],
        [2.3603e-02, 9.7640e-01],
        [9.7834e-01, 2.1663e-02],
        [8.8333e-01, 1.1667e-01],
        [3.4750e-02, 9.6525e-01],
        [7.0595e-03, 9.9294e-01],
        [9.9798e-01, 2.0227e-03],
        [2.2463e-02, 9.7754e-01],
        [3.3341e-02, 9.6666e-01],
        [2.9219e-03, 9.9708e-01],
        [9.8258e-01, 1.7421e-02],
        [9.9854e-01, 1.4592e-03],
        [6.1427e-03, 9.9386e-01],
        [9.9786e-01, 2.1403e-03],
        [7.5784e-03, 9.9242e-01],
        [9.9852e-01, 1.4781e-03],
        [7.6970e-03, 9.9230e-01],
        [6.6992e-03, 9.9330e-01],
        [9.9635e-01, 3.6517e-03],
        [5.7133e-03, 9.9429e-01],
        [9.9774e-01, 2.2599e-03],
        [9.9835e-01, 1.6478e-03],
        [9.9441e-01, 5.5863e-03],
        [9.9693e-01, 3.0675e-03],
        [9.9935e-01, 6.5311e-04],
        [7.7251e-03, 9.9227e-01],
        [1.8652e-02, 9.8135e-01],
        [1.5162e-02, 9.8484e-01],
        [9.8231e-01, 1.7693e-02],
        [9.9216e-01, 7.8383e-03],
        [3.7974e-03, 9.9620e-01],
        [9.9828e-01, 1.7155e-03],
        [9.9938e-01, 6.2141e-04],
        [5.5357e-02, 9.4464e-01],
        [4.0416e-03, 9.9596e-01],
        [9.9898e-01, 1.0150e-03],
        [9.3802e-03, 9.9062e-01],
        [2.8860e-02, 9.7114e-01],
        [7.6876e-02, 9.2312e-01],
        [4.5977e-03, 9.9540e-01],
        [9.9938e-01, 6.1742e-04],
        [7.1329e-03, 9.9287e-01],
        [9.9548e-01, 4.5206e-03],
        [3.4936e-03, 9.9651e-01],
        [9.9664e-01, 3.3613e-03],
        [3.8869e-03, 9.9611e-01]], device='cuda:0')
base_loss tensor(0.6923, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(0.2391, device='cuda:0', grad_fn=<MseLossBackward0>)
==> name Embedding.weight torch.Size([30522, 300]) tensor([[ 4.2895e-06, -4.3078e-06, -9.5901e-06,  ...,  3.3088e-07,
         -4.2810e-06, -3.3753e-06],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]], device='cuda:0')
==> name lstm.weight_ih_l0 torch.Size([1200, 300]) tensor([[ 1.1134e-05, -1.5393e-05, -1.5435e-05,  ...,  3.1746e-05,
         -1.6046e-05, -4.2947e-05],
        [-2.2259e-05,  4.6141e-05,  4.6046e-05,  ..., -1.8878e-05,
          1.7006e-05, -3.6844e-05],
        [-1.4521e-05, -3.9541e-06,  1.3036e-05,  ..., -8.2692e-06,
          7.8398e-06, -5.2756e-05],
        ...,
        [-1.9210e-05,  5.8974e-06, -1.5267e-05,  ...,  3.2718e-05,
         -2.8807e-05,  2.3968e-05],
        [-1.4511e-06, -3.9305e-05, -3.7669e-07,  ..., -2.8350e-05,
         -1.2132e-05,  2.6677e-05],
        [ 2.6646e-05,  1.0596e-05, -4.9879e-05,  ..., -3.5353e-05,
         -9.5918e-06,  1.4179e-05]], device='cuda:0')
==> name lstm.weight_hh_l0 torch.Size([1200, 300]) tensor([[-3.6479e-06, -1.0940e-06,  9.5189e-07,  ..., -8.0461e-06,
          2.8154e-06, -2.2347e-07],
        [ 9.0061e-07, -4.1074e-06,  4.1575e-06,  ..., -3.6206e-06,
          4.4698e-06, -1.7914e-06],
        [ 4.0828e-06,  1.9894e-06,  1.1531e-06,  ...,  4.8708e-06,
          1.1951e-06,  4.2620e-07],
        ...,
        [ 4.4622e-06, -8.7215e-06, -1.2699e-06,  ..., -7.7960e-06,
         -3.7402e-06, -1.6552e-06],
        [ 1.2975e-06,  5.4024e-06,  5.0457e-06,  ...,  8.2990e-06,
          3.0930e-06,  1.2476e-06],
        [ 3.0339e-06, -4.4661e-06,  3.9427e-06,  ..., -4.5608e-06,
          1.2604e-06, -6.0176e-06]], device='cuda:0')
==> name lstm.bias_ih_l0 torch.Size([1200]) tensor([ 1.3994e-06,  3.1864e-06,  4.1229e-05,  ..., -7.8160e-05,
        -1.0436e-05,  2.1306e-05], device='cuda:0')
==> name lstm.bias_hh_l0 torch.Size([1200]) tensor([ 1.3994e-06,  3.1864e-06,  4.1229e-05,  ..., -7.8160e-05,
        -1.0436e-05,  2.1306e-05], device='cuda:0')
==> name lstm.weight_ih_l0_reverse torch.Size([1200, 300]) tensor([[-2.4453e-05,  6.8845e-06, -6.3057e-06,  ...,  1.8058e-05,
         -2.1923e-05, -1.4474e-05],
        [ 1.0830e-04,  5.8390e-05, -1.6178e-05,  ..., -4.7305e-05,
          8.4298e-05, -5.1377e-05],
        [-2.2711e-06,  4.7694e-06, -4.0802e-06,  ...,  2.3284e-06,
         -1.8584e-06,  1.6168e-05],
        ...,
        [ 6.7675e-05,  4.8358e-07, -2.3002e-05,  ...,  3.0601e-05,
          3.3147e-05,  7.3859e-07],
        [ 2.6208e-05,  1.7220e-05, -1.9233e-05,  ...,  2.5989e-06,
          2.2019e-05, -3.7519e-06],
        [-3.6759e-06,  1.7936e-05, -1.6935e-05,  ..., -5.5991e-06,
          2.7520e-05,  4.9674e-05]], device='cuda:0')
==> name lstm.weight_hh_l0_reverse torch.Size([1200, 300]) tensor([[ 4.7319e-07, -3.1432e-07, -2.5765e-06,  ..., -1.5755e-06,
          3.0146e-07, -3.6865e-06],
        [ 2.3800e-06, -1.3784e-06, -3.2332e-06,  ..., -6.9224e-06,
          1.8738e-06,  1.8117e-08],
        [ 1.8032e-06, -2.3583e-07,  8.8701e-07,  ...,  2.8492e-06,
         -3.0774e-07,  4.7480e-06],
        ...,
        [-1.8872e-06,  2.3539e-06, -5.7651e-06,  ..., -7.3550e-06,
         -1.8903e-06, -3.3612e-07],
        [ 1.5521e-06,  7.4449e-08,  2.0907e-06,  ..., -4.6201e-07,
         -3.5754e-07,  1.8727e-06],
        [ 2.7371e-06, -3.1097e-06,  4.3934e-06,  ...,  1.3616e-06,
          4.5727e-06,  3.9348e-06]], device='cuda:0')
==> name lstm.bias_ih_l0_reverse torch.Size([1200]) tensor([-1.0855e-06, -4.0618e-06, -1.7984e-05,  ..., -5.9909e-06,
         8.0564e-06,  1.3974e-05], device='cuda:0')
==> name lstm.bias_hh_l0_reverse torch.Size([1200]) tensor([-1.0855e-06, -4.0618e-06, -1.7984e-05,  ..., -5.9909e-06,
         8.0564e-06,  1.3974e-05], device='cuda:0')
==> name fc1.weight torch.Size([192, 600]) tensor([[ 2.0301e-04, -1.4700e-04,  5.7671e-05,  ..., -1.7737e-04,
         -1.3158e-05, -1.8568e-04],
        [-2.9163e-04,  1.4258e-05,  4.6423e-05,  ..., -1.0018e-04,
          2.3034e-04, -5.4825e-04],
        [-5.9930e-05, -1.7034e-04,  7.2142e-05,  ...,  2.8759e-05,
         -1.6556e-04, -4.3326e-05],
        ...,
        [-1.6169e-04,  2.2280e-04,  1.3857e-04,  ...,  9.0090e-06,
         -1.5415e-05,  1.8953e-04],
        [-1.8912e-05, -9.9823e-05,  7.7406e-05,  ..., -1.8455e-04,
          1.8721e-04,  4.1969e-05],
        [ 4.9470e-05, -9.9140e-05,  2.6651e-04,  ..., -1.2074e-04,
          3.2852e-04, -2.7626e-04]], device='cuda:0')
==> name fc1.bias torch.Size([192]) tensor([ 2.6804e-04, -1.3696e-03, -1.8937e-03, -1.0212e-03,  1.1473e-03,
        -1.2048e-03, -6.0359e-05, -1.1154e-03, -8.7559e-04,  2.6016e-04,
        -1.6834e-03, -3.5295e-04,  9.6643e-04, -9.4344e-04,  1.2715e-03,
        -7.2517e-05,  2.8715e-04,  9.3476e-05,  9.8068e-05, -2.6266e-04,
         1.5458e-03,  1.1444e-03,  3.0824e-04,  1.4749e-05,  9.7378e-04,
         1.0355e-03, -4.0402e-05,  6.8828e-05, -8.2679e-04,  4.5618e-05,
         9.3944e-04,  1.3675e-04,  1.2535e-03,  5.5311e-04,  1.3014e-03,
         7.5817e-04, -1.9041e-04, -2.7130e-05,  4.7845e-04, -6.6082e-04,
        -2.6660e-04,  4.2534e-04, -4.6335e-04, -2.0125e-04, -3.4367e-05,
        -3.0162e-05, -7.8862e-04, -5.7853e-05,  1.2130e-03, -6.2471e-04,
         4.8944e-04,  1.4308e-03,  3.5488e-04, -3.4202e-04,  2.3002e-03,
         4.7772e-04,  9.8553e-04,  6.6594e-04,  7.7836e-05,  2.9573e-04,
         4.1550e-05,  4.0024e-04, -8.4700e-04, -2.2348e-04,  6.8938e-04,
        -9.3474e-04, -3.6607e-04,  4.7452e-04,  9.8718e-05,  3.2422e-04,
        -1.3678e-03, -8.4741e-04,  6.1592e-04, -7.0493e-04,  1.9678e-03,
        -9.5356e-04,  1.0771e-04,  1.4639e-04, -6.8016e-05, -8.1459e-04,
         9.2247e-04, -8.2435e-04,  9.0646e-04,  6.2285e-04, -9.0610e-04,
         3.5809e-04, -2.9856e-04,  7.5814e-04,  4.1425e-06,  5.2673e-04,
         1.0024e-03,  5.6583e-04,  2.9014e-05,  6.1874e-04,  2.8658e-03,
        -5.1512e-04,  6.8806e-04,  1.5276e-03,  1.2757e-03,  4.3942e-04,
         2.4444e-04, -3.8341e-04, -4.0358e-04, -3.9504e-05, -3.7649e-04,
        -7.5881e-04, -3.7871e-04, -1.2840e-04, -7.9477e-04, -1.0716e-03,
        -1.5033e-05,  2.8605e-03, -6.5885e-04, -6.1931e-05,  1.1431e-04,
         1.6431e-04, -3.9089e-04,  1.7436e-03,  2.4852e-03,  7.1867e-05,
        -2.2096e-04, -1.1486e-04, -1.9589e-04,  3.2916e-04, -1.2428e-03,
        -9.3186e-04,  6.3893e-04,  4.4526e-04, -1.8735e-04, -6.3833e-04,
        -2.6428e-04,  4.1223e-04, -7.6234e-05, -4.1236e-05,  1.7956e-03,
        -1.1166e-04,  1.5210e-03, -1.1523e-03, -1.1020e-03, -1.7096e-03,
        -1.5896e-03,  4.3862e-04,  1.5678e-04, -1.2256e-03, -1.3399e-03,
         1.4485e-03, -6.8624e-04, -4.6679e-04,  4.2027e-04, -1.1719e-03,
        -8.9521e-04, -7.7877e-04, -2.7011e-04,  5.7420e-05, -5.8158e-04,
         2.7828e-04,  9.3046e-05, -7.1943e-04, -2.8942e-04,  1.3292e-06,
         1.9218e-03, -5.0853e-04,  2.1496e-03,  2.0133e-04, -2.7017e-04,
         2.9994e-04,  4.0682e-04, -9.8199e-04,  6.6435e-04,  5.1220e-04,
        -2.8518e-04, -1.3830e-03,  8.3347e-04,  1.8714e-05,  8.9544e-04,
         1.1211e-04,  4.8084e-04, -1.2791e-03,  1.1755e-03,  1.8717e-04,
         5.8020e-04, -3.2698e-05, -1.5131e-03, -5.4591e-04,  1.6628e-03,
        -1.3104e-04, -2.7888e-04,  8.6090e-05, -4.4568e-05,  8.7775e-04,
        -5.1841e-04, -2.2506e-04], device='cuda:0')
==> name fc2.weight torch.Size([2, 192]) tensor([[ 4.1003e-04, -1.7851e-03, -2.5668e-04, -1.7393e-03, -2.5270e-03,
          8.4097e-04,  9.2676e-04, -4.8626e-04,  8.7177e-04, -5.2457e-04,
          2.3321e-03, -6.8572e-04,  7.7860e-04, -6.6594e-04, -3.9696e-04,
          1.8910e-03, -6.0246e-05,  3.0891e-04,  4.1008e-04,  4.1254e-03,
          3.7830e-04, -4.1347e-04,  3.6234e-04, -3.7417e-05, -1.7689e-03,
          7.8294e-04,  4.5529e-04, -1.2183e-03, -1.0980e-03,  2.1514e-04,
          9.6498e-04, -5.5540e-04, -2.0414e-03, -6.3912e-04,  1.9610e-03,
          9.3375e-04,  4.2196e-04, -1.4383e-03,  4.4170e-04, -1.1074e-03,
          7.6809e-04,  5.7811e-04, -2.5802e-04, -3.7789e-03,  2.7816e-03,
          4.7136e-04, -2.3133e-04, -2.3570e-03, -3.9887e-04,  3.1424e-04,
          1.0718e-03, -3.3904e-03,  1.6114e-03,  1.6755e-04,  1.2222e-03,
         -2.8671e-03, -1.6763e-03,  4.0214e-03,  1.4907e-04, -6.1909e-04,
         -1.3492e-03, -2.8216e-04, -1.7529e-03,  6.2822e-04,  2.1615e-03,
         -8.2277e-04, -8.2618e-04, -6.6277e-04,  3.8007e-05,  1.0101e-03,
          1.1766e-03,  3.5281e-03,  3.7938e-03,  9.3148e-04,  1.9434e-03,
          2.2254e-03,  2.0148e-03, -1.7278e-03,  1.2287e-03,  4.1496e-04,
         -1.9630e-04, -1.2134e-03,  1.3549e-03,  5.1591e-04, -2.7421e-03,
          1.3164e-03, -3.6468e-04,  4.6083e-04,  1.6047e-04, -1.9064e-03,
         -1.7411e-03, -5.0042e-04,  2.4022e-03, -3.2909e-03,  3.1611e-03,
          1.6152e-03,  2.4979e-03,  2.2324e-03, -6.4844e-05, -9.0581e-04,
          2.0702e-03, -1.2871e-03,  8.9530e-05, -1.1407e-03, -2.9652e-04,
          7.5306e-05, -1.6306e-04, -1.5368e-03,  1.3996e-03,  3.4659e-04,
         -1.2501e-03, -1.6907e-03,  1.8263e-03,  5.7125e-04,  1.1062e-03,
         -1.7622e-03,  3.7122e-03, -2.5990e-04,  3.5797e-03, -2.7503e-03,
          4.3327e-04, -8.6467e-04, -1.1315e-04,  4.4025e-04,  2.2228e-03,
          9.1643e-04,  5.8658e-04,  1.1348e-03, -3.2655e-04,  1.1931e-03,
         -1.0197e-03, -6.8272e-04,  1.4254e-03, -1.5122e-03, -2.0717e-03,
          1.8554e-03,  8.9320e-04, -8.6805e-04,  1.7449e-03,  4.3289e-04,
          2.3432e-03,  7.1709e-04,  2.4148e-04, -5.0016e-03,  1.3420e-03,
         -1.7999e-03, -1.1919e-04,  1.5809e-03, -3.9597e-04, -7.1645e-05,
         -5.6565e-03, -3.1464e-04,  1.1180e-03, -1.3625e-03, -2.4241e-04,
         -9.6017e-04, -6.4064e-04, -1.3625e-05, -2.1361e-03, -4.4721e-04,
         -2.2681e-04, -9.1340e-04,  8.7661e-04,  2.5376e-04, -3.7342e-03,
          8.0380e-04, -5.4483e-06, -3.8425e-03,  1.4955e-03,  5.2409e-04,
          1.7870e-04,  7.6894e-04, -9.3968e-04,  1.5525e-03, -1.0677e-03,
         -2.5287e-03,  6.9710e-04, -4.5209e-03,  1.0202e-03, -1.2248e-03,
          1.6260e-03,  1.3887e-03,  9.7097e-04,  2.9589e-04,  3.8819e-03,
         -1.9278e-04, -3.3081e-03,  1.2031e-03,  2.7545e-04, -2.7551e-03,
          2.2443e-04, -7.5297e-04],
        [ 2.8649e-04,  7.7246e-04, -3.4579e-03,  3.0258e-03, -1.2507e-03,
          1.7129e-03,  3.4222e-04, -6.3063e-04,  4.7038e-04, -2.0493e-03,
          2.0569e-03, -1.7213e-04,  1.0761e-03, -5.3754e-04, -1.7272e-05,
          1.0526e-03,  1.5592e-03,  1.7258e-05,  3.1615e-04, -1.3218e-03,
          8.3656e-04,  1.3009e-03,  5.0671e-04, -2.9529e-04, -2.6306e-03,
         -1.0592e-03, -1.0146e-03,  5.7078e-04,  3.9649e-04,  4.7447e-04,
         -1.3812e-03, -2.5425e-03,  3.9208e-04, -4.6355e-04, -1.1757e-03,
         -4.3254e-04, -1.3659e-05,  2.2303e-03,  2.8990e-04,  1.5059e-03,
         -5.5366e-04,  5.7808e-04,  3.3523e-04, -8.1001e-04, -1.6587e-05,
         -1.6545e-03,  2.2868e-04,  1.2803e-04,  1.9911e-03,  1.1970e-03,
          1.7120e-03,  7.8303e-04, -1.0852e-03,  6.3524e-06, -9.9510e-04,
         -9.4758e-04, -1.5923e-04, -7.7155e-04,  7.2328e-04, -3.4690e-04,
          1.5532e-04,  2.3480e-03,  2.3871e-03, -2.9310e-03,  1.6608e-04,
         -8.9273e-04,  1.3815e-03,  4.1642e-04,  1.4032e-04, -5.5690e-04,
          8.2048e-04, -1.4121e-03, -2.0060e-03, -2.6231e-03, -9.1187e-04,
          5.1288e-04, -6.5559e-04,  2.4018e-03, -3.5761e-05,  3.5662e-04,
         -4.4033e-03, -1.9403e-03, -5.2401e-04,  5.0021e-04, -1.4171e-03,
         -9.4423e-04, -2.5480e-03, -3.4626e-03, -9.5773e-04,  1.9099e-04,
          8.7203e-04, -1.1180e-03,  5.7646e-04,  7.1518e-04,  4.9688e-04,
         -2.7495e-04,  9.5931e-04, -9.2760e-04,  1.3519e-04, -1.1769e-03,
          2.1669e-03,  6.2149e-04, -7.1897e-04,  2.5060e-04,  1.4182e-03,
         -9.9158e-04,  1.8742e-03,  4.4056e-04, -6.7540e-04,  2.1701e-03,
         -2.4742e-04,  6.6889e-04, -4.2388e-04,  1.8827e-04, -1.0478e-03,
         -7.5006e-05, -1.2526e-03,  2.4819e-03,  8.9028e-04, -1.5679e-03,
         -5.7028e-04, -6.7103e-04, -1.8542e-04,  7.8099e-04, -6.8666e-04,
         -1.6705e-03,  2.6385e-03, -2.3459e-04,  1.1214e-03,  2.9052e-03,
          1.4230e-04, -3.6303e-04,  1.2709e-03, -1.5030e-03,  1.4037e-03,
         -1.4349e-03, -2.6687e-03,  1.6775e-03,  2.0570e-04, -1.5173e-03,
         -4.6811e-04, -3.1389e-04, -2.7954e-04, -8.7084e-04,  4.0897e-04,
          3.5389e-04, -8.0853e-04, -3.5066e-04, -5.1361e-04, -1.8245e-03,
          5.6759e-04,  1.8659e-03, -5.2503e-04, -6.7869e-05,  8.3434e-04,
          4.3464e-04, -5.2097e-04,  1.2080e-03,  2.7104e-04, -7.7555e-04,
         -3.0035e-03,  1.2778e-03,  5.6890e-04,  1.8033e-03, -2.0053e-04,
          1.4440e-03, -3.5548e-04,  1.6366e-05,  1.0149e-03, -8.0819e-04,
          9.8538e-04,  2.8083e-04,  1.1123e-03, -2.9368e-04,  1.0220e-06,
         -1.7655e-05, -5.6363e-04, -1.0842e-04, -1.4002e-03,  1.4698e-03,
         -6.0496e-04,  1.5043e-03, -6.0121e-04, -5.5235e-04,  1.3940e-03,
          1.3940e-03, -4.8387e-04, -1.9310e-03, -1.3251e-04, -8.3994e-04,
          1.1910e-03, -5.2275e-04]], device='cuda:0')
==> name fc2.bias torch.Size([2]) tensor([-0.0007,  0.0007], device='cuda:0')
tensor([[ 0.0169,  0.0541],
        [ 0.0269,  0.1242],
        [-0.0512,  0.0734],
        [-0.0461,  0.1150],
        [-0.0554,  0.1312],
        [ 0.0087,  0.0896],
        [ 0.0510,  0.0884],
        [-0.0219,  0.0514],
        [ 0.0280,  0.0845],
        [-0.0343,  0.0759],
        [-0.0117,  0.1196],
        [ 0.0093,  0.0734],
        [-0.0186,  0.1624],
        [-0.0390,  0.1062],
        [-0.0108,  0.1479],
        [ 0.0258,  0.1483],
        [ 0.0625,  0.1787],
        [-0.0071,  0.0975],
        [ 0.0375,  0.1178],
        [-0.0414,  0.0594],
        [-0.0089,  0.0536],
        [-0.0033,  0.0720],
        [-0.0291,  0.1342],
        [-0.0474,  0.0785],
        [-0.0574,  0.0256],
        [ 0.0049,  0.0757],
        [-0.0508,  0.0713],
        [-0.0712,  0.0910],
        [-0.0596,  0.0946],
        [-0.0508,  0.0973],
        [-0.0550,  0.0522],
        [ 0.0139,  0.1638],
        [-0.0174,  0.1110],
        [-0.0279,  0.1060],
        [ 0.0445,  0.1344],
        [-0.0204,  0.0750],
        [-0.0461,  0.1601],
        [-0.0409,  0.1514],
        [-0.0583,  0.0354],
        [-0.0229,  0.1200],
        [-0.0328,  0.1693],
        [-0.0469,  0.1153],
        [ 0.0138,  0.0830],
        [ 0.0115,  0.1097],
        [ 0.0153,  0.1928],
        [-0.0421,  0.0893],
        [-0.0575,  0.0414],
        [-0.0145,  0.0862],
        [-0.0261,  0.1554],
        [ 0.0224,  0.0654],
        [-0.0461,  0.1277],
        [-0.0423,  0.0713],
        [ 0.0083,  0.0927],
        [-0.0210,  0.0708],
        [-0.0089,  0.1282],
        [-0.0324,  0.0524],
        [ 0.0211,  0.1231],
        [-0.0206,  0.0683],
        [ 0.0206,  0.1293],
        [ 0.0661,  0.1131],
        [-0.0306,  0.1063],
        [-0.0253,  0.0654],
        [-0.0420,  0.1362],
        [-0.0139,  0.1469]], device='cuda:0', grad_fn=<SqueezeBackward1>)
Iter:    100,  Train Loss:  0.24,  Train Acc: 56.25%,  Val Loss:  0.22,  Val Acc: 49.92%,  Time: 0:00:06 *,  LR: 0.2966316784620994
Epoch [2/30]
s_logits tensor([[0.4699, 0.5301],
        [0.4508, 0.5492],
        [0.4556, 0.5444],
        [0.4693, 0.5307],
        [0.4565, 0.5435],
        [0.4694, 0.5306],
        [0.4425, 0.5575],
        [0.4886, 0.5114],
        [0.4468, 0.5532],
        [0.4503, 0.5497],
        [0.4674, 0.5326],
        [0.4692, 0.5308],
        [0.4697, 0.5303],
        [0.4802, 0.5198],
        [0.4963, 0.5037],
        [0.4816, 0.5184],
        [0.4613, 0.5387],
        [0.4819, 0.5181],
        [0.4673, 0.5327],
        [0.4528, 0.5472],
        [0.4596, 0.5404],
        [0.4744, 0.5256],
        [0.4631, 0.5369],
        [0.4830, 0.5170],
        [0.5146, 0.4854],
        [0.4755, 0.5245],
        [0.4712, 0.5288],
        [0.4671, 0.5329],
        [0.4766, 0.5234],
        [0.4754, 0.5246],
        [0.4642, 0.5358],
        [0.4728, 0.5272],
        [0.4918, 0.5082],
        [0.4676, 0.5324],
        [0.4721, 0.5279],
        [0.5007, 0.4993],
        [0.4552, 0.5448],
        [0.4726, 0.5274],
        [0.4804, 0.5196],
        [0.4589, 0.5411],
        [0.4628, 0.5372],
        [0.4547, 0.5453],
        [0.4808, 0.5192],
        [0.4708, 0.5292],
        [0.4638, 0.5362],
        [0.4699, 0.5301],
        [0.4812, 0.5188],
        [0.4806, 0.5194],
        [0.4768, 0.5232],
        [0.4740, 0.5260],
        [0.4661, 0.5339],
        [0.4702, 0.5298],
        [0.4736, 0.5264],
        [0.4947, 0.5053],
        [0.4770, 0.5230],
        [0.4795, 0.5205],
        [0.4830, 0.5170],
        [0.4724, 0.5276],
        [0.4798, 0.5202],
        [0.4667, 0.5333],
        [0.4504, 0.5496],
        [0.4633, 0.5367],
        [0.4688, 0.5312],
        [0.4632, 0.5368]], device='cuda:0', grad_fn=<SoftmaxBackward0>) label tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1,
        1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1], device='cuda:0')
t_logits tensor([[8.1666e-03, 9.9183e-01],
        [9.9921e-01, 7.9013e-04],
        [3.3586e-01, 6.6414e-01],
        [9.9874e-01, 1.2649e-03],
        [9.9543e-01, 4.5695e-03],
        [6.5895e-03, 9.9341e-01],
        [5.1427e-03, 9.9486e-01],
        [3.1161e-03, 9.9688e-01],
        [5.5556e-03, 9.9444e-01],
        [3.5193e-03, 9.9648e-01],
        [2.9431e-02, 9.7057e-01],
        [9.9921e-01, 7.8535e-04],
        [3.0449e-03, 9.9696e-01],
        [9.9888e-01, 1.1170e-03],
        [4.0080e-03, 9.9599e-01],
        [1.0628e-02, 9.8937e-01],
        [1.1172e-02, 9.8883e-01],
        [9.9216e-01, 7.8411e-03],
        [6.1694e-03, 9.9383e-01],
        [7.4154e-03, 9.9258e-01],
        [9.8738e-01, 1.2616e-02],
        [9.9357e-01, 6.4350e-03],
        [9.9669e-01, 3.3058e-03],
        [2.0594e-02, 9.7941e-01],
        [9.9654e-01, 3.4634e-03],
        [9.9948e-01, 5.1982e-04],
        [9.9945e-01, 5.5318e-04],
        [2.1315e-02, 9.7868e-01],
        [4.0183e-03, 9.9598e-01],
        [1.5797e-02, 9.8420e-01],
        [1.5271e-02, 9.8473e-01],
        [9.9924e-01, 7.5767e-04],
        [6.5296e-03, 9.9347e-01],
        [9.9838e-01, 1.6195e-03],
        [4.2043e-03, 9.9580e-01],
        [9.9944e-01, 5.6369e-04],
        [6.0282e-03, 9.9397e-01],
        [9.9830e-01, 1.6955e-03],
        [9.9953e-01, 4.7178e-04],
        [3.1116e-02, 9.6888e-01],
        [9.9932e-01, 6.7784e-04],
        [9.9927e-01, 7.3154e-04],
        [3.5414e-02, 9.6459e-01],
        [9.9934e-01, 6.5629e-04],
        [9.9645e-01, 3.5453e-03],
        [6.2262e-03, 9.9377e-01],
        [4.8790e-03, 9.9512e-01],
        [5.6165e-03, 9.9438e-01],
        [5.0370e-03, 9.9496e-01],
        [5.3949e-03, 9.9461e-01],
        [3.6996e-03, 9.9630e-01],
        [9.9669e-01, 3.3065e-03],
        [9.9896e-01, 1.0432e-03],
        [9.9936e-01, 6.4149e-04],
        [2.8940e-01, 7.1060e-01],
        [3.3104e-03, 9.9669e-01],
        [9.9692e-01, 3.0811e-03],
        [9.9936e-01, 6.3563e-04],
        [9.9824e-01, 1.7643e-03],
        [2.5674e-02, 9.7433e-01],
        [9.9875e-01, 1.2533e-03],
        [8.3294e-03, 9.9167e-01],
        [9.9885e-01, 1.1472e-03],
        [9.9931e-01, 6.9159e-04]], device='cuda:0')
base_loss tensor(0.6965, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(0.2361, device='cuda:0', grad_fn=<MseLossBackward0>)
==> name Embedding.weight torch.Size([30522, 300]) tensor([[ 5.1109e-07, -2.9937e-06, -3.4041e-06,  ..., -5.6525e-06,
          2.3740e-06,  2.1891e-06],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]], device='cuda:0')
==> name lstm.weight_ih_l0 torch.Size([1200, 300]) tensor([[ 2.9538e-05, -8.7266e-06,  1.0440e-05,  ...,  2.6004e-05,
         -1.9205e-05, -7.6822e-06],
        [-1.3901e-06,  2.6676e-05,  1.1234e-05,  ..., -6.6206e-06,
         -5.1461e-06,  4.0665e-05],
        [ 1.0873e-05,  1.1484e-05, -5.7442e-06,  ...,  2.9802e-06,
          2.2464e-05, -1.0287e-05],
        ...,
        [-3.3658e-06,  2.2897e-05, -1.9639e-05,  ..., -2.5442e-05,
         -1.9817e-05,  2.8603e-05],
        [ 2.2341e-05, -4.7929e-06, -1.6094e-06,  ...,  7.1778e-07,
          2.8469e-06, -2.3499e-06],
        [-3.2211e-05,  2.2418e-05, -5.1831e-05,  ...,  4.3869e-06,
          3.4797e-06, -8.3368e-06]], device='cuda:0')
==> name lstm.weight_hh_l0 torch.Size([1200, 300]) tensor([[-3.2501e-06, -3.1772e-07, -1.6246e-06,  ...,  2.0681e-07,
         -2.7705e-06,  1.7819e-06],
        [ 6.4633e-06,  2.1501e-06,  4.6445e-07,  ...,  6.2749e-06,
          1.2831e-06, -2.8199e-06],
        [-1.5500e-06,  2.6979e-06, -5.3569e-06,  ...,  2.2027e-06,
         -1.1295e-06, -2.1183e-06],
        ...,
        [ 4.8234e-07,  3.0707e-07,  1.5708e-06,  ...,  6.8485e-06,
          4.8836e-07, -6.5982e-08],
        [-3.9179e-07, -2.5526e-06,  2.2946e-06,  ..., -1.7930e-06,
         -3.7656e-06,  5.8275e-06],
        [ 1.1941e-05, -8.1941e-07,  4.1530e-06,  ...,  6.6603e-06,
          1.4906e-06, -3.6335e-06]], device='cuda:0')
==> name lstm.bias_ih_l0 torch.Size([1200]) tensor([-1.1080e-05,  2.9206e-05, -2.4648e-06,  ...,  4.2950e-06,
        -1.7629e-05, -7.7947e-06], device='cuda:0')
==> name lstm.bias_hh_l0 torch.Size([1200]) tensor([-1.1080e-05,  2.9206e-05, -2.4648e-06,  ...,  4.2950e-06,
        -1.7629e-05, -7.7947e-06], device='cuda:0')
==> name lstm.weight_ih_l0_reverse torch.Size([1200, 300]) tensor([[ 2.8607e-06,  2.4475e-06,  2.5438e-06,  ..., -2.3203e-07,
         -4.1370e-05,  1.2016e-05],
        [-2.7342e-05, -1.6908e-05,  1.8750e-05,  ...,  2.1878e-06,
          1.0363e-05, -1.3360e-05],
        [ 7.6816e-06, -5.1974e-06,  9.9380e-06,  ..., -4.8184e-05,
         -8.2954e-06,  4.3030e-05],
        ...,
        [-1.5780e-05,  7.0695e-07,  3.6964e-06,  ..., -2.5147e-05,
         -1.8339e-05,  3.3414e-05],
        [-1.0596e-05, -2.2335e-05, -8.0398e-06,  ..., -9.1166e-06,
         -2.7406e-06,  1.5748e-05],
        [-2.4265e-05, -3.9579e-05, -8.9222e-06,  ...,  4.3291e-05,
         -2.8184e-05,  2.0223e-05]], device='cuda:0')
==> name lstm.weight_hh_l0_reverse torch.Size([1200, 300]) tensor([[-1.2966e-06,  1.3081e-06, -6.1040e-07,  ..., -2.2480e-06,
          1.1648e-06,  4.7854e-06],
        [-5.8339e-06,  1.0056e-05,  5.0462e-06,  ..., -6.5959e-06,
          6.9281e-07, -3.3091e-06],
        [ 4.2182e-06,  1.1793e-05, -1.7343e-06,  ...,  9.1624e-06,
          5.3881e-06, -9.7731e-06],
        ...,
        [ 8.9112e-07,  7.5139e-09, -5.2177e-06,  ..., -2.2168e-06,
          5.6978e-07,  1.5090e-06],
        [ 5.9920e-10, -1.6483e-06, -6.9056e-07,  ..., -4.2409e-08,
          2.9971e-06, -2.6406e-06],
        [-2.2591e-06, -4.6779e-06, -1.6591e-06,  ..., -1.2312e-06,
         -5.0668e-07, -1.6799e-06]], device='cuda:0')
==> name lstm.bias_ih_l0_reverse torch.Size([1200]) tensor([-4.8907e-05,  3.9894e-05,  4.1635e-05,  ...,  7.6328e-06,
         3.8950e-05,  2.2690e-06], device='cuda:0')
==> name lstm.bias_hh_l0_reverse torch.Size([1200]) tensor([-4.8907e-05,  3.9894e-05,  4.1635e-05,  ...,  7.6328e-06,
         3.8950e-05,  2.2690e-06], device='cuda:0')
==> name fc1.weight torch.Size([192, 600]) tensor([[ 1.5169e-04,  6.4668e-05,  1.1504e-04,  ...,  1.3239e-06,
          2.4247e-04,  5.4602e-05],
        [ 2.7282e-04,  2.4179e-04,  2.7967e-04,  ..., -3.3545e-05,
          3.9847e-04, -2.6847e-04],
        [ 2.2833e-04,  7.0747e-05,  4.1297e-06,  ...,  1.1837e-05,
         -1.5070e-04, -1.6023e-04],
        ...,
        [-9.7638e-06, -1.8980e-04, -1.6549e-04,  ...,  9.4843e-05,
         -2.5317e-04,  8.8996e-05],
        [ 4.7193e-05,  6.1357e-05,  4.2013e-05,  ..., -4.6359e-05,
          1.5686e-04, -1.2856e-04],
        [ 1.1632e-04,  7.0101e-05,  1.6734e-04,  ..., -1.0320e-04,
          1.9556e-04, -1.1638e-04]], device='cuda:0')
==> name fc1.bias torch.Size([192]) tensor([ 5.1887e-04, -1.6174e-03, -3.4017e-04, -2.0641e-04,  9.1961e-04,
        -4.5350e-04,  9.0073e-05,  6.7562e-04,  2.0444e-04, -1.4637e-04,
        -4.3915e-04, -4.0543e-04,  2.9290e-04, -7.5391e-04, -7.3623e-04,
        -5.6930e-05, -2.0117e-04,  1.9428e-04,  1.0372e-04, -9.1228e-04,
         1.1664e-03, -8.7790e-04,  1.5873e-03,  6.7994e-05, -2.5656e-04,
         3.8412e-04,  9.0193e-04, -3.5171e-04, -4.5155e-04,  1.4839e-04,
        -4.7972e-04,  1.4828e-03, -4.5939e-04, -4.4711e-04,  3.4465e-04,
         3.1654e-04,  3.9458e-04,  3.0122e-04, -7.2930e-04, -1.4711e-03,
        -7.7028e-04, -1.6808e-04, -4.4888e-04, -3.6342e-04, -2.4151e-04,
        -1.9953e-03, -3.8886e-04, -8.0793e-04, -5.3671e-04, -1.2498e-03,
         2.0620e-04,  9.3359e-04,  7.1391e-04,  1.0382e-03,  1.9201e-03,
         1.9664e-05, -2.9577e-04,  1.8796e-04, -4.0428e-05, -9.2016e-04,
        -8.4793e-05, -6.1275e-04,  6.8689e-05, -4.0254e-04, -1.1724e-03,
         1.5658e-04, -1.0473e-04,  9.1445e-04,  2.3563e-04, -5.2315e-04,
         2.4739e-04, -4.6754e-05,  7.5116e-04, -4.3469e-04, -3.9164e-05,
        -1.8303e-04,  1.1419e-04,  8.9662e-04,  8.6101e-05, -2.1519e-03,
        -4.7693e-05,  2.1678e-04, -8.3278e-05,  6.2502e-04,  1.0982e-03,
        -1.5314e-04,  1.8781e-04, -6.5456e-04, -9.7057e-04,  2.9108e-04,
         2.2090e-04,  1.0273e-03,  3.4503e-04,  7.5603e-04,  3.1562e-04,
         1.3966e-04,  1.3428e-03, -2.6842e-04,  1.4149e-04,  1.3244e-05,
         1.7653e-04, -2.0334e-05,  4.3464e-04, -1.1228e-03, -3.5580e-04,
        -4.2012e-05,  1.8538e-03,  5.7607e-04, -6.5207e-04,  1.2464e-03,
        -4.1243e-04, -2.2254e-03, -1.1031e-04, -1.3018e-04, -3.7074e-04,
        -6.2116e-04,  1.7040e-05,  1.3872e-03,  5.6748e-04, -5.9945e-05,
        -3.2681e-03, -2.6099e-04,  3.4378e-04,  5.1178e-04,  6.6595e-07,
         1.5403e-03, -1.1606e-04, -1.7805e-04, -1.5491e-03, -4.1470e-04,
        -1.4259e-04, -4.4032e-04, -2.1772e-04,  2.7569e-05,  7.3928e-05,
         9.7940e-04, -1.1430e-03, -7.3060e-04, -1.8269e-04, -3.4337e-04,
         1.4696e-03, -4.1401e-04,  8.8610e-04, -4.1951e-06, -1.6007e-03,
         3.2013e-04, -3.9893e-04, -1.6137e-05, -1.1376e-03,  3.3208e-04,
        -1.2161e-04, -3.4085e-04, -1.8862e-04,  6.0508e-04,  2.6785e-04,
         2.1201e-04,  5.8186e-04,  1.2385e-03,  9.6222e-04,  8.5699e-04,
        -2.0041e-03, -2.0064e-04,  1.0301e-04, -5.5670e-04, -8.4769e-04,
        -2.5948e-04, -7.0369e-05, -1.1179e-03,  1.4722e-04,  1.7828e-03,
         6.2924e-04,  4.1933e-04,  6.3417e-04,  1.9661e-04, -8.5799e-04,
         2.9117e-05,  2.4820e-04,  2.6940e-04,  2.6273e-04,  7.1407e-04,
        -9.5053e-04,  6.5576e-04,  9.7982e-04, -4.4192e-04,  2.6801e-04,
         2.0619e-04,  3.3815e-04, -3.0583e-04,  2.9732e-04, -5.7073e-04,
        -2.7038e-04,  6.4825e-04], device='cuda:0')
==> name fc2.weight torch.Size([2, 192]) tensor([[ 1.0039e-03, -1.1587e-03,  2.1375e-04,  5.3327e-04, -1.1424e-03,
         -8.9570e-04,  2.1679e-04, -7.3676e-04, -1.5854e-04,  1.2471e-03,
          7.1351e-04,  2.0531e-03, -1.7691e-03, -8.0522e-04, -2.3581e-03,
         -4.1970e-04,  1.5978e-04,  1.5900e-04,  3.3731e-04, -3.0590e-03,
          1.1869e-03,  9.1032e-05,  1.3800e-04,  1.1631e-03,  3.0448e-03,
          3.8991e-04,  3.6372e-04, -5.5915e-04, -2.2659e-03, -1.2969e-04,
         -1.0738e-03,  5.7826e-04,  1.5625e-03,  1.0711e-03, -5.7219e-04,
         -1.8515e-04,  1.1142e-03, -2.5288e-03,  4.6285e-04, -3.0486e-03,
          9.9918e-04,  1.5688e-03,  2.6713e-03, -1.8725e-03, -2.0208e-04,
         -4.1714e-04, -6.5882e-04, -5.1339e-04,  7.7247e-04, -1.2122e-03,
          1.0478e-03, -2.5368e-03,  8.2357e-04,  2.1989e-03,  2.7500e-03,
         -1.3418e-03, -1.5047e-03,  3.5788e-04, -2.2512e-03,  2.6732e-04,
         -1.8832e-04, -1.5624e-03, -1.1414e-03,  1.1938e-04,  1.9244e-03,
          1.8310e-03,  1.7244e-03, -1.3816e-03,  2.7161e-04, -1.5599e-03,
         -5.2565e-04,  2.5174e-04, -1.2621e-03, -6.3481e-04,  5.5840e-05,
         -1.7439e-03,  1.7155e-03, -6.1065e-04,  1.4176e-03,  1.4175e-03,
         -1.2566e-03, -1.5342e-03, -2.3960e-04,  1.8887e-03,  5.1703e-05,
         -6.1670e-05, -1.5579e-03,  1.3519e-04, -2.2427e-04, -1.1367e-03,
          1.1115e-03, -9.0533e-04,  8.0555e-05, -2.1167e-03, -1.3928e-03,
         -1.5621e-03,  1.5362e-03, -2.4000e-05,  1.0274e-04, -1.4278e-03,
         -4.6115e-04, -9.6383e-04,  2.0259e-03,  1.2325e-03, -4.7994e-04,
          7.4441e-04,  1.3236e-03,  3.1140e-05,  1.4101e-03,  1.3355e-03,
         -8.5969e-04,  4.4883e-04,  1.3180e-03, -5.6390e-04, -7.7154e-04,
         -7.9804e-04,  2.0541e-03,  5.3026e-04,  8.7902e-04, -1.1700e-03,
         -2.0984e-03, -5.1745e-05, -8.5713e-04, -1.4185e-03,  1.0406e-03,
         -6.6553e-04, -1.5462e-04,  5.5426e-04,  1.0779e-03,  9.7574e-04,
         -2.3676e-03, -8.5905e-04, -1.9207e-03,  4.1776e-04,  9.3451e-04,
         -1.5072e-03,  6.5093e-04,  2.2854e-03,  8.9238e-04,  3.3579e-04,
          3.8993e-04,  1.9168e-04,  4.9628e-04, -2.5741e-03, -1.1073e-03,
          6.8720e-04,  3.1319e-04,  2.5522e-03,  1.4039e-03, -6.3011e-04,
         -1.8413e-03,  1.0470e-03, -6.8893e-04, -3.2653e-03,  5.8914e-04,
         -2.6307e-05, -5.9981e-04,  3.0750e-03, -9.8649e-04, -1.1271e-03,
         -1.7952e-03,  3.0555e-04,  2.6237e-04, -2.5670e-03, -3.7551e-03,
          4.6197e-04,  1.6405e-03, -1.3298e-03,  3.3153e-05, -1.0062e-03,
         -1.1370e-03, -1.7913e-03,  2.4056e-05,  8.1597e-04,  2.0057e-04,
         -2.9867e-03, -8.0246e-04, -2.6573e-03, -1.4371e-03, -9.2468e-04,
         -1.6867e-03, -2.8074e-04, -1.8897e-03,  1.6246e-03,  2.8055e-03,
          1.3945e-03, -9.3832e-04,  6.2299e-04,  1.0941e-03,  2.0902e-03,
         -1.3390e-03,  1.1770e-03],
        [-9.4390e-05, -1.0729e-03, -2.5893e-04, -1.5264e-03,  9.2915e-05,
          1.0815e-03,  8.5908e-04,  2.2908e-03,  3.5516e-04,  7.2370e-04,
          5.1931e-04, -4.7434e-04,  1.3728e-03,  2.0921e-04, -1.4033e-03,
          4.6644e-05, -5.2135e-04, -9.0661e-04,  9.5042e-04,  1.2416e-03,
          5.8894e-04, -1.2142e-03,  8.8701e-04, -7.7844e-05, -3.8826e-04,
          2.9341e-04,  4.8494e-04, -8.0077e-04,  7.4322e-04, -2.0857e-04,
         -1.4400e-03,  2.1109e-03, -4.0077e-05,  5.6758e-04,  1.6402e-03,
          6.8955e-04, -1.8814e-03,  2.9283e-03,  7.8771e-04, -2.1951e-03,
          7.8559e-04, -1.2538e-04, -2.4112e-03, -2.0144e-04, -3.4403e-04,
          6.7416e-04,  8.2940e-05,  1.8444e-03, -3.3140e-04,  1.6746e-03,
         -2.4023e-03,  2.1146e-03, -1.1180e-03, -9.1027e-04, -1.3843e-03,
         -2.3300e-03, -1.8067e-03, -1.8440e-03,  8.9393e-04,  3.0532e-04,
         -7.0533e-04, -1.1048e-03,  2.4095e-03, -1.1106e-03, -3.7585e-03,
         -7.2092e-04, -8.0741e-04, -4.1021e-04, -6.2247e-04,  5.8192e-04,
         -1.3042e-03,  1.7833e-04, -3.5146e-04,  1.8592e-03, -5.4004e-04,
          7.3356e-05, -2.3105e-03,  8.8452e-04, -1.2621e-04, -1.9066e-04,
          2.2402e-03,  1.1415e-04, -4.9603e-05, -4.1960e-04, -2.3870e-03,
          8.1347e-04,  1.6523e-03, -1.1363e-03,  3.5938e-04, -1.9091e-03,
          2.2927e-04, -1.1081e-03, -8.1000e-04,  2.1634e-04,  3.5865e-04,
          1.0452e-03,  4.2076e-03, -1.3475e-03, -3.8908e-04,  2.7464e-04,
          2.1039e-03, -6.1510e-04,  1.0113e-03,  3.1765e-03,  2.0373e-04,
          5.9547e-05,  2.8756e-03, -5.4675e-04, -1.3340e-03,  1.7906e-03,
          1.2997e-03, -1.0709e-03, -1.3941e-04,  1.1134e-04,  2.7620e-04,
          4.7246e-04,  2.3401e-03,  1.7433e-03, -7.3268e-04,  4.9790e-04,
          1.2144e-03, -3.4891e-04,  1.1632e-03,  1.3969e-04,  3.0222e-04,
          5.6138e-04, -4.6011e-04, -1.1831e-04, -2.5964e-03,  1.3481e-03,
         -8.6936e-04, -1.4182e-04,  4.3698e-03,  1.0883e-03, -1.0411e-03,
          1.1948e-03,  8.3472e-05, -2.5857e-03,  1.0584e-03, -5.0073e-05,
         -9.8737e-05,  2.9661e-03,  9.0381e-04,  1.1945e-03,  2.3590e-03,
          2.0212e-03, -5.8487e-04, -1.0015e-03, -1.6407e-03,  1.2251e-03,
         -6.2431e-04,  1.8042e-03, -1.1849e-03,  1.0990e-03, -7.2428e-04,
          7.7698e-04, -1.2421e-03,  1.0248e-03, -8.6830e-04, -4.3260e-04,
          2.1995e-04, -8.9426e-05, -1.2943e-03,  3.4992e-05,  4.3080e-06,
         -7.5094e-04, -8.2188e-04, -1.4912e-03,  2.3899e-03, -6.3062e-04,
         -1.0462e-03,  1.4223e-03, -2.9927e-04, -6.2106e-04, -5.8662e-05,
         -4.3419e-04, -2.7051e-03,  4.5137e-04, -4.5899e-04,  1.7794e-04,
          4.5334e-04,  1.3250e-03, -8.8761e-04,  8.9815e-04, -8.1915e-04,
          7.1331e-04,  1.2659e-03, -2.6379e-04, -3.4659e-04,  8.9254e-04,
         -1.1084e-05, -1.0515e-03]], device='cuda:0')
==> name fc2.bias torch.Size([2]) tensor([-0.0058,  0.0058], device='cuda:0')
tensor([[-2.0801e-02,  9.9706e-02],
        [ 7.5667e-03,  2.0495e-01],
        [-2.9332e-02,  1.4889e-01],
        [-1.5778e-02,  1.0710e-01],
        [ 1.7988e-02,  1.9232e-01],
        [-3.2624e-03,  1.1939e-01],
        [-1.7322e-02,  2.1380e-01],
        [ 2.3389e-02,  6.9180e-02],
        [-4.0486e-03,  2.0972e-01],
        [-7.6736e-03,  1.9167e-01],
        [-3.6596e-02,  9.4032e-02],
        [-5.3161e-02,  7.0071e-02],
        [-2.1665e-02,  9.9751e-02],
        [ 1.7345e-02,  9.6697e-02],
        [ 4.3207e-02,  5.7907e-02],
        [ 1.3111e-02,  8.6804e-02],
        [-4.0550e-02,  1.1458e-01],
        [ 3.5310e-02,  1.0761e-01],
        [-7.0129e-03,  1.2400e-01],
        [-1.6572e-04,  1.8916e-01],
        [-5.2813e-02,  1.0924e-01],
        [-3.4465e-02,  6.7989e-02],
        [ 8.9258e-05,  1.4791e-01],
        [ 4.4879e-02,  1.1304e-01],
        [ 6.8043e-02,  9.8171e-03],
        [-1.5445e-02,  8.2446e-02],
        [-1.3560e-02,  1.0194e-01],
        [-3.7097e-02,  9.4771e-02],
        [ 7.3030e-03,  1.0110e-01],
        [ 2.8291e-02,  1.2692e-01],
        [-3.4994e-02,  1.0842e-01],
        [ 3.0814e-03,  1.1179e-01],
        [ 4.9104e-02,  8.1982e-02],
        [-9.0437e-03,  1.2091e-01],
        [ 1.4741e-02,  1.2661e-01],
        [ 4.5906e-02,  4.2983e-02],
        [-1.3339e-02,  1.6641e-01],
        [-6.5928e-03,  1.0308e-01],
        [-7.0302e-03,  7.1459e-02],
        [-2.4628e-02,  1.4024e-01],
        [-9.0965e-03,  1.3990e-01],
        [-4.4179e-02,  1.3771e-01],
        [ 8.0591e-04,  7.7614e-02],
        [-2.1124e-02,  9.5702e-02],
        [-7.1109e-03,  1.3806e-01],
        [-2.1050e-02,  9.9532e-02],
        [-1.1006e-02,  6.4415e-02],
        [-2.6355e-02,  5.1244e-02],
        [ 1.5665e-02,  1.0869e-01],
        [-2.9459e-02,  7.4449e-02],
        [-2.6373e-02,  1.0944e-01],
        [-3.3364e-02,  8.6173e-02],
        [ 3.3717e-02,  1.3923e-01],
        [ 5.2905e-02,  7.3912e-02],
        [ 3.5326e-02,  1.2750e-01],
        [ 7.3919e-03,  8.9604e-02],
        [ 2.6128e-02,  9.3979e-02],
        [-1.4878e-02,  9.5597e-02],
        [ 2.5363e-02,  1.0606e-01],
        [-3.4098e-02,  9.9315e-02],
        [-4.2546e-03,  1.9497e-01],
        [-4.9007e-02,  9.7871e-02],
        [-3.3303e-02,  9.1716e-02],
        [-3.9263e-02,  1.0839e-01]], device='cuda:0',
       grad_fn=<SqueezeBackward1>)
Iter:    150,  Train Loss:  0.24,  Train Acc: 48.44%,  Val Loss:  0.22,  Val Acc: 49.31%,  Time: 0:00:09 *,  LR: 0.002739052315863355
s_logits tensor([[0.4924, 0.5076],
        [0.5082, 0.4918],
        [0.4981, 0.5019],
        [0.5000, 0.5000],
        [0.4867, 0.5133],
        [0.4993, 0.5007],
        [0.5024, 0.4976],
        [0.4701, 0.5299],
        [0.5060, 0.4940],
        [0.4989, 0.5011],
        [0.4735, 0.5265],
        [0.5392, 0.4608],
        [0.5039, 0.4961],
        [0.4881, 0.5119],
        [0.4986, 0.5014],
        [0.4682, 0.5318],
        [0.4772, 0.5228],
        [0.4916, 0.5084],
        [0.4904, 0.5096],
        [0.5018, 0.4982],
        [0.4810, 0.5190],
        [0.5362, 0.4638],
        [0.4914, 0.5086],
        [0.4738, 0.5262],
        [0.4984, 0.5016],
        [0.5085, 0.4915],
        [0.5090, 0.4910],
        [0.5034, 0.4966],
        [0.5118, 0.4882],
        [0.5172, 0.4828],
        [0.5044, 0.4956],
        [0.4967, 0.5033],
        [0.4892, 0.5108],
        [0.4793, 0.5207],
        [0.5010, 0.4990],
        [0.5003, 0.4997],
        [0.4819, 0.5181],
        [0.4947, 0.5053],
        [0.4799, 0.5201],
        [0.4954, 0.5046],
        [0.4948, 0.5052],
        [0.4706, 0.5294],
        [0.4840, 0.5160],
        [0.4777, 0.5223],
        [0.4929, 0.5071],
        [0.5161, 0.4839],
        [0.5028, 0.4972],
        [0.5001, 0.4999],
        [0.4741, 0.5259],
        [0.4990, 0.5010],
        [0.4887, 0.5113],
        [0.5005, 0.4995],
        [0.5020, 0.4980],
        [0.4642, 0.5358],
        [0.4941, 0.5059],
        [0.5113, 0.4887],
        [0.5015, 0.4985],
        [0.5043, 0.4957],
        [0.4835, 0.5165],
        [0.4784, 0.5216],
        [0.4860, 0.5140],
        [0.4980, 0.5020],
        [0.4942, 0.5058],
        [0.4911, 0.5089]], device='cuda:0', grad_fn=<SoftmaxBackward0>) label tensor([0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0,
        1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1,
        1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1], device='cuda:0')
t_logits tensor([[9.9604e-01, 3.9642e-03],
        [1.4215e-02, 9.8579e-01],
        [9.9251e-01, 7.4906e-03],
        [9.9527e-01, 4.7327e-03],
        [9.9704e-01, 2.9564e-03],
        [4.1125e-03, 9.9589e-01],
        [1.3164e-02, 9.8684e-01],
        [9.9590e-01, 4.0960e-03],
        [4.8314e-03, 9.9517e-01],
        [4.4303e-03, 9.9557e-01],
        [7.6228e-03, 9.9238e-01],
        [3.8239e-03, 9.9618e-01],
        [9.9585e-01, 4.1539e-03],
        [7.3053e-03, 9.9269e-01],
        [4.8976e-02, 9.5102e-01],
        [9.9389e-01, 6.1107e-03],
        [9.9936e-01, 6.3940e-04],
        [2.2047e-02, 9.7795e-01],
        [9.9090e-01, 9.0953e-03],
        [9.9894e-01, 1.0563e-03],
        [4.0593e-03, 9.9594e-01],
        [9.9935e-01, 6.5380e-04],
        [4.1495e-03, 9.9585e-01],
        [2.5150e-02, 9.7485e-01],
        [9.6469e-03, 9.9035e-01],
        [3.2422e-03, 9.9676e-01],
        [1.4051e-02, 9.8595e-01],
        [9.9932e-01, 6.7784e-04],
        [9.9881e-01, 1.1904e-03],
        [8.3301e-01, 1.6699e-01],
        [3.0071e-03, 9.9699e-01],
        [9.9911e-01, 8.9057e-04],
        [9.9692e-01, 3.0821e-03],
        [7.1033e-02, 9.2897e-01],
        [9.6024e-03, 9.9040e-01],
        [9.9786e-01, 2.1378e-03],
        [9.9228e-01, 7.7227e-03],
        [3.3628e-03, 9.9664e-01],
        [9.8947e-01, 1.0525e-02],
        [6.4100e-03, 9.9359e-01],
        [1.7977e-02, 9.8202e-01],
        [9.9883e-01, 1.1654e-03],
        [9.9887e-01, 1.1334e-03],
        [4.8222e-03, 9.9518e-01],
        [4.7747e-03, 9.9523e-01],
        [9.9735e-01, 2.6522e-03],
        [9.9406e-01, 5.9369e-03],
        [2.6466e-03, 9.9735e-01],
        [1.1491e-01, 8.8509e-01],
        [4.0616e-03, 9.9594e-01],
        [9.9589e-01, 4.1150e-03],
        [9.9916e-01, 8.4240e-04],
        [9.9951e-01, 4.8759e-04],
        [9.5185e-01, 4.8148e-02],
        [3.7953e-03, 9.9620e-01],
        [9.9898e-01, 1.0239e-03],
        [9.9910e-01, 9.0116e-04],
        [5.3491e-03, 9.9465e-01],
        [9.9739e-01, 2.6137e-03],
        [9.9741e-01, 2.5909e-03],
        [3.3857e-03, 9.9661e-01],
        [6.6975e-03, 9.9330e-01],
        [9.9902e-01, 9.8319e-04],
        [8.1249e-03, 9.9188e-01]], device='cuda:0')
base_loss tensor(0.6951, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(0.2400, device='cuda:0', grad_fn=<MseLossBackward0>)
==> name Embedding.weight torch.Size([30522, 300]) tensor([[-3.9746e-06,  2.7348e-08, -6.7048e-06,  ...,  1.1839e-06,
          3.1339e-06, -2.7220e-06],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]], device='cuda:0')
==> name lstm.weight_ih_l0 torch.Size([1200, 300]) tensor([[ 8.2165e-06, -9.0034e-06, -2.5091e-05,  ...,  1.1741e-05,
          7.0041e-06,  3.1717e-05],
        [-1.6337e-05, -2.6643e-06, -2.3816e-05,  ..., -1.2734e-05,
         -4.0291e-05,  4.7258e-06],
        [ 1.3351e-05, -1.3949e-05,  3.0033e-05,  ...,  9.4381e-06,
          2.1253e-05,  1.1419e-05],
        ...,
        [-2.4326e-05,  1.1351e-05,  8.4025e-06,  ..., -1.4474e-05,
         -1.0380e-05,  2.6711e-05],
        [ 1.0416e-06, -1.3483e-05, -4.2403e-07,  ...,  5.4760e-06,
         -1.0921e-05, -2.4510e-05],
        [ 1.1065e-05,  1.6798e-05,  1.7156e-05,  ...,  1.9088e-05,
         -3.4776e-06,  3.7710e-06]], device='cuda:0')
==> name lstm.weight_hh_l0 torch.Size([1200, 300]) tensor([[-7.8265e-07,  5.2485e-07,  2.3554e-07,  ..., -7.4426e-07,
         -4.2125e-06,  2.6388e-06],
        [-1.6169e-06,  2.7588e-06, -4.4161e-09,  ...,  5.2349e-06,
          5.7937e-07,  1.0966e-06],
        [-3.1358e-06,  5.0993e-06, -6.3649e-07,  ...,  1.5861e-06,
         -3.1835e-07, -6.6549e-07],
        ...,
        [-7.2227e-07,  4.2534e-06, -2.4792e-06,  ..., -8.1334e-07,
          3.0475e-06,  9.8476e-07],
        [ 3.3850e-06, -3.4420e-06,  2.6232e-06,  ...,  1.2700e-06,
         -1.2102e-06,  4.3403e-07],
        [-1.6961e-06, -2.7212e-08,  4.6521e-06,  ...,  2.2514e-06,
         -1.2751e-06,  4.6175e-06]], device='cuda:0')
==> name lstm.bias_ih_l0 torch.Size([1200]) tensor([ 4.9313e-06, -1.1342e-05, -9.1738e-06,  ...,  1.6294e-05,
        -1.7742e-05, -1.0333e-05], device='cuda:0')
==> name lstm.bias_hh_l0 torch.Size([1200]) tensor([ 4.9313e-06, -1.1342e-05, -9.1738e-06,  ...,  1.6294e-05,
        -1.7742e-05, -1.0333e-05], device='cuda:0')
==> name lstm.weight_ih_l0_reverse torch.Size([1200, 300]) tensor([[ 1.6916e-05, -1.0205e-05,  4.2341e-06,  ...,  3.4432e-05,
         -5.7704e-06,  1.1167e-05],
        [-2.3042e-05, -3.0818e-05, -1.4198e-05,  ..., -1.8534e-05,
         -3.9772e-05, -1.1161e-05],
        [-1.6616e-05, -1.7556e-05, -3.2146e-06,  ..., -9.1667e-06,
         -4.0715e-05, -2.5270e-05],
        ...,
        [ 2.9424e-05,  1.1519e-06, -3.9433e-05,  ...,  3.3367e-05,
          2.9260e-05,  5.8581e-05],
        [ 2.3746e-05, -4.1378e-06, -2.4133e-05,  ...,  1.8261e-05,
          3.3659e-05,  2.0256e-06],
        [-1.3240e-05, -9.4020e-06,  2.2893e-05,  ..., -1.8855e-05,
         -3.7988e-05,  6.4436e-05]], device='cuda:0')
==> name lstm.weight_hh_l0_reverse torch.Size([1200, 300]) tensor([[-6.8133e-07, -2.9210e-06,  1.8512e-06,  ...,  3.9054e-06,
          1.8616e-06, -3.9241e-07],
        [-3.5204e-06, -3.3145e-06, -3.5604e-06,  ...,  5.0318e-06,
          3.4904e-07, -3.6304e-06],
        [ 4.7133e-06, -2.4428e-06,  3.0379e-06,  ...,  4.5315e-07,
         -8.2634e-07,  5.8361e-06],
        ...,
        [-9.5966e-08, -2.9706e-06,  6.1593e-06,  ..., -7.1373e-06,
         -5.2233e-06, -2.0872e-06],
        [-6.9305e-06,  4.4803e-06, -3.3704e-06,  ...,  7.8502e-06,
         -6.3224e-06, -3.7656e-06],
        [ 4.0257e-08, -2.6044e-06, -4.9208e-06,  ..., -1.5772e-06,
         -7.8207e-06,  1.2364e-06]], device='cuda:0')
==> name lstm.bias_ih_l0_reverse torch.Size([1200]) tensor([-1.7267e-05,  3.5472e-05,  2.2167e-05,  ...,  2.7849e-05,
         1.4745e-05,  4.9190e-05], device='cuda:0')
==> name lstm.bias_hh_l0_reverse torch.Size([1200]) tensor([-1.7267e-05,  3.5472e-05,  2.2167e-05,  ...,  2.7849e-05,
         1.4745e-05,  4.9190e-05], device='cuda:0')
==> name fc1.weight torch.Size([192, 600]) tensor([[-1.8859e-04,  1.9425e-04, -2.2683e-04,  ..., -2.9709e-05,
         -1.2582e-04, -9.3724e-05],
        [-2.5061e-04,  4.6828e-06,  2.9729e-05,  ...,  4.8583e-04,
         -1.5741e-04, -4.2306e-04],
        [-2.7775e-04, -5.5002e-05, -3.1282e-04,  ...,  2.7848e-04,
         -1.2246e-04, -5.8946e-04],
        ...,
        [-1.6483e-04,  3.9445e-05, -2.9140e-05,  ...,  1.6025e-06,
         -2.5614e-05, -1.8153e-05],
        [ 2.3933e-07,  1.0179e-04, -5.7373e-05,  ...,  3.6293e-05,
         -1.5197e-06, -2.9993e-05],
        [-1.3788e-04,  1.0225e-04, -2.2725e-04,  ...,  1.8070e-04,
         -2.1476e-05, -1.5119e-04]], device='cuda:0')
==> name fc1.bias torch.Size([192]) tensor([ 1.3705e-03, -1.6295e-04, -5.9118e-04, -9.3461e-04,  1.3520e-03,
        -3.6755e-04, -4.7884e-04, -9.6292e-04, -1.2041e-04, -4.3219e-05,
         1.6541e-03,  5.1340e-05, -5.6483e-04,  1.0745e-03, -8.7790e-04,
        -2.8709e-04,  6.3051e-04,  6.9808e-04, -2.9023e-04, -3.8458e-04,
         8.3929e-04,  1.0907e-03,  6.9376e-04,  3.3334e-04, -5.4097e-04,
         2.2536e-04,  4.2143e-04, -8.4074e-05,  1.3729e-04,  2.0095e-05,
         9.6690e-04, -4.1831e-04,  1.2735e-03, -7.3994e-05,  3.8119e-05,
         4.2823e-04, -9.1079e-04,  5.9513e-04, -5.1886e-04, -3.1530e-04,
         3.4419e-04,  2.9575e-04,  3.4317e-04,  5.8693e-04, -3.3629e-04,
        -8.0562e-04,  2.0701e-04, -5.3019e-04, -8.9088e-04, -8.9341e-04,
        -4.9974e-04,  9.9094e-04,  2.2764e-04, -5.4071e-04,  1.6754e-03,
         8.1167e-04, -2.0749e-04,  6.9070e-04,  1.7953e-05, -5.9495e-04,
         1.4782e-05,  1.2475e-03, -4.5632e-04,  6.5164e-04, -5.0434e-04,
         3.2052e-04,  3.3993e-04, -8.0888e-04,  1.2874e-04,  7.1620e-04,
         1.9760e-05,  5.3810e-04,  6.8191e-04,  3.4455e-04, -1.2081e-03,
         4.4636e-05, -2.6243e-05,  4.3009e-04, -1.3857e-04, -1.0989e-03,
        -1.9920e-03,  3.7304e-04,  4.7509e-04, -5.3777e-04, -4.3940e-05,
         4.7121e-05,  2.3866e-04,  5.8088e-04, -1.9523e-04, -3.1694e-04,
        -9.2284e-04,  8.0724e-04, -1.4157e-03,  7.7383e-04,  8.7576e-04,
         3.8153e-04, -2.4625e-04, -3.8073e-04,  5.9043e-04, -5.4694e-07,
        -1.1534e-03,  4.0088e-04, -5.7191e-04,  1.3355e-03,  4.8755e-04,
         5.5102e-04,  7.0382e-04, -1.6659e-04,  1.3770e-05, -2.9182e-03,
         6.8431e-04, -6.3540e-04,  6.0852e-04, -5.2850e-04,  8.9969e-05,
        -2.6158e-04,  3.4834e-05,  5.5029e-04,  1.6304e-04,  2.3075e-04,
        -2.2144e-04, -3.0654e-05,  8.2994e-04,  7.1179e-05, -8.0774e-04,
         1.4437e-03, -6.0042e-05, -1.2595e-03,  6.9482e-04, -1.0272e-03,
        -3.5481e-04,  2.6304e-04,  1.8429e-05, -5.7436e-05,  4.8117e-04,
         5.5169e-04,  1.2335e-04,  2.1764e-03, -9.4946e-05, -2.6969e-04,
        -3.0419e-04,  5.2583e-04, -1.9390e-03, -1.0077e-03, -1.1723e-03,
         3.1107e-04,  7.1337e-05, -2.6163e-04, -1.6534e-04,  1.3822e-03,
        -4.3432e-04, -4.2585e-04,  1.0448e-03,  1.7800e-04,  1.5045e-04,
         1.1887e-04,  8.3608e-04, -3.2560e-04,  5.4024e-04, -2.5719e-04,
         2.2916e-04, -1.7861e-04,  9.2336e-04,  7.4021e-04,  1.3247e-04,
         8.1722e-05,  2.8290e-04, -6.2333e-04,  3.9924e-04,  9.4606e-04,
         2.6244e-04, -9.0721e-04,  6.2393e-04,  9.4162e-05,  5.1487e-04,
         2.5320e-04,  8.4769e-05,  3.2505e-04, -1.2894e-04,  5.3542e-05,
        -1.0843e-03, -8.0366e-04, -1.8627e-04,  6.8331e-04,  1.5590e-03,
        -2.1494e-04, -1.3660e-04,  2.0431e-04,  1.1890e-03,  3.0449e-04,
         7.3363e-06, -1.9216e-04], device='cuda:0')
==> name fc2.weight torch.Size([2, 192]) tensor([[ 1.5170e-03,  1.2953e-03, -1.2052e-03,  2.8329e-04,  1.0324e-03,
          1.6268e-03, -4.6183e-04,  2.1480e-04,  3.5326e-04,  6.7761e-05,
         -1.3469e-03,  4.1928e-04, -3.7520e-03, -2.6965e-04, -2.8211e-04,
         -7.8796e-04, -1.0291e-03, -1.2969e-03, -1.0071e-03, -1.4229e-03,
          1.5774e-03, -1.4475e-03,  2.0012e-04,  2.1325e-04, -1.2117e-03,
         -1.1151e-03, -6.1870e-04,  9.0851e-04,  9.8386e-04,  7.8229e-04,
          1.5736e-03, -7.1688e-05,  4.3811e-04,  4.8382e-04, -9.6841e-04,
          1.9078e-04, -8.0472e-04, -1.3944e-03, -3.5379e-04, -9.7677e-04,
         -1.9139e-04, -7.7046e-04, -4.7167e-04,  1.6220e-03, -2.2359e-03,
         -2.7493e-04, -2.4169e-04, -9.3249e-04, -1.7350e-03, -2.2354e-04,
          8.8909e-04, -1.6563e-03,  2.4941e-03,  2.6637e-05,  1.2122e-03,
         -1.2354e-03, -8.9370e-05, -2.2135e-04,  1.6982e-03, -1.3398e-03,
         -1.3223e-03, -1.5352e-04, -1.0870e-03, -3.9891e-04, -3.9055e-04,
         -1.5107e-03,  5.5726e-04, -5.1486e-03, -6.0442e-04, -1.7306e-03,
          6.7899e-04, -7.1014e-04, -1.5104e-03, -7.8025e-04, -2.3513e-03,
         -1.7992e-04, -3.8295e-04, -6.5026e-04,  1.5411e-04, -9.8763e-05,
         -3.4321e-03, -2.4758e-03,  1.5818e-03, -7.2662e-04, -4.0733e-04,
          1.1485e-03, -8.2110e-04,  2.9709e-04, -1.2813e-03, -1.1900e-03,
         -4.1711e-04, -9.8257e-04, -1.2952e-03, -4.9105e-04, -1.1897e-04,
         -1.0364e-03,  3.0751e-04, -1.3563e-03, -3.7115e-04,  4.1509e-04,
         -2.5379e-03,  1.0660e-03, -4.7245e-04,  1.5553e-04,  2.5747e-04,
         -1.2965e-04, -1.2958e-03, -6.3251e-04, -1.0664e-03,  5.4042e-04,
         -1.1871e-03, -4.9350e-04, -3.2766e-04, -5.3773e-04,  1.3828e-03,
         -3.0739e-04, -6.7222e-04,  2.2785e-03, -1.6508e-03,  1.4251e-03,
          7.0915e-04,  5.1916e-04,  2.0888e-03, -1.4207e-04,  1.2279e-03,
         -6.7856e-04,  4.2213e-05, -7.0026e-04,  2.1113e-03,  1.1946e-03,
         -2.1067e-04, -1.5560e-03,  1.9728e-03, -1.4805e-04, -2.9797e-04,
          6.0097e-04, -1.7249e-03, -1.6052e-03,  1.0346e-03,  8.6197e-05,
         -5.0659e-04, -1.2899e-03, -4.1288e-04, -1.7541e-03,  1.3195e-04,
          1.1994e-03, -9.6537e-04, -1.1380e-04, -4.4989e-04, -6.6991e-04,
          3.8261e-03, -1.0870e-03, -5.0375e-04, -2.5490e-03, -2.0435e-04,
          2.8101e-04,  2.4780e-03,  2.2463e-03, -4.2509e-05,  5.2912e-04,
         -1.1717e-03, -9.6706e-04,  5.3106e-04, -5.6704e-04,  1.0639e-04,
          9.7751e-04, -1.8786e-03, -3.6658e-04,  3.9807e-04, -3.3496e-04,
         -5.6874e-04,  5.8514e-04, -1.8622e-05, -4.5017e-04,  8.1301e-04,
          1.6480e-04, -9.2997e-04, -9.5383e-04, -7.5409e-04,  3.1965e-04,
         -2.4825e-04, -3.4381e-03, -2.0048e-04, -3.3929e-04, -9.0929e-04,
          3.4725e-03,  1.1544e-03, -1.1184e-03, -1.3328e-03,  1.2512e-03,
         -1.5627e-03, -7.8096e-04],
        [-4.0901e-04,  6.2122e-04,  2.7525e-03, -1.5485e-03,  5.9848e-04,
          7.0134e-04,  1.0700e-04, -1.0787e-03, -4.6976e-04,  5.1487e-04,
          6.0283e-04, -1.0186e-03, -2.5156e-03, -6.6771e-04,  8.4349e-04,
         -5.2240e-04,  8.8563e-04, -3.8939e-04, -1.6060e-03, -1.3402e-03,
          1.6371e-04,  6.8720e-04, -9.4528e-04, -1.7165e-03, -5.8411e-04,
         -5.1044e-04, -2.9068e-04,  2.2491e-05,  3.0036e-04,  1.2458e-03,
         -3.4361e-04,  1.0547e-03, -3.3633e-03, -7.4730e-04, -1.2121e-04,
          5.8254e-04, -1.1653e-03,  7.4245e-04, -1.7428e-03, -7.5175e-04,
          1.4134e-03,  2.4323e-04,  9.2224e-04,  4.9710e-04,  2.2503e-04,
         -1.7362e-04, -1.1432e-04,  8.8011e-04, -1.2114e-04,  1.1957e-03,
          1.3783e-03,  2.0694e-03,  1.2348e-03, -1.8234e-03,  2.0812e-04,
         -6.3484e-04, -3.9759e-04, -2.4824e-04,  1.8163e-04,  5.6154e-04,
         -4.4238e-04,  2.7761e-03, -1.3695e-04,  1.9081e-03, -1.4364e-03,
          1.5903e-03,  7.7505e-04,  9.6702e-05, -5.4547e-04, -1.1978e-04,
          5.6136e-04, -5.6695e-04, -4.9838e-05,  1.0074e-03, -4.8054e-04,
          1.2981e-03,  2.9111e-04, -5.8770e-04,  8.4095e-04, -4.8434e-05,
         -6.4330e-04, -7.4567e-04,  4.5644e-05, -7.2647e-04, -7.0936e-04,
         -1.9842e-04,  6.4672e-05, -6.0430e-04,  3.3180e-04,  3.0081e-03,
          1.9779e-03,  1.8002e-04,  1.2097e-03,  1.9595e-04, -6.7420e-04,
          1.2996e-03,  9.9009e-04, -1.3377e-03, -3.3122e-04, -1.5987e-03,
          1.2565e-03, -7.7537e-04, -1.1527e-03,  2.1768e-03, -5.9089e-04,
          2.6071e-03,  1.7637e-03, -1.9516e-03,  1.8003e-04, -4.2797e-05,
         -6.3218e-04,  6.1921e-04,  4.7058e-04,  1.0594e-03, -5.4217e-04,
         -2.3076e-04, -2.1040e-03,  3.3921e-03, -2.1305e-03,  6.0368e-04,
          1.1576e-04, -2.9179e-04,  1.3806e-03,  7.7741e-04,  1.8318e-03,
          6.7117e-05,  2.2133e-03,  5.2842e-04,  1.7191e-03,  1.4251e-03,
          5.3335e-04,  2.3927e-04, -1.5382e-03, -4.4165e-04,  6.9966e-04,
          1.5070e-03,  1.5379e-03, -2.1402e-04, -1.8217e-04, -1.7715e-04,
         -1.1007e-03,  9.8685e-04, -5.7595e-04, -2.1841e-03,  7.0630e-04,
          2.6065e-05,  2.9114e-04, -9.5232e-04, -2.8270e-04,  5.1868e-05,
          1.4837e-03,  5.7721e-04,  1.7185e-03, -9.3318e-04, -6.6454e-04,
         -4.3270e-04,  1.0733e-03, -6.4208e-04, -1.2537e-03,  1.3242e-03,
         -1.3344e-03, -3.7339e-04, -1.3914e-04,  2.3670e-04,  1.8055e-04,
          1.3387e-03, -5.6610e-06, -7.2939e-04,  4.8566e-04,  2.0932e-03,
         -1.4348e-03,  4.2258e-04, -6.6184e-04, -1.7119e-03, -1.2611e-04,
          9.3807e-05, -2.8756e-03,  1.8132e-04, -1.4175e-04,  5.1369e-05,
         -6.9539e-04,  7.2849e-04, -1.6936e-03,  1.3744e-03,  1.8663e-03,
          2.5332e-03,  7.1018e-05, -4.0758e-04, -2.3714e-04,  4.8502e-05,
          5.4597e-04,  1.4755e-04]], device='cuda:0')
==> name fc2.bias torch.Size([2]) tensor([-0.0038,  0.0038], device='cuda:0')
tensor([[ 0.0616,  0.0919],
        [ 0.0580,  0.0251],
        [ 0.0795,  0.0871],
        [ 0.0412,  0.0414],
        [-0.0337,  0.0195],
        [ 0.0592,  0.0619],
        [ 0.0903,  0.0808],
        [ 0.0385,  0.1582],
        [ 0.0838,  0.0600],
        [ 0.0821,  0.0866],
        [ 0.0335,  0.1396],
        [ 0.1542, -0.0029],
        [ 0.0897,  0.0742],
        [-0.0048,  0.0427],
        [ 0.0488,  0.0546],
        [ 0.0763,  0.2036],
        [ 0.0633,  0.1546],
        [ 0.0047,  0.0381],
        [ 0.0369,  0.0754],
        [ 0.0641,  0.0567],
        [-0.0058,  0.0701],
        [ 0.1705,  0.0253],
        [ 0.0660,  0.1003],
        [ 0.0467,  0.1517],
        [ 0.0641,  0.0707],
        [ 0.0765,  0.0426],
        [ 0.1181,  0.0822],
        [ 0.0655,  0.0519],
        [ 0.0796,  0.0324],
        [ 0.1496,  0.0808],
        [ 0.0678,  0.0501],
        [ 0.0061,  0.0192],
        [ 0.0952,  0.1384],
        [ 0.0227,  0.1055],
        [ 0.0666,  0.0624],
        [ 0.0537,  0.0523],
        [ 0.0006,  0.0729],
        [ 0.0666,  0.0876],
        [ 0.0116,  0.0921],
        [ 0.0875,  0.1059],
        [ 0.0656,  0.0866],
        [ 0.1294,  0.2471],
        [ 0.0128,  0.0770],
        [ 0.0016,  0.0908],
        [ 0.0686,  0.0970],
        [ 0.0819,  0.0175],
        [ 0.0938,  0.0825],
        [ 0.0612,  0.0610],
        [ 0.0889,  0.1927],
        [ 0.0810,  0.0849],
        [-0.0021,  0.0432],
        [ 0.0670,  0.0649],
        [ 0.0725,  0.0645],
        [ 0.0122,  0.1558],
        [ 0.0467,  0.0705],
        [ 0.0852,  0.0401],
        [ 0.1576,  0.1516],
        [ 0.0852,  0.0680],
        [ 0.0100,  0.0761],
        [ 0.0141,  0.1005],
        [-0.0125,  0.0437],
        [ 0.0241,  0.0322],
        [-0.0234, -0.0004],
        [ 0.0112,  0.0469]], device='cuda:0', grad_fn=<SqueezeBackward1>)
Iter:    200,  Train Loss:  0.24,  Train Acc: 46.88%,  Val Loss:  0.22,  Val Acc: 48.60%,  Time: 0:00:11 ,  LR: 0.20610737385377145
Epoch [3/30]
s_logits tensor([[0.4887, 0.5113],
        [0.4771, 0.5229],
        [0.4947, 0.5053],
        [0.4903, 0.5097],
        [0.4978, 0.5022],
        [0.4842, 0.5158],
        [0.5138, 0.4862],
        [0.4903, 0.5097],
        [0.4927, 0.5073],
        [0.4826, 0.5174],
        [0.4781, 0.5219],
        [0.4911, 0.5089],
        [0.4950, 0.5050],
        [0.4947, 0.5053],
        [0.4836, 0.5164],
        [0.4852, 0.5148],
        [0.4798, 0.5202],
        [0.4847, 0.5153],
        [0.5246, 0.4754],
        [0.4883, 0.5117],
        [0.4792, 0.5208],
        [0.4861, 0.5139],
        [0.4814, 0.5186],
        [0.5005, 0.4995],
        [0.4984, 0.5016],
        [0.4877, 0.5123],
        [0.4667, 0.5333],
        [0.4882, 0.5118],
        [0.4919, 0.5081],
        [0.4879, 0.5121],
        [0.5302, 0.4698],
        [0.4928, 0.5072],
        [0.4946, 0.5054],
        [0.5054, 0.4946],
        [0.4773, 0.5227],
        [0.5087, 0.4913],
        [0.5187, 0.4813],
        [0.4891, 0.5109],
        [0.4934, 0.5066],
        [0.4735, 0.5265],
        [0.4906, 0.5094],
        [0.5119, 0.4881],
        [0.4853, 0.5147],
        [0.4818, 0.5182],
        [0.4952, 0.5048],
        [0.5385, 0.4615],
        [0.5011, 0.4989],
        [0.4823, 0.5177],
        [0.4866, 0.5134],
        [0.4929, 0.5071],
        [0.4851, 0.5149],
        [0.4936, 0.5064],
        [0.4894, 0.5106],
        [0.4875, 0.5125],
        [0.4834, 0.5166],
        [0.4865, 0.5135],
        [0.4842, 0.5158],
        [0.5253, 0.4747],
        [0.4738, 0.5262],
        [0.4789, 0.5211],
        [0.4960, 0.5040],
        [0.4929, 0.5071],
        [0.4948, 0.5052],
        [0.4932, 0.5068]], device='cuda:0', grad_fn=<SoftmaxBackward0>) label tensor([0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1,
        1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,
        0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0], device='cuda:0')
t_logits tensor([[9.9774e-01, 2.2594e-03],
        [9.9774e-01, 2.2613e-03],
        [3.6453e-03, 9.9635e-01],
        [4.4081e-03, 9.9559e-01],
        [3.8665e-03, 9.9613e-01],
        [9.9926e-01, 7.3872e-04],
        [3.1168e-03, 9.9688e-01],
        [3.2015e-03, 9.9680e-01],
        [1.2024e-02, 9.8798e-01],
        [4.5399e-03, 9.9546e-01],
        [8.6821e-02, 9.1318e-01],
        [9.7021e-01, 2.9792e-02],
        [5.1196e-03, 9.9488e-01],
        [9.3191e-03, 9.9068e-01],
        [9.9899e-01, 1.0100e-03],
        [9.9869e-01, 1.3105e-03],
        [2.1046e-02, 9.7895e-01],
        [4.3322e-03, 9.9567e-01],
        [5.4638e-01, 4.5362e-01],
        [7.3390e-03, 9.9266e-01],
        [4.9193e-03, 9.9508e-01],
        [4.0281e-03, 9.9597e-01],
        [3.8835e-03, 9.9612e-01],
        [3.4578e-03, 9.9654e-01],
        [8.2929e-03, 9.9171e-01],
        [9.9394e-01, 6.0625e-03],
        [7.1975e-01, 2.8025e-01],
        [6.2530e-03, 9.9375e-01],
        [3.9217e-03, 9.9608e-01],
        [9.7849e-01, 2.1509e-02],
        [9.9845e-01, 1.5480e-03],
        [9.9931e-01, 6.9499e-04],
        [9.9542e-01, 4.5824e-03],
        [9.9899e-01, 1.0124e-03],
        [9.9922e-01, 7.7954e-04],
        [5.7522e-02, 9.4248e-01],
        [7.9799e-03, 9.9202e-01],
        [2.6827e-01, 7.3173e-01],
        [9.9921e-01, 7.9021e-04],
        [6.3301e-03, 9.9367e-01],
        [9.9593e-01, 4.0717e-03],
        [9.9837e-01, 1.6319e-03],
        [9.9903e-01, 9.6742e-04],
        [9.9908e-01, 9.1840e-04],
        [3.9714e-03, 9.9603e-01],
        [3.9137e-03, 9.9609e-01],
        [9.9233e-01, 7.6735e-03],
        [5.7003e-03, 9.9430e-01],
        [9.1294e-01, 8.7059e-02],
        [5.0047e-03, 9.9500e-01],
        [1.4152e-02, 9.8585e-01],
        [3.4750e-03, 9.9652e-01],
        [9.9820e-01, 1.7984e-03],
        [9.9827e-01, 1.7261e-03],
        [9.8092e-01, 1.9083e-02],
        [9.8320e-01, 1.6805e-02],
        [9.9895e-01, 1.0479e-03],
        [9.9052e-01, 9.4836e-03],
        [4.8463e-03, 9.9515e-01],
        [3.3855e-03, 9.9661e-01],
        [2.3236e-02, 9.7676e-01],
        [3.8519e-03, 9.9615e-01],
        [3.7308e-03, 9.9627e-01],
        [9.9872e-01, 1.2816e-03]], device='cuda:0')
base_loss tensor(0.6922, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(0.2308, device='cuda:0', grad_fn=<MseLossBackward0>)
==> name Embedding.weight torch.Size([30522, 300]) tensor([[ 3.7805e-06, -2.3647e-07, -5.1885e-06,  ...,  4.5976e-06,
         -7.9051e-06, -6.4669e-06],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]], device='cuda:0')
==> name lstm.weight_ih_l0 torch.Size([1200, 300]) tensor([[ 1.8544e-05, -3.3661e-05,  2.1257e-06,  ...,  5.9028e-06,
         -2.2153e-05, -2.3159e-06],
        [-1.4335e-05, -5.9377e-07,  3.4397e-05,  ..., -2.4478e-07,
          2.5835e-05,  1.0146e-05],
        [-2.0196e-05,  7.0284e-06,  1.6173e-05,  ..., -8.5962e-06,
         -2.9950e-05,  1.5203e-05],
        ...,
        [ 2.9549e-05,  4.1418e-05, -6.9502e-06,  ..., -4.8932e-06,
          7.9042e-06, -4.7757e-06],
        [-9.3063e-06,  2.0251e-05,  1.3218e-05,  ..., -3.4419e-05,
         -1.8336e-05,  6.2212e-06],
        [ 1.8236e-05,  9.9838e-07, -2.8344e-05,  ...,  5.8885e-06,
         -3.4139e-05,  4.3951e-06]], device='cuda:0')
==> name lstm.weight_hh_l0 torch.Size([1200, 300]) tensor([[ 4.2081e-06, -2.6657e-06, -1.0111e-06,  ..., -1.6978e-06,
         -3.3151e-06,  3.4407e-06],
        [ 8.9677e-06, -3.7012e-07, -3.6505e-06,  ..., -1.6845e-07,
          2.8860e-06, -6.7992e-06],
        [-1.9903e-06, -7.5501e-07,  9.6321e-07,  ..., -1.4989e-06,
          1.3776e-06,  3.1053e-06],
        ...,
        [-3.5274e-06, -4.8994e-06,  1.7719e-06,  ...,  2.6834e-06,
         -2.7485e-06,  2.1893e-06],
        [ 9.4431e-07,  2.7584e-06, -2.0696e-06,  ...,  5.4730e-06,
          3.7679e-06, -3.3447e-06],
        [ 2.8063e-06, -1.4659e-06, -8.6447e-07,  ..., -2.5935e-07,
          7.8426e-07, -1.2629e-05]], device='cuda:0')
==> name lstm.bias_ih_l0 torch.Size([1200]) tensor([-2.7704e-05, -1.1347e-05, -5.3581e-06,  ..., -1.0901e-05,
        -1.3411e-05, -3.8551e-06], device='cuda:0')
==> name lstm.bias_hh_l0 torch.Size([1200]) tensor([-2.7704e-05, -1.1347e-05, -5.3581e-06,  ..., -1.0901e-05,
        -1.3411e-05, -3.8551e-06], device='cuda:0')
==> name lstm.weight_ih_l0_reverse torch.Size([1200, 300]) tensor([[ 2.8019e-05,  3.6393e-06, -5.1995e-06,  ..., -1.7173e-05,
         -1.2774e-05,  1.3267e-05],
        [ 9.0796e-06,  7.7465e-06, -1.2077e-06,  ...,  9.5461e-06,
         -1.3153e-05, -3.5898e-05],
        [-2.3400e-05,  4.8541e-06,  2.7430e-05,  ..., -6.2489e-06,
          1.2204e-05,  6.8582e-06],
        ...,
        [-1.2167e-05, -7.2424e-06, -3.5510e-06,  ...,  7.5407e-06,
          1.0750e-06, -9.8387e-06],
        [-2.3275e-06, -4.3229e-06,  1.6640e-06,  ..., -1.4488e-05,
         -2.0591e-06,  1.3167e-05],
        [-3.5116e-05, -8.5321e-06, -3.3993e-05,  ...,  3.0940e-06,
         -1.0933e-05, -3.4265e-05]], device='cuda:0')
==> name lstm.weight_hh_l0_reverse torch.Size([1200, 300]) tensor([[ 2.9304e-06,  3.0226e-06, -1.2971e-06,  ...,  9.5980e-07,
          3.2215e-07, -5.0234e-07],
        [-2.7966e-06,  9.9444e-06, -3.6771e-06,  ...,  9.0356e-07,
          1.1807e-06, -5.6740e-06],
        [-2.4938e-06,  2.8265e-06,  1.4943e-07,  ..., -2.4615e-06,
          1.1817e-06, -8.0841e-06],
        ...,
        [ 3.0449e-06, -2.2302e-07,  4.6544e-06,  ...,  9.4576e-06,
          8.0624e-08, -5.4018e-06],
        [ 3.6935e-06, -1.0657e-06,  3.4855e-07,  ..., -1.3407e-06,
          2.0306e-06,  5.8646e-06],
        [ 2.3418e-06,  1.4111e-06,  3.8259e-06,  ...,  2.8913e-06,
          3.2357e-06, -3.2413e-06]], device='cuda:0')
==> name lstm.bias_ih_l0_reverse torch.Size([1200]) tensor([ 9.0828e-06, -4.5006e-06, -2.1699e-05,  ...,  1.0945e-05,
         3.6312e-08, -3.8509e-05], device='cuda:0')
==> name lstm.bias_hh_l0_reverse torch.Size([1200]) tensor([ 9.0828e-06, -4.5006e-06, -2.1699e-05,  ...,  1.0945e-05,
         3.6312e-08, -3.8509e-05], device='cuda:0')
==> name fc1.weight torch.Size([192, 600]) tensor([[-1.6984e-04, -2.9020e-05, -1.1785e-04,  ...,  1.9078e-04,
          6.8617e-05, -3.3420e-05],
        [ 2.1959e-04, -4.5162e-05,  2.0996e-05,  ..., -1.1013e-04,
          8.1561e-05,  6.9010e-05],
        [ 1.5164e-05, -2.3662e-04, -2.1289e-04,  ...,  3.8457e-04,
          1.6242e-05, -1.2515e-04],
        ...,
        [-3.4122e-05, -1.4341e-04,  2.1968e-04,  ..., -2.6826e-05,
         -2.3052e-05, -1.1889e-04],
        [ 5.6821e-05,  1.4541e-04, -8.5279e-05,  ...,  3.3528e-05,
          1.2311e-04,  5.1372e-05],
        [-1.5905e-04,  1.7102e-04, -3.7547e-04,  ...,  8.5089e-05,
          2.5447e-04,  9.5922e-05]], device='cuda:0')
==> name fc1.bias torch.Size([192]) tensor([ 1.1438e-03,  2.8497e-04, -1.0713e-03,  1.9147e-04, -1.7470e-04,
        -8.9185e-05, -9.4273e-04, -1.0083e-03,  1.7717e-04, -2.0660e-03,
        -1.8342e-05, -5.7802e-04,  9.8825e-05,  1.7462e-03, -2.0129e-03,
         2.9238e-04, -7.3518e-04,  6.3967e-04, -2.0244e-04,  1.4254e-03,
         3.1970e-03, -1.4551e-04, -6.7855e-04, -1.3459e-04, -5.3498e-05,
        -2.9496e-04, -4.3796e-04,  1.5348e-04,  5.4937e-04, -7.6658e-04,
         1.5146e-03, -3.1505e-04,  2.3256e-03, -1.9804e-03, -7.1184e-05,
         1.5652e-04,  1.3874e-03, -9.2796e-04,  1.4349e-03,  2.5730e-04,
         7.2909e-05,  2.1050e-04,  2.6110e-04,  3.7759e-04,  5.7655e-04,
        -1.5183e-04,  7.9533e-04, -9.0792e-04, -1.2594e-03,  6.7144e-04,
        -2.6798e-03, -2.3958e-03, -4.4388e-04, -2.8581e-04,  3.7956e-03,
        -4.4247e-06, -2.7908e-04,  1.4596e-03, -3.0133e-04,  9.4629e-04,
        -7.6414e-05,  3.8662e-04,  2.0432e-03,  3.8139e-04,  1.1037e-03,
         5.4646e-04,  3.3733e-04, -3.0831e-04, -3.2552e-04,  5.4760e-04,
        -1.2147e-04,  3.6798e-04,  5.2889e-04,  6.9503e-04,  7.8722e-04,
        -1.0093e-03,  3.5080e-05,  2.8637e-04,  4.5704e-04, -1.0066e-03,
         1.2721e-03, -9.3229e-04,  5.1726e-04,  7.5658e-05, -7.3101e-04,
         8.8761e-04,  4.1018e-04,  1.1381e-04,  7.4195e-04,  1.0170e-03,
        -5.3867e-04,  4.5812e-04, -1.7563e-03, -5.1486e-05,  1.0769e-03,
        -1.1010e-03, -4.8935e-04, -2.7452e-04,  2.4645e-05,  4.7380e-04,
        -2.4567e-04,  2.2289e-04, -1.6350e-03, -8.9336e-04, -1.4883e-03,
        -1.1836e-03, -1.7942e-04,  5.7192e-04,  2.0077e-05, -1.1579e-03,
         1.9928e-05, -2.4005e-03, -8.2545e-04, -2.8461e-04,  3.7396e-04,
         8.1442e-04,  3.3569e-04,  5.5633e-04,  6.8563e-04,  3.0227e-04,
         2.9436e-03, -6.3235e-04, -4.2273e-04,  8.9434e-04, -9.8571e-04,
        -1.8984e-03, -1.3784e-03,  1.0615e-03,  8.3338e-04, -5.8093e-04,
         6.4700e-04, -4.4414e-04, -4.9903e-04, -3.8019e-04,  1.8851e-03,
        -3.4686e-04,  7.4054e-04, -1.3811e-03, -5.7604e-04, -1.7014e-04,
        -2.6521e-03, -7.0771e-04, -1.1669e-03,  4.8339e-04,  1.1960e-04,
        -1.9964e-05, -3.2901e-04,  4.7270e-04, -5.1661e-04, -1.3469e-03,
         1.8817e-03,  5.2239e-04,  9.0039e-05, -6.6746e-04,  5.6927e-04,
        -2.8455e-05,  6.9692e-04,  2.0667e-03, -2.0842e-04,  5.0174e-04,
        -3.5196e-05, -1.0901e-04,  2.5579e-03, -6.4139e-04,  1.5685e-03,
         6.4448e-05,  2.5977e-04,  7.4670e-04, -2.4290e-04,  7.6848e-04,
         2.0494e-04, -2.7694e-04, -9.6104e-04,  3.8672e-04, -2.2901e-04,
        -5.4430e-04, -1.5716e-04, -1.7806e-04,  8.1885e-04, -8.4394e-04,
        -4.5048e-04, -2.9604e-04, -1.6976e-03, -1.1571e-03, -1.0139e-03,
        -3.6315e-04,  5.3460e-04,  6.1627e-04, -2.0810e-04, -6.7922e-04,
         5.6779e-04,  2.3701e-03], device='cuda:0')
==> name fc2.weight torch.Size([2, 192]) tensor([[ 1.4498e-03,  1.7319e-03, -2.0609e-03, -1.6634e-04,  1.1584e-03,
          1.0898e-03, -1.1319e-03,  3.5887e-04, -8.8300e-04,  2.0431e-03,
         -8.3036e-04, -4.1406e-05, -5.1543e-04, -8.8859e-04,  1.9789e-03,
          1.2771e-03,  6.1477e-04, -1.4923e-03, -1.8579e-04,  1.2000e-03,
          5.3409e-03,  3.9183e-05, -1.3959e-03, -5.8082e-04,  6.1023e-04,
          4.3024e-04, -3.4600e-04,  8.9446e-04,  1.6870e-03, -2.3720e-06,
         -1.1935e-03,  9.5162e-04, -2.3324e-03,  1.6987e-03,  3.0054e-04,
         -8.4898e-04,  3.0726e-03,  2.8765e-03,  7.0359e-04,  2.6128e-04,
          1.2970e-03,  2.1711e-03,  4.8893e-04, -1.0827e-04,  2.3342e-03,
          7.5390e-05,  9.4864e-04, -1.2519e-03,  7.2700e-04,  2.1226e-04,
          1.9160e-03,  7.1299e-04,  3.3065e-03, -1.0282e-03,  3.9119e-03,
          6.3047e-04, -1.0978e-03,  2.7873e-03,  3.8513e-04,  1.1064e-03,
          3.5990e-04, -7.6630e-04,  9.6353e-04,  1.4836e-03,  1.7175e-03,
          1.4136e-03,  2.4553e-03, -2.2968e-04,  2.3076e-04, -2.0567e-03,
         -1.5528e-03, -2.3539e-03,  3.3941e-04,  2.2556e-03, -2.3533e-04,
          7.6690e-04,  1.3919e-03,  6.1397e-04,  2.3538e-03,  2.4976e-04,
         -1.5234e-03, -1.7209e-04,  4.4593e-04, -1.1771e-04,  1.0526e-04,
          1.5502e-03,  2.8815e-03, -5.9326e-04,  1.6042e-03, -1.4385e-03,
          1.7740e-03, -2.8663e-04, -1.2939e-03, -7.6028e-04,  6.0507e-04,
          4.1868e-03, -1.6845e-04,  4.6786e-04,  3.0580e-04, -1.0233e-03,
          2.1526e-03, -1.2752e-03,  2.4019e-03,  8.9302e-04,  6.0359e-04,
          2.0567e-03,  6.3191e-04,  1.8957e-03, -6.7140e-04,  7.1267e-04,
         -1.0712e-03,  9.2152e-04,  2.8818e-03,  9.1477e-04, -6.7988e-04,
          9.0147e-04,  6.9048e-05,  9.6086e-04,  3.8630e-05,  6.1162e-04,
          8.1777e-04, -1.3141e-04, -1.3096e-03,  7.6292e-04,  6.3692e-04,
          1.5383e-03,  1.6643e-04,  1.5011e-03, -1.4076e-03,  2.4400e-03,
          2.0061e-04,  1.7191e-03,  8.2960e-05, -3.7548e-04, -4.7966e-05,
          1.5574e-03,  2.0555e-03,  6.0273e-04, -2.4294e-04,  4.3064e-04,
          1.2754e-03,  8.9654e-04,  2.2306e-03,  2.6711e-03, -4.6010e-04,
         -5.4773e-04,  7.3739e-05,  8.9156e-04,  3.4176e-03, -1.0556e-03,
          2.6059e-03,  1.8697e-03,  1.0284e-03,  1.9136e-03,  5.6104e-04,
          6.4472e-04,  9.8970e-04,  9.3768e-04, -3.3502e-04, -1.4548e-03,
         -1.6921e-03,  9.9499e-04,  2.7379e-04,  6.0283e-04, -1.1158e-04,
         -1.4154e-03, -7.8658e-05,  1.1612e-03,  5.8035e-04,  5.8914e-04,
         -1.4154e-03,  5.5411e-04,  1.4067e-03,  1.2320e-03,  1.3870e-03,
          9.7973e-04,  1.0853e-03, -1.0083e-03,  2.1379e-04,  2.2540e-03,
          2.7467e-04, -1.2941e-04,  9.2539e-04,  3.9027e-03,  1.0956e-03,
          3.9526e-04,  6.5961e-04, -7.9824e-04,  8.6294e-04,  1.1292e-03,
          5.9010e-04,  2.7059e-03],
        [-8.9219e-04,  1.1494e-03,  1.4018e-03, -2.1748e-04,  1.6598e-03,
         -2.0383e-03,  1.1231e-03,  2.8578e-04,  3.7230e-04, -1.9014e-03,
         -5.6970e-04, -1.0579e-03,  4.6282e-04, -1.4215e-03, -3.6969e-03,
          2.2526e-03, -1.2085e-03, -1.5393e-04,  6.7430e-04, -2.1551e-03,
         -2.0982e-03,  5.7686e-04, -5.0005e-04,  2.0740e-04,  4.8245e-04,
          9.6560e-04,  8.0336e-04, -4.8535e-04, -2.5804e-03, -1.0654e-03,
         -1.0281e-03, -2.4771e-04, -1.2661e-03, -4.6942e-04,  4.0056e-04,
          4.4702e-04, -4.7219e-05, -6.0611e-04,  1.4341e-04, -8.0878e-04,
         -4.8870e-04, -6.1536e-04, -1.4981e-03,  4.8502e-04,  1.6537e-03,
         -9.4762e-04,  1.6910e-04,  1.0207e-03, -9.2602e-04,  1.4651e-04,
         -1.7952e-03, -3.0916e-03, -3.1677e-03, -1.8759e-04, -2.1260e-03,
          7.2002e-04,  1.3418e-03, -1.4182e-03,  3.5948e-04,  1.4492e-03,
          2.0645e-03, -6.7543e-04,  1.7972e-04,  1.3219e-03,  1.3663e-03,
          1.1974e-03, -1.5368e-04,  8.0189e-04, -8.6345e-05, -5.2707e-04,
         -2.4294e-05,  2.0419e-03, -1.0922e-03, -8.5439e-04, -3.5844e-04,
         -4.0237e-04, -1.6805e-03,  9.7725e-04,  3.0565e-04,  4.4338e-04,
         -9.1680e-04, -1.7645e-03, -7.3409e-04, -7.3046e-04, -3.1409e-03,
         -6.5159e-05, -1.3961e-03, -1.4864e-03, -1.5441e-03, -2.3829e-04,
          3.7041e-04,  1.4258e-03,  9.0725e-04, -1.3066e-04, -6.6740e-04,
         -2.7436e-03, -1.9164e-03, -1.7680e-04, -2.4938e-04,  3.8392e-04,
         -8.7761e-04, -6.2462e-04, -2.2113e-03, -1.4919e-03,  1.2492e-03,
         -3.2339e-03, -4.9659e-04, -1.0881e-03,  3.1393e-04, -1.8359e-03,
         -7.2083e-04, -1.1850e-03,  6.2658e-04,  8.4481e-05, -1.2352e-03,
          5.7327e-04, -1.8708e-03,  1.5111e-03, -1.0498e-03, -6.5105e-04,
         -2.2461e-03, -4.8062e-04,  2.2678e-03,  7.7054e-04, -1.9181e-03,
         -2.8896e-03, -3.5064e-03,  4.4221e-04,  1.0501e-03, -1.5697e-03,
          4.6248e-04,  8.8087e-04, -1.7527e-03, -4.2164e-04, -1.9316e-03,
         -3.8792e-03, -2.1338e-03, -2.2770e-03, -7.5753e-04,  1.3511e-04,
         -2.2065e-03, -1.0725e-03, -2.1648e-03, -3.8765e-04, -1.8903e-03,
         -4.2626e-05,  4.4734e-04, -7.2551e-04, -3.1075e-03,  2.7632e-04,
         -2.3700e-03, -1.1020e-03,  2.7406e-04, -2.3475e-03, -9.9527e-04,
         -3.0538e-04, -1.5039e-04, -7.5042e-04,  8.0051e-05,  1.0963e-03,
         -4.3030e-04,  1.6159e-03, -1.7273e-03,  9.7715e-04, -3.8838e-04,
          2.8466e-04,  4.9191e-04,  6.4853e-04, -5.0614e-04,  7.6054e-04,
          9.4550e-04, -6.7307e-05,  1.5296e-04, -8.0453e-04, -3.1559e-03,
          1.3712e-03, -1.7107e-03,  1.2164e-04, -1.3095e-03, -7.6010e-04,
         -6.6342e-04, -1.5068e-03, -2.2506e-05, -1.9358e-03, -1.4318e-03,
         -5.5130e-04,  3.0776e-04,  5.7214e-04,  6.0863e-04, -2.1990e-03,
         -9.6020e-04,  1.7998e-03]], device='cuda:0')
Traceback (most recent call last):
  File "/home/huyiwen/CV/bilstm/distill.py", line 71, in <module>
    student_train(T_model, S_model, cfg, train_loader, test_loader)
  File "/home/huyiwen/CV/bilstm/student.py", line 131, in student_train
    print("==> name", name, param.grad.shape, param.grad)
  File "/home/huyiwen/miniconda3/envs/kd/lib/python3.10/site-packages/wandb/sdk/lib/redirect.py", line 643, in write
    cb(data)
  File "/home/huyiwen/miniconda3/envs/kd/lib/python3.10/site-packages/wandb/sdk/wandb_run.py", line 2123, in <lambda>
    lambda data: self._console_raw_callback("stdout", data),
  File "/home/huyiwen/miniconda3/envs/kd/lib/python3.10/site-packages/wandb/sdk/wandb_run.py", line 370, in wrapper_fn
    return func(self, *args, **kwargs)
  File "/home/huyiwen/miniconda3/envs/kd/lib/python3.10/site-packages/wandb/sdk/wandb_run.py", line 1465, in _console_raw_callback
    self._backend.interface.publish_output_raw(name, data)
  File "/home/huyiwen/miniconda3/envs/kd/lib/python3.10/site-packages/wandb/sdk/interface/interface.py", line 618, in publish_output_raw
    self._publish_output_raw(o)
  File "/home/huyiwen/miniconda3/envs/kd/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py", line 79, in _publish_output_raw
    self._publish(rec)
  File "/home/huyiwen/miniconda3/envs/kd/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/huyiwen/miniconda3/envs/kd/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py", line 221, in send_record_publish
    self.send_server_request(server_req)
  File "/home/huyiwen/miniconda3/envs/kd/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py", line 155, in send_server_request
    self._send_message(msg)
  File "/home/huyiwen/miniconda3/envs/kd/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py", line 152, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/huyiwen/miniconda3/envs/kd/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py", line 130, in _sendall_with_error_handle
    sent = self._sock.send(data)
KeyboardInterrupt