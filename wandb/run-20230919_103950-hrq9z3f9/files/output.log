
加载数据...
tensor([[  101,  4205,  5472,  ...,     0,     0,     0],
        [  101,  2019,  4024,  ...,     0,     0,     0],
        [  101,  2045,  1005,  ...,     0,     0,     0],
        ...,
        [  101,  2035,  1996,  ...,     0,     0,     0],
        [  101, 11552,  2135,  ...,     0,     0,     0],
        [  101,  1037,  4121,  ...,     0,     0,     0]])
Time usage: 0:00:10
Some weights of the model checkpoint at /home/huyiwen/pretrained/bert-base-uncased-SST-2 were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
BERT_Model(
  (bert): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0-11): 12 x BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (fc): Linear(in_features=768, out_features=192, bias=True)
  (fc1): Linear(in_features=192, out_features=2, bias=True)
)
cuda
biLSTM(
  (Embedding): Embedding(30522, 300)
  (lstm): LSTM(300, 300, batch_first=True, bidirectional=True)
  (fc1): Linear(in_features=600, out_features=192, bias=True)
  (fc2): Linear(in_features=192, out_features=2, bias=True)
)
10,717,178 total parameters.
Epoch [1/30]
s_logits tensor([[0.4773, 0.5227],
        [0.4840, 0.5160],
        [0.4748, 0.5252],
        [0.4847, 0.5153],
        [0.4798, 0.5202],
        [0.4893, 0.5107],
        [0.4852, 0.5148],
        [0.4929, 0.5071],
        [0.4747, 0.5253],
        [0.4861, 0.5139],
        [0.4815, 0.5185],
        [0.5015, 0.4985],
        [0.4974, 0.5026],
        [0.4883, 0.5117],
        [0.4966, 0.5034],
        [0.4848, 0.5152],
        [0.4911, 0.5089],
        [0.4943, 0.5057],
        [0.4831, 0.5169],
        [0.4812, 0.5188],
        [0.4877, 0.5123],
        [0.4851, 0.5149],
        [0.4872, 0.5128],
        [0.4819, 0.5181],
        [0.4877, 0.5123],
        [0.4821, 0.5179],
        [0.5041, 0.4959],
        [0.4794, 0.5206],
        [0.4903, 0.5097],
        [0.4899, 0.5101],
        [0.4875, 0.5125],
        [0.4926, 0.5074],
        [0.4905, 0.5095],
        [0.4951, 0.5049],
        [0.4869, 0.5131],
        [0.4880, 0.5120],
        [0.4870, 0.5130],
        [0.4922, 0.5078],
        [0.4858, 0.5142],
        [0.4865, 0.5135],
        [0.4834, 0.5166],
        [0.4867, 0.5133],
        [0.4930, 0.5070],
        [0.4832, 0.5168],
        [0.4877, 0.5123],
        [0.4843, 0.5157],
        [0.4855, 0.5145],
        [0.4865, 0.5135],
        [0.4893, 0.5107],
        [0.4866, 0.5134],
        [0.4911, 0.5089],
        [0.4856, 0.5144],
        [0.4889, 0.5111],
        [0.4826, 0.5174],
        [0.4836, 0.5164],
        [0.4897, 0.5103],
        [0.4882, 0.5118],
        [0.4888, 0.5112],
        [0.4863, 0.5137],
        [0.4895, 0.5105],
        [0.4830, 0.5170],
        [0.4989, 0.5011],
        [0.4815, 0.5185],
        [0.4785, 0.5215]], device='cuda:0', grad_fn=<SoftmaxBackward0>) label tensor([0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,
        0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0,
        1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1], device='cuda:0')
t_logits tensor([[9.9947e-01, 5.3368e-04],
        [1.2205e-02, 9.8779e-01],
        [9.9808e-01, 1.9192e-03],
        [9.9885e-01, 1.1547e-03],
        [3.9347e-03, 9.9607e-01],
        [5.3743e-03, 9.9463e-01],
        [9.5874e-01, 4.1255e-02],
        [3.5135e-03, 9.9649e-01],
        [9.2223e-01, 7.7773e-02],
        [4.1820e-03, 9.9582e-01],
        [9.9900e-01, 9.9894e-04],
        [9.9904e-01, 9.6125e-04],
        [9.1609e-01, 8.3912e-02],
        [3.0861e-03, 9.9691e-01],
        [4.1088e-03, 9.9589e-01],
        [9.9472e-01, 5.2836e-03],
        [1.4192e-02, 9.8581e-01],
        [1.5545e-02, 9.8446e-01],
        [4.5848e-02, 9.5415e-01],
        [5.4886e-03, 9.9451e-01],
        [9.9874e-01, 1.2551e-03],
        [9.9950e-01, 5.0455e-04],
        [9.9912e-01, 8.7586e-04],
        [9.9855e-01, 1.4496e-03],
        [3.8550e-03, 9.9615e-01],
        [3.0349e-03, 9.9697e-01],
        [9.9906e-01, 9.3514e-04],
        [9.9930e-01, 7.0369e-04],
        [4.0615e-03, 9.9594e-01],
        [4.2186e-03, 9.9578e-01],
        [4.2164e-03, 9.9578e-01],
        [9.9280e-01, 7.2048e-03],
        [9.9821e-01, 1.7895e-03],
        [9.9936e-01, 6.4397e-04],
        [3.5035e-03, 9.9650e-01],
        [9.9912e-01, 8.8046e-04],
        [9.9697e-01, 3.0259e-03],
        [9.9921e-01, 7.8953e-04],
        [9.9807e-01, 1.9271e-03],
        [9.9935e-01, 6.5100e-04],
        [4.0775e-03, 9.9592e-01],
        [9.7800e-01, 2.1997e-02],
        [9.1303e-03, 9.9087e-01],
        [2.9660e-03, 9.9703e-01],
        [7.3085e-03, 9.9269e-01],
        [9.9474e-01, 5.2644e-03],
        [9.6431e-01, 3.5686e-02],
        [9.9511e-01, 4.8911e-03],
        [9.9947e-01, 5.2820e-04],
        [9.9789e-01, 2.1140e-03],
        [9.9562e-01, 4.3801e-03],
        [9.9917e-01, 8.3110e-04],
        [5.5824e-03, 9.9442e-01],
        [3.1015e-03, 9.9690e-01],
        [5.6073e-03, 9.9439e-01],
        [9.6293e-01, 3.7073e-02],
        [1.6173e-02, 9.8383e-01],
        [1.1644e-02, 9.8836e-01],
        [7.2993e-03, 9.9270e-01],
        [9.9913e-01, 8.7073e-04],
        [4.8140e-03, 9.9519e-01],
        [9.9937e-01, 6.2513e-04],
        [5.6990e-03, 9.9430e-01],
        [5.8538e-03, 9.9415e-01]], device='cuda:0')
base_loss tensor(0.6930, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(0.2418, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor([  101,  2009,  3084,  2033,  2514,  6881,  1032,  1013,  3241,  2055,
         2035,  1996,  2919,  2477,  1999,  1996,  2088,  1032,  1013,  2066,
        26781, 13046,  2007,  3714,  3456,  1032,  1013,  1998, 15023,  2008,
         3280,  1032,  1013,  1998,  5691,  4626,  3769,  8603,   102,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0], device='cuda:0')
==> name Embedding.weight torch.Size([30522, 300]) tensor([[-2.9295e-05,  3.3053e-06, -1.2505e-05,  ...,  2.6403e-05,
          9.3589e-06, -2.2155e-05],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]], device='cuda:0')
==> name lstm.weight_ih_l0 torch.Size([1200, 300]) tensor([[-1.6675e-05, -1.2395e-04,  1.2946e-05,  ...,  2.6398e-05,
         -7.8244e-05, -3.9243e-06],
        [ 1.7894e-05,  2.1899e-05, -1.7054e-05,  ..., -1.9401e-06,
          2.9978e-05,  7.4291e-06],
        [-1.9433e-05, -4.1803e-05, -7.2578e-07,  ...,  1.3894e-05,
          1.0953e-06, -7.2114e-07],
        ...,
        [-1.1859e-05, -2.4305e-05, -4.5699e-06,  ...,  3.4159e-05,
         -4.0185e-05,  1.7461e-05],
        [ 3.7486e-05,  9.1290e-06, -3.0394e-05,  ...,  4.5073e-05,
          1.5996e-05,  2.1749e-05],
        [ 7.7777e-06,  1.6416e-05,  8.6062e-07,  ..., -8.8775e-08,
          4.1225e-06, -2.4020e-05]], device='cuda:0')
==> name lstm.weight_hh_l0 torch.Size([1200, 300]) tensor([[-3.7335e-06, -2.0494e-06,  4.5470e-06,  ..., -2.3412e-06,
          5.6245e-06,  6.9529e-06],
        [-2.5878e-06,  1.2885e-06, -5.6717e-06,  ..., -3.1674e-06,
         -3.8239e-06,  7.0940e-07],
        [ 8.8620e-07, -1.7579e-06,  3.7485e-07,  ..., -1.8464e-06,
         -8.4626e-07, -2.3473e-06],
        ...,
        [-5.9021e-06, -5.6939e-07, -4.9866e-06,  ..., -1.9352e-06,
          4.2306e-06, -1.9777e-06],
        [-2.2010e-06,  3.1026e-06,  7.8407e-08,  ...,  5.9750e-07,
          2.1278e-06,  3.9274e-06],
        [ 3.6669e-07,  3.8131e-06, -1.2545e-06,  ...,  3.4301e-06,
          4.1163e-06, -9.4094e-06]], device='cuda:0')
==> name lstm.bias_ih_l0 torch.Size([1200]) tensor([-3.3297e-05, -4.2846e-05, -1.7956e-06,  ..., -5.3851e-06,
        -1.3374e-05,  4.4864e-05], device='cuda:0')
==> name lstm.bias_hh_l0 torch.Size([1200]) tensor([-3.3297e-05, -4.2846e-05, -1.7956e-06,  ..., -5.3851e-06,
        -1.3374e-05,  4.4864e-05], device='cuda:0')
==> name lstm.weight_ih_l0_reverse torch.Size([1200, 300]) tensor([[ 2.7350e-05, -3.3087e-05,  7.1234e-06,  ...,  2.5681e-05,
          1.9858e-06, -1.1766e-05],
        [ 4.0696e-06,  7.5091e-05,  8.8980e-05,  ..., -7.3885e-05,
         -5.3958e-05, -3.6012e-05],
        [-3.8685e-06, -3.2117e-05, -3.6412e-05,  ...,  4.8187e-05,
         -3.0786e-05,  1.7530e-05],
        ...,
        [ 5.5617e-06, -2.1728e-05, -6.3521e-06,  ...,  2.4454e-05,
         -1.5594e-05, -8.4120e-06],
        [ 3.1867e-05,  8.4122e-06,  6.1410e-06,  ...,  1.9939e-05,
          1.7045e-05,  1.8476e-05],
        [ 1.8714e-05, -1.2775e-05, -2.4975e-05,  ..., -3.4263e-05,
         -5.9082e-05,  3.4133e-05]], device='cuda:0')
==> name lstm.weight_hh_l0_reverse torch.Size([1200, 300]) tensor([[-1.3182e-06,  3.5319e-06, -3.3547e-06,  ...,  2.1938e-06,
          1.5971e-06, -1.1969e-07],
        [-6.2876e-06, -5.6563e-06,  4.3930e-07,  ..., -9.4341e-06,
         -6.9235e-07,  1.1788e-06],
        [-1.2774e-06,  6.7388e-07,  1.4131e-06,  ..., -1.6129e-07,
         -3.2024e-07,  1.2725e-05],
        ...,
        [ 1.7953e-06,  1.9392e-06,  2.5907e-06,  ...,  2.0266e-06,
         -8.7593e-09, -3.8599e-06],
        [-2.9447e-06,  2.3509e-06, -2.5067e-07,  ...,  3.1388e-06,
          2.5346e-06, -3.4478e-06],
        [ 4.4348e-06, -5.3972e-06, -3.9753e-06,  ..., -1.3537e-06,
          9.7805e-06,  1.3609e-05]], device='cuda:0')
==> name lstm.bias_ih_l0_reverse torch.Size([1200]) tensor([-2.8496e-05,  1.6208e-05, -5.2631e-06,  ..., -5.0612e-06,
         1.9240e-05, -3.4503e-05], device='cuda:0')
==> name lstm.bias_hh_l0_reverse torch.Size([1200]) tensor([-2.8496e-05,  1.6208e-05, -5.2631e-06,  ..., -5.0612e-06,
         1.9240e-05, -3.4503e-05], device='cuda:0')
==> name fc1.weight torch.Size([192, 600]) tensor([[-6.1222e-04, -1.2121e-04, -2.4883e-04,  ..., -9.7700e-05,
         -1.1008e-04,  1.4417e-04],
        [-7.6041e-04, -1.8911e-04, -1.3293e-04,  ..., -7.7425e-05,
          1.9333e-04,  3.7515e-04],
        [ 2.4234e-05,  3.9308e-04, -3.0887e-04,  ...,  3.8992e-06,
         -6.0397e-05,  4.6578e-05],
        ...,
        [ 2.2092e-04,  1.7717e-04, -1.2586e-04,  ...,  1.0850e-04,
         -3.4010e-05,  1.1475e-05],
        [-7.8209e-05, -2.3422e-04, -1.1100e-04,  ...,  1.0322e-04,
          9.4679e-05,  2.3545e-04],
        [-2.9087e-04, -4.5295e-04,  2.4390e-05,  ...,  6.6789e-05,
          4.9023e-05,  5.0750e-05]], device='cuda:0')
==> name fc1.bias torch.Size([192]) tensor([ 5.6226e-04, -8.3838e-04,  2.1182e-03, -2.2383e-04, -6.7815e-04,
         2.1834e-04, -1.0497e-03,  1.5927e-04,  3.5988e-04,  1.2712e-03,
         3.1422e-03,  1.8132e-04,  7.2148e-04, -1.2059e-03, -3.1657e-04,
        -9.2605e-04,  6.8268e-04, -3.3557e-04, -9.3197e-05, -1.7811e-03,
        -7.5199e-04,  1.0350e-03,  1.6216e-03, -3.6291e-04,  5.6178e-04,
        -6.8056e-04,  1.7480e-03, -4.0759e-04,  2.9809e-04, -6.4658e-04,
        -1.3759e-04,  1.7868e-03, -2.5742e-03,  1.5758e-03, -9.4705e-04,
         5.6664e-04, -3.7312e-04,  8.2918e-04,  1.6207e-03, -4.7709e-04,
        -6.0320e-04,  6.7918e-04, -9.2833e-04,  2.0032e-04, -1.5557e-04,
         3.3028e-03, -2.9501e-04,  2.3483e-04, -6.9188e-04, -1.5995e-03,
         2.3310e-04,  3.3670e-03, -9.5246e-04,  9.9878e-04,  2.0571e-03,
         2.4971e-04, -2.5101e-03, -1.9184e-03, -3.7852e-04,  2.1922e-03,
        -1.4773e-04,  6.1039e-04, -1.7346e-04,  3.5856e-05, -5.3284e-04,
         1.7087e-03, -1.2520e-03, -9.6073e-04,  1.1753e-05, -8.6337e-04,
         1.2090e-04, -7.1399e-04, -1.0485e-03, -1.0953e-03, -1.7877e-03,
         1.5292e-03, -5.2487e-04, -9.6671e-04,  3.6649e-06, -2.8812e-04,
         2.1270e-03,  2.3279e-04, -1.4480e-04,  2.2699e-04,  2.2739e-04,
         2.1705e-04,  4.3080e-05, -5.3211e-04, -9.9161e-04, -1.8334e-04,
         1.8800e-03, -5.2364e-04, -1.5536e-03,  4.8151e-04, -1.3552e-03,
         4.1212e-04, -1.4631e-03,  2.8984e-04, -9.5717e-04, -1.2059e-04,
        -9.0791e-04, -1.1553e-03,  1.6405e-04,  8.3839e-04,  4.8298e-04,
        -7.7703e-04,  1.5311e-03,  2.2114e-03, -5.0621e-04, -8.4281e-04,
         9.9350e-05,  2.2083e-04, -2.7687e-04,  5.8868e-05,  5.6864e-04,
         8.0735e-04, -3.5499e-04, -8.0482e-04, -2.8249e-03,  2.6637e-04,
         4.7386e-04,  4.3225e-04,  3.7250e-04,  1.5984e-03,  9.0511e-05,
         2.5155e-03,  2.0997e-03, -1.6329e-04, -3.7548e-04,  1.5926e-07,
        -7.3706e-04,  3.7850e-04, -1.8931e-06, -2.4401e-04,  6.6922e-04,
        -1.0575e-03, -8.8469e-04,  1.7223e-03,  1.6766e-03,  4.1782e-04,
         7.7973e-05,  1.4380e-03, -4.0099e-04,  9.0340e-04,  9.5663e-04,
         9.0456e-04,  1.7577e-03, -2.9195e-04,  1.4660e-04,  9.6813e-04,
        -5.9850e-04, -2.3997e-04,  1.0621e-03,  1.3919e-03,  2.0983e-04,
        -1.6357e-05, -8.8070e-04, -1.0369e-03, -5.6056e-04,  1.0839e-03,
        -1.9760e-04, -1.1272e-03, -1.7065e-03, -5.6697e-04, -3.4022e-03,
        -1.1707e-04, -5.4510e-05, -2.2927e-03,  2.6006e-03, -9.4481e-04,
        -3.3527e-04,  1.3174e-04,  1.8242e-03, -2.6258e-04, -7.6088e-04,
        -7.5752e-06,  6.0920e-04, -2.2731e-03, -5.0994e-04, -1.0497e-03,
         5.7513e-06, -9.7124e-05,  1.7239e-03,  3.2278e-04,  1.9563e-04,
         6.1977e-04, -1.8845e-04,  1.6054e-03, -4.0660e-04,  4.7450e-04,
        -1.1165e-03, -2.5992e-03], device='cuda:0')
==> name fc2.weight torch.Size([2, 192]) tensor([[ 1.7882e-03, -4.1385e-04, -2.1695e-04, -7.3722e-04,  1.7951e-04,
          4.8219e-04, -2.0075e-03,  6.7527e-04, -5.3781e-04, -4.0964e-04,
         -2.6392e-03,  2.0031e-04,  2.3792e-03, -2.1261e-03, -7.5141e-04,
         -5.5978e-04, -1.3993e-03,  6.6326e-04, -2.8159e-03, -1.5124e-03,
         -4.9749e-04,  4.0999e-05,  9.9941e-04, -1.2068e-03, -2.0159e-03,
         -8.8190e-04, -1.6633e-03, -2.8211e-03,  6.3772e-04, -7.2195e-04,
          1.0103e-03, -1.1954e-04,  4.5029e-04,  2.5037e-04,  1.9336e-04,
         -4.8927e-06, -6.1133e-04, -2.5585e-03,  3.6797e-03, -1.1079e-03,
         -9.1042e-05,  8.0677e-05, -3.7928e-04, -1.0784e-03, -1.6820e-03,
         -1.1611e-03, -1.4565e-03, -8.6256e-04, -2.2928e-03, -1.1130e-03,
         -4.3870e-04, -1.2202e-03, -6.7258e-04,  2.8633e-03,  6.7999e-04,
         -1.8982e-03, -1.7027e-03, -7.6495e-04, -2.3676e-03, -1.5913e-03,
          1.6667e-03,  8.7386e-04, -6.4766e-04, -1.7851e-03, -7.8152e-04,
         -6.4494e-05, -1.7508e-03, -1.8524e-03,  2.0940e-03, -1.1537e-03,
         -7.2062e-04,  5.3768e-04, -1.0913e-03, -3.4107e-03,  9.3141e-04,
         -1.0782e-03, -3.1996e-03,  4.8886e-04, -1.3642e-03,  9.9299e-05,
          2.7491e-03, -9.2976e-06,  1.3307e-04,  2.6364e-04,  1.6710e-03,
          1.5050e-03, -1.0331e-03, -3.7591e-04, -2.1216e-03,  1.4614e-03,
          4.5561e-04, -8.7806e-05,  9.8707e-04,  9.0159e-04, -1.0508e-03,
         -1.0861e-03, -1.1481e-03,  6.3488e-05,  1.2931e-03, -2.3086e-05,
         -2.3723e-03, -2.8043e-03,  3.4936e-04, -2.2104e-03, -4.9465e-04,
          2.3692e-04, -1.2090e-03, -3.1434e-04, -3.1993e-04,  1.5084e-03,
          1.6275e-03, -1.1096e-03, -4.8229e-04, -1.4606e-05, -1.0876e-03,
         -1.0413e-03, -5.9826e-04,  4.3520e-05, -2.4145e-03,  9.2346e-04,
         -8.5222e-04, -6.2168e-04, -1.3684e-03, -1.1500e-03,  6.7768e-04,
          7.9076e-04, -9.7131e-04,  8.5942e-04, -1.7343e-03, -4.5035e-05,
         -2.7086e-03,  5.9186e-04, -1.2561e-04,  1.2278e-03, -1.2319e-03,
         -2.1351e-03, -2.7072e-03, -1.8479e-03, -1.7186e-03,  8.7793e-04,
          8.0411e-04, -3.1966e-03, -3.4156e-04,  1.8051e-03, -1.7183e-03,
         -1.3717e-03,  1.9468e-03, -2.1501e-03, -2.0571e-03, -1.8873e-03,
         -1.2550e-03, -1.4354e-03, -1.3824e-03, -3.3041e-04, -3.2283e-04,
          9.4177e-04,  9.5461e-04, -1.7339e-03,  6.0725e-04, -7.4688e-04,
          1.2354e-03, -9.8749e-04, -1.8510e-03, -1.3853e-03, -1.8945e-03,
          2.0080e-03, -2.6553e-04, -2.2929e-03,  2.0498e-03,  2.4298e-03,
          1.0828e-03,  2.1143e-04, -3.8029e-04, -1.2270e-03, -2.0004e-03,
          1.3860e-04, -1.6709e-04, -3.3605e-03,  4.7376e-04,  8.0522e-05,
         -6.8278e-04, -1.0957e-03, -3.0721e-04,  4.9824e-04, -3.1149e-03,
         -8.6292e-04, -1.4562e-03, -1.4838e-03,  1.5398e-03, -9.7877e-04,
         -4.7172e-03, -3.0250e-03],
        [-3.3838e-04, -2.4796e-03, -9.5013e-05,  3.5939e-03, -3.0549e-03,
         -9.6500e-04,  5.1644e-05, -4.8920e-04,  1.3200e-03,  2.0482e-03,
         -1.0742e-03,  1.7753e-03,  1.1571e-03,  2.1757e-03,  5.0871e-04,
          4.8363e-03,  1.2775e-03,  5.7185e-05,  4.3019e-04, -2.4327e-04,
         -7.6615e-04, -2.3841e-05,  3.1664e-03,  2.1331e-03,  1.2857e-03,
          2.8638e-03,  2.8199e-03,  7.0595e-04, -4.6484e-04, -1.0054e-03,
          2.1206e-04, -2.8470e-03,  3.2433e-03,  1.4555e-03,  1.2798e-03,
          1.8817e-03,  3.0301e-03,  3.0902e-03, -3.6869e-04,  6.2013e-04,
          1.5084e-03,  1.4414e-03,  2.8514e-03,  3.1404e-04,  1.5241e-03,
         -2.4643e-03, -1.5019e-04, -6.9982e-04,  1.7136e-03,  1.4805e-03,
         -1.7086e-04,  4.8463e-03, -6.1547e-03,  3.4118e-03, -1.9598e-03,
          9.9111e-04,  3.1903e-03,  2.7243e-03, -2.3881e-03,  5.1984e-03,
          6.4512e-04,  1.4631e-03,  1.0678e-03,  1.9861e-03, -1.7998e-03,
         -5.8932e-04,  2.3875e-03,  1.1028e-03,  5.3799e-05,  1.6540e-03,
          5.0363e-04,  1.4070e-03,  2.7224e-03, -1.0771e-03,  2.4733e-04,
          9.1992e-04,  2.4299e-03, -1.4258e-03,  4.0731e-03, -2.7517e-05,
          1.0029e-03, -1.1739e-03, -8.5794e-04,  2.3453e-04, -3.4133e-03,
         -7.3865e-04, -8.8413e-04, -2.3372e-04,  1.1347e-03,  1.0235e-03,
          2.7170e-03,  6.7579e-04,  2.7405e-03,  2.3939e-03,  1.9552e-03,
          8.7014e-04, -4.5636e-03, -1.3422e-03,  1.4116e-03,  1.6245e-03,
         -5.4993e-04, -5.4882e-05, -1.0633e-03,  1.2193e-03, -4.5185e-04,
         -3.0777e-04,  1.7905e-04,  4.5121e-03,  1.2392e-03,  4.0486e-04,
         -2.4524e-04,  6.5639e-04,  1.9620e-03,  9.0869e-04, -1.0816e-03,
          6.1587e-04,  3.3962e-03, -2.5266e-03,  7.9911e-04, -1.6668e-03,
          6.1209e-05, -1.1881e-03, -1.2197e-03,  1.5440e-03, -1.0078e-03,
          3.0712e-03,  3.1618e-03, -4.1828e-04,  2.7398e-06,  2.9047e-03,
          1.8240e-03,  1.2155e-03, -1.5911e-03, -2.3541e-03,  1.9289e-03,
          9.5078e-04,  3.2583e-03,  3.4183e-03, -1.2775e-03,  1.3142e-03,
          2.6827e-04, -6.9528e-04, -3.9192e-04,  2.7112e-03,  1.1835e-04,
          5.5442e-05,  1.5070e-03,  2.2979e-03,  1.5182e-03,  2.4701e-03,
          1.0646e-03, -5.6676e-05,  2.1681e-03,  3.6227e-03,  3.6474e-04,
          6.5551e-04,  1.1570e-03, -1.6520e-03,  1.3268e-03,  9.8194e-04,
          2.0601e-03,  1.4937e-03,  7.8625e-04,  5.3126e-04,  3.3823e-03,
         -1.6267e-03,  1.1461e-03,  1.7368e-03,  4.5674e-03,  1.9005e-03,
          1.3297e-03,  8.4269e-04,  2.3399e-03,  4.4875e-04,  1.7891e-03,
          2.5373e-04,  1.9116e-03,  5.4618e-04,  4.0420e-04,  3.0108e-04,
          1.4644e-03,  3.0634e-04,  1.5539e-03,  1.2403e-03,  1.3062e-03,
         -2.0083e-03,  3.9312e-04, -1.1965e-03,  1.0770e-03,  3.5023e-03,
          1.2179e-03,  8.3854e-04]], device='cuda:0')
==> name fc2.bias torch.Size([2]) tensor([-0.0211,  0.0211], device='cuda:0')
Iter:      0,  Train Loss:  0.24,  Train Acc: 48.44%,  Val Loss:  0.22,  Val Acc: 51.18%,  Time: 0:00:02 *,  LR: 0.9972609476841366
s_logits tensor([[0.4672, 0.5328],
        [0.4505, 0.5495],
        [0.4717, 0.5283],
        [0.4674, 0.5326],
        [0.4724, 0.5276],
        [0.4665, 0.5335],
        [0.4495, 0.5505],
        [0.4749, 0.5251],
        [0.4645, 0.5355],
        [0.4677, 0.5323],
        [0.4610, 0.5390],
        [0.4614, 0.5386],
        [0.4662, 0.5338],
        [0.4652, 0.5348],
        [0.4625, 0.5375],
        [0.4691, 0.5309],
        [0.4598, 0.5402],
        [0.4687, 0.5313],
        [0.4604, 0.5396],
        [0.4762, 0.5238],
        [0.4661, 0.5339],
        [0.4669, 0.5331],
        [0.4662, 0.5338],
        [0.4605, 0.5395],
        [0.4726, 0.5274],
        [0.4829, 0.5171],
        [0.4599, 0.5401],
        [0.4680, 0.5320],
        [0.4686, 0.5314],
        [0.4690, 0.5310],
        [0.4663, 0.5337],
        [0.4526, 0.5474],
        [0.4719, 0.5281],
        [0.4602, 0.5398],
        [0.4829, 0.5171],
        [0.4647, 0.5353],
        [0.4592, 0.5408],
        [0.4673, 0.5327],
        [0.4423, 0.5577],
        [0.4623, 0.5377],
        [0.4569, 0.5431],
        [0.4659, 0.5341],
        [0.4639, 0.5361],
        [0.4645, 0.5355],
        [0.4552, 0.5448],
        [0.4596, 0.5404],
        [0.4809, 0.5191],
        [0.4657, 0.5343],
        [0.4562, 0.5438],
        [0.4610, 0.5390],
        [0.4621, 0.5379],
        [0.4748, 0.5252],
        [0.4599, 0.5401],
        [0.4756, 0.5244],
        [0.4829, 0.5171],
        [0.4584, 0.5416],
        [0.4648, 0.5352],
        [0.4602, 0.5398],
        [0.4483, 0.5517],
        [0.4621, 0.5379],
        [0.4452, 0.5548],
        [0.4651, 0.5349],
        [0.4616, 0.5384],
        [0.4716, 0.5284]], device='cuda:0', grad_fn=<SoftmaxBackward0>) label tensor([0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1,
        1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0,
        1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1], device='cuda:0')
t_logits tensor([[3.6535e-03, 9.9635e-01],
        [8.5200e-02, 9.1480e-01],
        [9.9759e-01, 2.4075e-03],
        [9.8347e-01, 1.6529e-02],
        [9.9656e-01, 3.4396e-03],
        [9.9897e-01, 1.0284e-03],
        [9.9876e-01, 1.2386e-03],
        [8.9474e-01, 1.0526e-01],
        [1.7154e-02, 9.8285e-01],
        [7.8416e-03, 9.9216e-01],
        [9.9947e-01, 5.3270e-04],
        [9.9902e-01, 9.7864e-04],
        [9.9658e-01, 3.4200e-03],
        [7.4760e-03, 9.9252e-01],
        [5.5121e-03, 9.9449e-01],
        [9.9818e-01, 1.8217e-03],
        [9.9763e-01, 2.3679e-03],
        [9.9828e-01, 1.7159e-03],
        [9.9196e-01, 8.0375e-03],
        [9.8732e-01, 1.2684e-02],
        [9.9913e-01, 8.7289e-04],
        [9.9762e-01, 2.3800e-03],
        [2.9597e-03, 9.9704e-01],
        [9.9868e-01, 1.3227e-03],
        [9.8777e-01, 1.2229e-02],
        [3.2997e-02, 9.6700e-01],
        [4.0559e-03, 9.9594e-01],
        [1.0727e-02, 9.8927e-01],
        [1.6889e-02, 9.8311e-01],
        [9.9938e-01, 6.1934e-04],
        [3.1060e-03, 9.9689e-01],
        [9.9907e-01, 9.3411e-04],
        [9.9672e-01, 3.2779e-03],
        [4.5648e-03, 9.9544e-01],
        [3.7807e-02, 9.6219e-01],
        [5.6310e-03, 9.9437e-01],
        [9.8587e-01, 1.4132e-02],
        [9.8950e-01, 1.0499e-02],
        [3.9312e-03, 9.9607e-01],
        [4.4445e-03, 9.9556e-01],
        [9.9902e-01, 9.7928e-04],
        [9.9541e-01, 4.5851e-03],
        [9.9492e-01, 5.0788e-03],
        [9.9911e-01, 8.9491e-04],
        [4.4977e-03, 9.9550e-01],
        [5.4439e-03, 9.9456e-01],
        [9.9627e-01, 3.7299e-03],
        [4.3933e-03, 9.9561e-01],
        [9.9934e-01, 6.6126e-04],
        [9.9890e-01, 1.0952e-03],
        [3.5763e-03, 9.9642e-01],
        [3.7101e-03, 9.9629e-01],
        [3.5931e-03, 9.9641e-01],
        [5.6526e-03, 9.9435e-01],
        [9.9926e-01, 7.4279e-04],
        [3.3738e-03, 9.9663e-01],
        [9.9906e-01, 9.4135e-04],
        [9.7151e-01, 2.8491e-02],
        [9.8061e-02, 9.0194e-01],
        [9.9738e-01, 2.6226e-03],
        [4.0014e-03, 9.9600e-01],
        [9.9899e-01, 1.0121e-03],
        [9.9566e-01, 4.3449e-03],
        [2.7041e-03, 9.9730e-01]], device='cuda:0')
base_loss tensor(0.6973, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(0.2453, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor([  101,  2007,  2062,  2839,  2458,  2023,  2453,  2031,  2042,  2019,
        18823, 10874,  1025,  2007,  2488,  3477, 27475,  1010,  2009,  2071,
         2031,  2042,  1037,  3241,  2158,  1005,  1055,  6071,  3185,  1012,
          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0], device='cuda:0')
==> name Embedding.weight torch.Size([30522, 300]) tensor([[-4.7117e-07,  9.9422e-06,  1.3211e-05,  ..., -7.4900e-06,
         -3.6467e-06,  7.0208e-06],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]], device='cuda:0')
==> name lstm.weight_ih_l0 torch.Size([1200, 300]) tensor([[-5.1490e-05,  2.7387e-05, -1.1380e-05,  ..., -4.5505e-05,
          2.0478e-06, -4.0140e-06],
        [ 3.0085e-06,  3.1383e-07, -4.2921e-06,  ...,  8.8345e-06,
          1.0960e-05,  7.2634e-06],
        [ 1.7895e-06,  5.8923e-06,  9.0628e-06,  ...,  1.0192e-07,
          7.1200e-06,  6.9057e-07],
        ...,
        [-9.2885e-06, -1.7439e-05,  4.9365e-05,  ...,  1.4679e-05,
          1.9337e-05,  2.2834e-05],
        [ 7.2113e-06, -1.2370e-05, -5.2568e-06,  ..., -4.3122e-06,
          1.2131e-05, -2.9546e-05],
        [ 3.1390e-05, -5.5591e-05, -6.1316e-06,  ...,  8.8863e-06,
          1.3562e-05,  1.1227e-05]], device='cuda:0')
==> name lstm.weight_hh_l0 torch.Size([1200, 300]) tensor([[ 3.2058e-06, -4.2263e-06, -4.7201e-06,  ..., -6.6998e-06,
         -4.1717e-06, -4.5917e-08],
        [-7.0212e-06,  2.6403e-06, -1.2964e-06,  ..., -2.3022e-07,
         -2.3126e-06, -8.4994e-06],
        [ 5.7645e-06,  2.3052e-06,  1.3156e-06,  ..., -3.9986e-06,
         -1.2213e-06,  4.6209e-06],
        ...,
        [ 6.7873e-07,  4.9230e-07, -3.0183e-07,  ..., -2.7335e-06,
         -3.7670e-06, -1.9434e-06],
        [-5.2754e-06, -3.0605e-07,  1.3146e-05,  ...,  2.1303e-07,
         -5.2108e-06, -2.0942e-06],
        [ 7.8216e-06, -1.8743e-06,  4.4806e-06,  ...,  5.4425e-07,
         -1.7505e-06,  4.5010e-06]], device='cuda:0')
==> name lstm.bias_ih_l0 torch.Size([1200]) tensor([-3.8639e-05,  4.7077e-05, -2.2283e-05,  ..., -4.3068e-05,
        -1.1236e-05, -1.0705e-05], device='cuda:0')
==> name lstm.bias_hh_l0 torch.Size([1200]) tensor([-3.8639e-05,  4.7077e-05, -2.2283e-05,  ..., -4.3068e-05,
        -1.1236e-05, -1.0705e-05], device='cuda:0')
==> name lstm.weight_ih_l0_reverse torch.Size([1200, 300]) tensor([[ 8.8428e-06,  6.2787e-06,  1.0395e-05,  ...,  2.5335e-05,
         -9.5399e-06,  1.1464e-05],
        [ 9.2522e-06, -1.4672e-05, -3.5603e-05,  ..., -1.1722e-05,
         -4.0552e-05,  3.2497e-06],
        [ 1.0878e-05, -6.1311e-05, -4.7219e-05,  ..., -1.4603e-05,
          1.5133e-05, -9.4341e-06],
        ...,
        [-1.2804e-05,  4.4061e-05,  2.8506e-05,  ...,  2.6406e-05,
         -1.2080e-07,  1.6972e-05],
        [ 2.1343e-05, -1.8805e-05,  4.0643e-06,  ..., -2.1680e-05,
          2.5517e-05, -3.5499e-05],
        [-9.7444e-06, -5.4083e-06, -1.2458e-05,  ...,  9.4559e-06,
         -6.3874e-06, -6.2816e-06]], device='cuda:0')
==> name lstm.weight_hh_l0_reverse torch.Size([1200, 300]) tensor([[-2.6762e-06,  6.5483e-06, -1.7599e-06,  ..., -5.2880e-06,
         -5.6412e-06,  6.7748e-06],
        [ 4.3090e-06,  1.6227e-06,  1.0008e-05,  ...,  6.5689e-07,
         -1.7000e-06, -1.8223e-06],
        [ 5.8079e-06, -6.3602e-06,  5.2670e-06,  ...,  6.3229e-06,
         -3.0023e-06,  2.7672e-06],
        ...,
        [-4.0188e-06,  4.5482e-07, -4.9719e-06,  ..., -7.9670e-06,
          9.7291e-07,  6.9637e-06],
        [ 1.1918e-06,  2.9334e-06, -2.1941e-06,  ..., -7.0790e-06,
         -2.5577e-06, -4.3764e-06],
        [ 5.4816e-06, -1.6739e-06,  4.6166e-06,  ..., -9.4928e-06,
         -1.4439e-07,  1.1355e-05]], device='cuda:0')
==> name lstm.bias_ih_l0_reverse torch.Size([1200]) tensor([-9.0028e-06,  2.9160e-05, -9.7394e-06,  ..., -9.4872e-06,
         7.9544e-06, -3.2793e-06], device='cuda:0')
==> name lstm.bias_hh_l0_reverse torch.Size([1200]) tensor([-9.0028e-06,  2.9160e-05, -9.7394e-06,  ..., -9.4872e-06,
         7.9544e-06, -3.2793e-06], device='cuda:0')
==> name fc1.weight torch.Size([192, 600]) tensor([[-1.5184e-04,  4.6295e-06, -1.5512e-04,  ..., -2.4435e-04,
         -1.8487e-04,  2.3713e-06],
        [-7.8326e-05,  3.4573e-05, -4.4194e-05,  ..., -1.0425e-04,
         -2.3158e-04,  7.0512e-05],
        [-1.7424e-04,  1.1136e-04,  1.9914e-05,  ..., -1.7690e-04,
         -6.5822e-05,  1.7844e-04],
        ...,
        [-1.8029e-04, -4.4873e-06, -8.5130e-05,  ..., -3.3048e-06,
          1.5791e-04,  7.8771e-05],
        [ 1.5030e-04,  1.1998e-04, -2.3602e-05,  ...,  6.3827e-05,
         -6.1156e-06, -1.5286e-04],
        [-7.0851e-05,  3.4695e-04, -2.6714e-04,  ..., -4.1816e-04,
         -2.5492e-04, -1.8165e-05]], device='cuda:0')
==> name fc1.bias torch.Size([192]) tensor([-2.3794e-03, -1.9889e-03,  9.4724e-04, -6.9466e-04,  3.2739e-04,
        -2.5410e-04, -6.4688e-04,  7.5322e-04,  1.5922e-03,  4.3198e-04,
         5.1491e-05,  1.7655e-04, -2.4273e-04, -2.6969e-03, -7.2792e-04,
        -9.2133e-04,  1.0916e-03, -9.0570e-04, -4.5398e-04, -4.0780e-03,
        -1.4007e-03,  2.8641e-03, -9.8974e-04, -1.8196e-04, -1.3389e-03,
        -1.3769e-03,  1.6185e-03, -3.1453e-03, -9.9184e-04,  1.5804e-04,
        -1.8841e-03,  2.8165e-03,  8.3453e-04,  1.1999e-03, -1.7836e-03,
         1.7460e-04, -9.6533e-04,  9.9491e-04, -1.4233e-03, -1.0668e-03,
        -7.8406e-04,  1.1201e-03,  3.0630e-04,  1.3433e-04, -1.6495e-04,
         5.3387e-04, -2.3694e-03, -1.9659e-03,  4.1324e-04, -9.1866e-04,
         2.4731e-03,  2.7886e-03, -1.2048e-03, -5.0479e-04, -3.1008e-03,
         7.3237e-04, -9.0263e-04, -3.5822e-03,  9.0557e-05,  4.0922e-04,
         4.0303e-04,  4.2308e-04, -8.8084e-04, -7.8869e-05,  1.2596e-03,
         2.5678e-03, -7.7969e-04, -2.1009e-03, -4.6680e-04, -4.2456e-03,
         2.5299e-03,  5.7987e-04, -2.3638e-03, -4.7559e-04, -2.5781e-03,
         4.3798e-04, -2.4788e-04,  1.1541e-04,  8.6387e-04, -7.1512e-04,
        -1.1759e-03,  1.0882e-03, -7.3305e-04,  5.6236e-04,  3.4384e-03,
         1.2771e-04, -3.6965e-05, -5.2068e-04, -2.4092e-03, -9.9288e-04,
         2.4010e-03,  1.4147e-03, -8.0983e-04,  6.1763e-04, -2.4426e-03,
         2.2359e-03,  1.0478e-03, -2.4329e-03, -1.0064e-04, -1.5205e-04,
        -1.4926e-03, -1.1506e-03, -5.1157e-04,  1.2816e-03, -1.7335e-03,
         1.1238e-03,  1.2625e-03,  1.4966e-03,  2.9398e-03,  1.0423e-03,
        -1.4496e-03,  6.7650e-04, -2.0506e-03,  1.2899e-03, -1.6160e-04,
        -3.7598e-04, -3.2313e-03,  1.0429e-03, -4.2791e-03, -2.5096e-04,
        -3.8741e-03, -5.0933e-04, -5.4110e-04,  1.8047e-03,  9.8722e-04,
         1.5793e-03,  4.2405e-03, -2.6638e-03, -6.3018e-04,  1.2672e-03,
        -1.7130e-03,  7.0189e-04, -1.8646e-03,  1.4218e-03,  3.2277e-04,
        -1.1317e-03, -1.7888e-03,  3.1629e-03,  3.1876e-03,  3.2287e-03,
         3.3495e-03,  3.8562e-03,  2.3673e-03,  9.1007e-04,  9.4256e-04,
         1.0296e-03,  1.0093e-03, -3.5319e-04, -2.2246e-04,  1.6810e-03,
        -1.8940e-03, -1.3032e-03,  2.7192e-03,  4.6527e-04,  1.6305e-03,
         2.8659e-04, -2.1593e-03, -3.2527e-03, -7.6019e-04, -7.8633e-04,
        -2.4964e-03,  3.0384e-04, -3.9978e-03,  3.8658e-04, -2.9756e-03,
         3.8946e-04,  1.9476e-03, -1.1128e-03,  9.9717e-04, -5.3449e-04,
        -9.7399e-04, -6.6086e-04,  8.0516e-04, -4.6305e-04, -2.4743e-04,
         7.7414e-04,  7.1517e-04, -1.2265e-03, -2.5016e-04,  2.6772e-04,
         5.9971e-04,  3.9535e-04, -5.6314e-04,  2.4352e-04,  2.4084e-03,
        -4.6813e-04,  9.2221e-04,  9.4264e-04,  2.0651e-04,  1.2428e-03,
        -1.2193e-03, -3.1516e-03], device='cuda:0')
==> name fc2.weight torch.Size([2, 192]) tensor([[-1.9106e-03, -1.7132e-03, -3.4755e-03, -1.4550e-03,  1.7795e-04,
         -2.4791e-03, -1.1361e-03, -8.1323e-04, -1.1928e-03, -1.4242e-03,
         -2.7199e-03, -1.9050e-03, -1.1466e-03, -3.0573e-03, -7.7670e-03,
         -1.5547e-03, -4.1652e-03, -1.9366e-03,  9.6814e-05, -6.1148e-03,
         -3.9771e-03, -1.1667e-03, -1.9481e-03, -1.6118e-03, -2.7413e-03,
         -1.9918e-03,  7.4591e-04, -4.8707e-03, -9.4013e-04, -1.6871e-03,
         -7.1202e-04, -2.2934e-03, -4.3628e-03,  1.1908e-04, -2.7900e-03,
          1.9296e-04, -3.2052e-04, -2.9478e-03, -7.7049e-04, -2.1858e-03,
         -2.0364e-04, -2.1193e-04, -2.5087e-03, -2.8170e-03, -3.9835e-04,
          1.8541e-04, -1.0507e-03, -6.8944e-04, -2.7862e-04, -2.3529e-03,
         -3.4834e-03, -2.1371e-03, -2.6955e-03,  7.9367e-04, -4.2608e-04,
         -1.2625e-03,  1.5106e-03, -2.1578e-03, -1.0588e-03, -2.1762e-04,
         -4.3615e-03, -8.1371e-04, -4.0078e-03, -8.5557e-04, -1.2873e-03,
         -1.0423e-03, -1.5325e-03, -4.9257e-03, -3.1501e-05, -3.0102e-03,
          3.9864e-04, -1.7844e-03, -1.9057e-03, -1.7822e-03, -8.0982e-04,
         -1.7068e-03,  9.4015e-04, -6.8304e-04, -2.2493e-05,  1.2533e-03,
         -2.4731e-03, -1.4055e-04, -1.3455e-03,  2.2622e-04, -5.0207e-04,
         -1.0483e-04, -2.3855e-03, -9.0439e-06, -1.9526e-03, -2.6779e-04,
          5.6482e-04, -1.6128e-03, -8.3104e-04, -9.9417e-04, -3.3014e-03,
         -4.2366e-03, -6.8492e-04, -3.5739e-03,  1.5281e-04, -9.8726e-04,
         -7.7324e-03, -4.6559e-03, -8.1263e-04, -2.0402e-03, -1.3438e-04,
         -1.7866e-03, -1.5729e-03,  7.6078e-04, -6.5173e-04, -1.9426e-03,
          1.2085e-03, -4.5537e-04,  1.1100e-03, -2.2228e-03, -1.4100e-03,
         -2.0922e-03, -5.2480e-03, -1.1892e-03, -5.0017e-03, -5.0949e-04,
         -2.6962e-03,  6.5285e-04, -4.5690e-03, -1.1636e-03, -4.4642e-03,
         -2.2521e-03, -3.0205e-03, -1.3093e-03,  2.1375e-04, -5.0313e-03,
         -3.0794e-03, -6.5145e-04, -4.5169e-03, -2.3866e-03, -3.6908e-03,
         -9.8465e-04, -3.6926e-03, -1.2116e-03, -2.1552e-03, -1.3970e-03,
         -2.5248e-04, -4.3327e-03,  2.1001e-04, -4.6334e-03, -2.6546e-03,
         -1.8142e-03, -9.2551e-04, -3.6109e-03,  7.9620e-05, -1.8403e-03,
         -1.6109e-03, -2.3510e-03,  2.1551e-03, -3.5775e-03, -1.7413e-04,
         -2.6963e-04, -2.3930e-03, -1.1533e-03,  8.7811e-04,  4.1538e-04,
         -7.0122e-04, -2.1970e-04,  1.3275e-03, -3.4124e-03, -4.5811e-03,
         -4.8635e-03, -1.0247e-03,  6.2141e-04, -2.3445e-03, -1.0455e-03,
         -1.1289e-03, -7.6604e-04, -8.7688e-04, -1.8291e-03, -6.3397e-03,
         -1.0731e-03, -2.8372e-03, -4.4083e-03, -3.6528e-03, -1.5102e-03,
         -2.6072e-03, -2.2766e-03,  2.0626e-04, -9.7448e-04,  1.6551e-03,
          1.2232e-03, -1.0396e-03,  5.5483e-05,  5.7587e-04, -1.2475e-04,
         -3.4942e-03, -6.3449e-03],
        [ 2.9613e-04,  2.3484e-03,  1.2825e-03,  1.9336e-03,  4.9001e-03,
          1.5731e-03,  2.1950e-04,  1.4463e-03,  6.0988e-04, -9.9271e-04,
          1.8246e-03,  2.1481e-04,  1.3395e-03,  2.1360e-03, -2.7746e-04,
         -8.4520e-04,  2.3824e-03,  1.4371e-03,  6.0893e-05,  3.6330e-03,
         -7.0650e-04,  2.6140e-03,  5.3893e-04,  3.2384e-03,  2.1300e-04,
          2.2369e-03,  7.5477e-04,  2.1426e-04,  2.3029e-03, -4.6758e-04,
          1.7518e-04,  4.2466e-03,  8.8033e-04,  1.7774e-03,  1.2120e-03,
          4.9899e-04,  1.5054e-04,  3.5038e-03,  2.2052e-03,  4.0534e-04,
         -5.4782e-05,  1.6304e-03,  3.0255e-03,  2.1681e-03,  2.4607e-03,
          7.8791e-04,  1.1201e-03,  3.7080e-04,  6.5902e-04,  1.6686e-04,
          3.4395e-03,  1.7011e-03,  6.6949e-04, -1.0271e-03,  3.7305e-03,
          6.8122e-04,  1.2418e-03,  2.4070e-03,  2.3336e-03,  1.5884e-03,
          1.1035e-03,  1.2528e-03,  1.9092e-03, -8.8249e-06,  3.7566e-03,
          3.0725e-03,  8.6107e-04,  4.3086e-03,  4.3308e-04,  8.7463e-04,
          3.2961e-03, -1.0406e-03,  5.0241e-03,  1.8632e-03,  1.5052e-03,
          3.6274e-04,  3.4485e-03,  1.0621e-03,  5.7256e-03,  1.2252e-03,
          4.1148e-03,  1.8217e-03,  4.9579e-04,  1.0021e-03,  1.0146e-03,
          1.6679e-03,  4.7982e-04,  4.4104e-04,  3.8566e-03,  2.1587e-03,
          1.5971e-03,  8.0336e-05, -3.3424e-04,  3.0681e-03, -2.3793e-03,
          5.8004e-03,  3.8802e-03,  1.6797e-03,  1.7295e-03,  8.9733e-04,
          4.3469e-04,  7.8557e-04, -6.8816e-04,  2.3232e-03,  2.3641e-03,
          1.5333e-03,  2.4922e-04,  3.9325e-03,  2.7695e-03, -1.0806e-03,
          1.8574e-03, -1.6403e-04,  2.1972e-03,  1.4457e-04,  9.0608e-04,
         -3.0359e-04,  4.7791e-03,  1.8718e-03,  1.2176e-03,  2.2750e-03,
          1.1624e-03, -6.4599e-04,  1.4129e-03,  1.6925e-03,  4.7565e-03,
          1.1784e-03,  7.3443e-03,  5.1733e-04, -5.8713e-04,  1.3014e-03,
          4.2669e-03,  2.2033e-03, -7.4537e-04,  3.4015e-03,  1.0220e-03,
          1.2709e-03,  1.0831e-03,  4.5450e-03,  3.6581e-03,  1.0433e-03,
          3.0448e-03,  5.3242e-03,  3.4867e-03,  3.7493e-03,  4.2986e-03,
          1.5133e-03,  1.1576e-03,  3.3298e-03,  2.9506e-03,  2.2844e-03,
          3.0010e-03,  1.9078e-03,  7.9841e-04,  1.1915e-03, -5.1021e-05,
          1.0169e-03,  3.7341e-03,  1.0696e-03,  5.6813e-04,  2.2064e-03,
          1.6999e-03, -7.4705e-04,  2.2872e-03,  1.0360e-03,  1.4845e-03,
          5.2808e-05,  4.4823e-04,  1.0898e-03,  3.4867e-03, -5.7853e-04,
          3.0020e-03,  5.1527e-04,  2.0729e-03, -1.3753e-04,  2.6221e-03,
          2.9098e-03,  3.9696e-03,  2.0053e-03,  1.8842e-03,  8.1160e-04,
          2.8130e-03,  2.8270e-03, -3.3310e-05,  1.1072e-03,  3.3731e-03,
          2.8502e-04,  5.9314e-04, -7.0510e-04,  1.1200e-04,  1.4310e-03,
          2.3103e-03, -6.2785e-04]], device='cuda:0')
==> name fc2.bias torch.Size([2]) tensor([-0.0498,  0.0498], device='cuda:0')
Iter:     50,  Train Loss:  0.25,  Train Acc: 46.88%,  Val Loss:  0.22,  Val Acc: 47.72%,  Time: 0:00:03 *,  LR: 0.7938926261462523
s_logits tensor([[0.5028, 0.4972],
        [0.4488, 0.5512],
        [0.4858, 0.5142],
        [0.4130, 0.5870],
        [0.4644, 0.5356],
        [0.4965, 0.5035],
        [0.5125, 0.4875],
        [0.4927, 0.5073],
        [0.5010, 0.4990],
        [0.4877, 0.5123],
        [0.4852, 0.5148],
        [0.4475, 0.5525],
        [0.4286, 0.5714],
        [0.4748, 0.5252],
        [0.4398, 0.5602],
        [0.4701, 0.5299],
        [0.4927, 0.5073],
        [0.4408, 0.5592],
        [0.4937, 0.5063],
        [0.4904, 0.5096],
        [0.4982, 0.5018],
        [0.4934, 0.5066],
        [0.4577, 0.5423],
        [0.4769, 0.5231],
        [0.4855, 0.5145],
        [0.4927, 0.5073],
        [0.4866, 0.5134],
        [0.4714, 0.5286],
        [0.4671, 0.5329],
        [0.4788, 0.5212],
        [0.4844, 0.5156],
        [0.4829, 0.5171],
        [0.4744, 0.5256],
        [0.4213, 0.5787],
        [0.4603, 0.5397],
        [0.4883, 0.5117],
        [0.4089, 0.5911],
        [0.4150, 0.5850],
        [0.4893, 0.5107],
        [0.4737, 0.5263],
        [0.4551, 0.5449],
        [0.4768, 0.5232],
        [0.4932, 0.5068],
        [0.4292, 0.5708],
        [0.4829, 0.5171],
        [0.4824, 0.5176],
        [0.4854, 0.5146],
        [0.4895, 0.5105],
        [0.4737, 0.5263],
        [0.4979, 0.5021],
        [0.4071, 0.5929],
        [0.4827, 0.5173],
        [0.4951, 0.5049],
        [0.4821, 0.5179],
        [0.4699, 0.5301],
        [0.4854, 0.5146],
        [0.4460, 0.5540],
        [0.4975, 0.5025],
        [0.4349, 0.5651],
        [0.5035, 0.4965],
        [0.4501, 0.5499],
        [0.4866, 0.5134],
        [0.4574, 0.5426],
        [0.4182, 0.5818]], device='cuda:0', grad_fn=<SoftmaxBackward0>) label tensor([1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1,
        0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1,
        0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0], device='cuda:0')
t_logits tensor([[4.1866e-03, 9.9581e-01],
        [9.9868e-01, 1.3215e-03],
        [3.6226e-03, 9.9638e-01],
        [3.5698e-03, 9.9643e-01],
        [9.9670e-01, 3.3039e-03],
        [2.1083e-02, 9.7892e-01],
        [9.9898e-01, 1.0237e-03],
        [2.1109e-02, 9.7889e-01],
        [9.7855e-01, 2.1445e-02],
        [9.9921e-01, 7.8884e-04],
        [4.6751e-03, 9.9532e-01],
        [9.9860e-01, 1.4011e-03],
        [9.8929e-01, 1.0715e-02],
        [9.9938e-01, 6.2266e-04],
        [9.9847e-01, 1.5339e-03],
        [3.1471e-03, 9.9685e-01],
        [1.9165e-02, 9.8084e-01],
        [2.8864e-03, 9.9711e-01],
        [5.1817e-03, 9.9482e-01],
        [2.3603e-02, 9.7640e-01],
        [9.7834e-01, 2.1663e-02],
        [8.8333e-01, 1.1667e-01],
        [3.4750e-02, 9.6525e-01],
        [7.0595e-03, 9.9294e-01],
        [9.9798e-01, 2.0227e-03],
        [2.2463e-02, 9.7754e-01],
        [3.3341e-02, 9.6666e-01],
        [2.9219e-03, 9.9708e-01],
        [9.8258e-01, 1.7421e-02],
        [9.9854e-01, 1.4592e-03],
        [6.1427e-03, 9.9386e-01],
        [9.9786e-01, 2.1403e-03],
        [7.5784e-03, 9.9242e-01],
        [9.9852e-01, 1.4781e-03],
        [7.6970e-03, 9.9230e-01],
        [6.6992e-03, 9.9330e-01],
        [9.9635e-01, 3.6517e-03],
        [5.7133e-03, 9.9429e-01],
        [9.9774e-01, 2.2599e-03],
        [9.9835e-01, 1.6478e-03],
        [9.9441e-01, 5.5863e-03],
        [9.9693e-01, 3.0675e-03],
        [9.9935e-01, 6.5311e-04],
        [7.7251e-03, 9.9227e-01],
        [1.8652e-02, 9.8135e-01],
        [1.5162e-02, 9.8484e-01],
        [9.8231e-01, 1.7693e-02],
        [9.9216e-01, 7.8383e-03],
        [3.7974e-03, 9.9620e-01],
        [9.9828e-01, 1.7155e-03],
        [9.9938e-01, 6.2141e-04],
        [5.5357e-02, 9.4464e-01],
        [4.0416e-03, 9.9596e-01],
        [9.9898e-01, 1.0150e-03],
        [9.3802e-03, 9.9062e-01],
        [2.8860e-02, 9.7114e-01],
        [7.6876e-02, 9.2312e-01],
        [4.5977e-03, 9.9540e-01],
        [9.9938e-01, 6.1742e-04],
        [7.1329e-03, 9.9287e-01],
        [9.9548e-01, 4.5206e-03],
        [3.4937e-03, 9.9651e-01],
        [9.9664e-01, 3.3613e-03],
        [3.8869e-03, 9.9611e-01]], device='cuda:0')
base_loss tensor(0.6928, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(0.2420, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor([  101,  2009,  1005,  1055, 24256, 12479,  1010,  2367,  2084,  2505,
         2008,  1005,  1055,  2042,  2589,  2077,  1998, 29350,  3144,  1999,
         3408,  1997,  2054,  2009,  1005,  1055,  2667,  2000,  2079,  1012,
          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0], device='cuda:0')
==> name Embedding.weight torch.Size([30522, 300]) tensor([[-2.5817e-07, -3.5655e-06,  8.8747e-07,  ...,  7.4467e-06,
         -1.0184e-06, -7.9729e-07],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]], device='cuda:0')
==> name lstm.weight_ih_l0 torch.Size([1200, 300]) tensor([[ 3.8005e-06, -2.8357e-05,  2.2328e-06,  ...,  2.8771e-05,
          1.6010e-05, -3.4323e-05],
        [-7.6791e-06,  2.6519e-05,  1.0844e-05,  ..., -4.5676e-06,
         -1.2940e-05, -2.1751e-05],
        [-2.1544e-05, -1.6962e-05, -6.4577e-06,  ...,  3.3854e-06,
          3.0847e-05, -1.2958e-05],
        ...,
        [ 3.3447e-06, -9.2305e-06, -8.6697e-06,  ...,  2.2362e-05,
         -4.7693e-05,  1.5584e-05],
        [-7.4739e-05, -4.4674e-05, -4.0191e-05,  ..., -8.2917e-05,
         -4.9962e-06, -2.7306e-05],
        [ 6.7644e-05, -6.8643e-06, -2.2206e-06,  ..., -5.7271e-05,
         -2.6603e-05,  2.3370e-05]], device='cuda:0')
==> name lstm.weight_hh_l0 torch.Size([1200, 300]) tensor([[-9.3284e-07,  1.7067e-06, -3.3880e-06,  ..., -1.7702e-06,
          5.3773e-06, -1.2797e-06],
        [-2.8567e-07, -6.8127e-07,  4.9144e-06,  ..., -1.5231e-06,
          2.1704e-06, -1.0764e-06],
        [ 2.9897e-06, -1.3054e-06,  2.4700e-06,  ...,  1.6451e-06,
          3.8032e-06,  1.3742e-06],
        ...,
        [-1.5953e-06, -3.9756e-06, -1.7910e-06,  ..., -2.8619e-06,
         -3.1343e-06, -8.7914e-08],
        [-1.0014e-05,  3.7397e-06, -1.3105e-06,  ...,  1.4947e-05,
          1.8463e-05,  4.9320e-06],
        [ 1.0863e-05,  2.1880e-07,  1.1535e-05,  ..., -8.4557e-06,
         -1.7739e-06, -4.5142e-06]], device='cuda:0')
==> name lstm.bias_ih_l0 torch.Size([1200]) tensor([ 2.0430e-05, -1.4672e-05,  2.7943e-05,  ..., -2.2190e-05,
         4.2847e-05, -1.6164e-05], device='cuda:0')
==> name lstm.bias_hh_l0 torch.Size([1200]) tensor([ 2.0430e-05, -1.4672e-05,  2.7943e-05,  ..., -2.2190e-05,
         4.2847e-05, -1.6164e-05], device='cuda:0')
==> name lstm.weight_ih_l0_reverse torch.Size([1200, 300]) tensor([[-1.3107e-05, -1.7833e-05, -2.0360e-05,  ...,  2.0456e-05,
         -1.0762e-05,  3.8643e-06],
        [-2.7132e-06,  5.7047e-05, -1.0430e-05,  ..., -7.7788e-05,
          4.8727e-05, -4.5381e-05],
        [-3.1466e-06,  4.6717e-05, -2.0945e-05,  ..., -1.8210e-05,
          2.6096e-05,  1.6890e-05],
        ...,
        [ 8.3501e-06,  6.8391e-06,  2.1045e-05,  ...,  1.8783e-05,
         -3.5807e-05,  1.2740e-05],
        [ 1.4867e-05,  2.7525e-05, -1.8898e-05,  ..., -1.4118e-06,
          2.5722e-05, -7.5463e-08],
        [ 4.5686e-06,  1.7691e-05, -1.7266e-05,  ...,  6.3619e-06,
          8.5501e-06,  2.7376e-05]], device='cuda:0')
==> name lstm.weight_hh_l0_reverse torch.Size([1200, 300]) tensor([[ 2.8325e-06,  1.6272e-06, -2.3780e-06,  ..., -1.6593e-06,
         -1.3321e-06, -1.2014e-06],
        [ 7.3431e-06,  2.4382e-07,  7.8418e-06,  ..., -1.6139e-06,
          5.6389e-06,  4.0799e-06],
        [-2.5408e-06,  4.5805e-06,  6.8922e-07,  ...,  4.5681e-06,
         -7.4155e-07,  8.6826e-06],
        ...,
        [-1.4232e-06, -9.6438e-07, -3.1838e-06,  ..., -4.8372e-06,
          2.6462e-06,  8.2250e-07],
        [ 7.0243e-07,  8.9436e-07,  5.8209e-06,  ...,  1.6879e-06,
          2.0440e-06, -1.0583e-06],
        [ 1.4742e-06,  2.0767e-07,  6.3018e-06,  ...,  3.9134e-07,
         -1.9433e-06,  4.1628e-07]], device='cuda:0')
==> name lstm.bias_ih_l0_reverse torch.Size([1200]) tensor([-6.0528e-07,  6.3385e-05,  3.1573e-06,  ..., -3.3137e-05,
         5.4045e-06,  1.7882e-05], device='cuda:0')
==> name lstm.bias_hh_l0_reverse torch.Size([1200]) tensor([-6.0528e-07,  6.3385e-05,  3.1573e-06,  ..., -3.3137e-05,
         5.4045e-06,  1.7882e-05], device='cuda:0')
==> name fc1.weight torch.Size([192, 600]) tensor([[ 3.1610e-04, -2.0442e-04,  6.3514e-05,  ..., -3.4687e-04,
         -1.7618e-04,  1.4244e-05],
        [-1.7625e-04,  1.1298e-04, -1.2767e-04,  ..., -1.6556e-04,
          2.3558e-05, -2.4857e-04],
        [-2.9551e-05,  1.5589e-05, -2.2668e-05,  ...,  3.3516e-05,
          1.7390e-05, -6.9607e-05],
        ...,
        [-2.2932e-04,  3.1904e-04,  9.6774e-06,  ...,  3.9923e-05,
         -2.6455e-05,  1.2702e-04],
        [ 1.5821e-04, -1.7851e-04,  8.0162e-05,  ..., -2.2579e-04,
          3.0265e-05, -8.9502e-05],
        [ 3.5128e-04, -1.3960e-04,  2.9580e-04,  ..., -2.5350e-04,
          1.1951e-04, -2.8463e-04]], device='cuda:0')
==> name fc1.bias torch.Size([192]) tensor([ 3.0599e-04, -6.8827e-04, -1.1611e-03, -3.7518e-04,  2.1506e-03,
        -3.8193e-04, -3.7951e-04, -2.8523e-04, -9.5694e-04,  1.0549e-03,
        -1.9284e-03, -1.9513e-04,  5.4089e-04,  3.8286e-04,  9.4204e-04,
         1.4823e-05,  1.3165e-03, -4.1001e-04, -5.5918e-05,  6.8650e-04,
         1.7034e-04,  1.1302e-03,  1.0636e-03, -1.7227e-04,  1.8148e-03,
        -1.3376e-04, -9.7740e-05,  2.6860e-04, -3.4800e-04, -5.0133e-05,
         5.1763e-04,  2.1523e-04,  9.5899e-04,  6.8717e-04,  1.8240e-03,
         5.8072e-04, -5.7742e-05,  2.6677e-04,  1.7163e-03, -7.4340e-04,
         5.7578e-04,  6.0187e-04, -4.7024e-04,  8.0592e-06,  6.7752e-04,
        -3.7082e-04, -9.1432e-05,  2.5175e-04,  1.0917e-03, -4.4761e-04,
         6.9857e-04,  1.0542e-03,  7.8625e-04, -1.1575e-03,  1.5109e-03,
         3.8805e-04,  5.8871e-04, -7.9704e-04,  4.9082e-05,  7.0764e-04,
        -1.2002e-05,  7.1215e-04, -6.7725e-04,  6.3251e-04,  6.9195e-04,
        -8.9830e-04, -6.4170e-05,  1.0863e-03,  1.2700e-04,  6.4948e-04,
        -1.2800e-03, -3.6331e-04,  6.1099e-04, -6.5684e-04,  1.8975e-03,
         1.0020e-03, -9.7202e-05, -1.5448e-04,  3.3812e-04, -5.0545e-04,
         1.0538e-03,  6.2317e-04,  1.0971e-03,  9.8737e-04, -4.9128e-04,
         3.4158e-04, -2.1858e-04,  2.6457e-04,  1.0733e-03,  1.0681e-04,
         2.3235e-03,  3.2340e-04, -3.1635e-04, -3.3997e-04,  2.4121e-03,
        -1.9419e-05,  6.4011e-04,  1.2335e-03,  4.6395e-04,  1.4369e-04,
        -2.5721e-05,  1.9312e-04, -2.7005e-04,  2.1093e-04,  8.3709e-04,
         1.5510e-04,  1.0411e-03, -1.2698e-04, -1.0890e-03, -5.0898e-04,
         7.7528e-04,  3.2579e-03, -1.1070e-03, -2.7447e-05, -4.5223e-04,
         1.0729e-03,  4.2119e-04, -3.0386e-04,  2.1217e-03,  3.1438e-05,
         3.5260e-04, -2.3717e-04, -1.3373e-03,  4.0083e-04, -1.3586e-03,
        -1.3782e-03,  1.6844e-03,  4.3355e-04, -3.1720e-04,  3.8125e-06,
        -1.0213e-03,  1.0912e-04, -3.5121e-04, -9.8930e-05,  1.3533e-03,
        -3.8652e-04,  6.9207e-04,  3.4258e-04, -8.0909e-04, -1.4132e-03,
        -2.3068e-03,  3.3757e-05,  9.2518e-04, -1.8965e-04, -3.4268e-04,
         6.0213e-05, -3.4100e-04, -3.5132e-04, -6.4262e-04, -7.1939e-04,
        -7.8889e-04, -8.0848e-04,  8.0951e-04,  1.3199e-04,  8.1979e-05,
        -3.6774e-05, -3.4703e-04, -6.2016e-04, -3.1396e-04,  5.0033e-04,
         2.4428e-05, -3.1765e-04,  5.3474e-05,  5.4311e-04, -6.2851e-04,
         6.0402e-04,  3.9958e-04, -1.3291e-03, -3.5046e-04,  1.2994e-03,
        -1.6691e-04, -1.5310e-03,  9.2261e-06, -8.1957e-06,  8.1201e-04,
         3.8848e-04,  2.1759e-04, -1.9124e-03,  4.0231e-04, -3.8696e-04,
         1.0416e-03,  9.1775e-04, -8.7357e-04, -5.0787e-04,  1.9159e-03,
        -1.8461e-04,  3.2949e-04,  1.6455e-04,  4.2030e-04,  7.0726e-04,
        -8.7811e-04,  7.3897e-04], device='cuda:0')
==> name fc2.weight torch.Size([2, 192]) tensor([[ 1.2461e-04, -1.6297e-03,  1.3757e-03, -9.2107e-04, -2.7529e-03,
          1.8303e-04, -1.2897e-04,  2.3764e-04,  7.2120e-04,  6.2814e-04,
          2.5172e-03, -2.2496e-04,  9.0281e-04,  9.7160e-04, -5.5074e-04,
          1.3211e-03, -2.4270e-03,  1.2547e-03,  1.9801e-03,  3.1496e-03,
          3.6462e-04, -3.0564e-04,  3.0843e-03,  3.6332e-04, -1.7728e-04,
          1.7916e-03, -1.3756e-05, -2.1678e-03,  3.4599e-04,  4.8931e-04,
          2.4649e-03, -1.0999e-03, -2.3482e-03, -7.8612e-04,  2.6946e-03,
          6.0269e-04,  1.8782e-03, -1.8840e-03, -1.4741e-04, -8.6503e-04,
          3.9139e-04, -1.5813e-04,  4.2075e-04, -1.6926e-03,  3.4761e-03,
          1.9196e-04, -3.5490e-04, -2.7441e-03, -4.0055e-04,  2.7893e-04,
          9.2172e-04, -1.2453e-03,  1.1516e-03, -9.4022e-04,  1.0123e-03,
         -1.2017e-03, -1.0345e-03,  1.8051e-03,  1.6094e-03, -1.3583e-03,
         -8.4147e-04, -4.6853e-05, -1.0386e-03,  7.8341e-04,  6.6187e-04,
         -7.4367e-04,  2.5910e-04,  1.7095e-03, -1.3738e-04,  1.9138e-03,
         -1.0583e-03,  1.5317e-03,  3.9373e-03, -8.4392e-04,  7.3153e-04,
          1.8444e-03,  3.0474e-03, -1.6645e-03,  1.3872e-03, -2.6571e-04,
         -4.7837e-04, -5.1526e-04,  2.6322e-03,  1.3257e-03, -2.5338e-03,
          1.1850e-03, -2.0024e-03, -1.2972e-04, -6.5879e-04, -1.8015e-03,
         -2.6205e-03, -5.4643e-05,  1.2481e-03, -2.4870e-03,  3.4915e-03,
          6.4567e-04,  1.4932e-03,  1.3940e-03,  6.2942e-04, -5.5349e-04,
          1.9550e-03, -6.8655e-04,  6.2821e-05, -4.2119e-04, -1.2036e-03,
          7.6982e-04, -7.3560e-05, -8.3314e-04,  8.3276e-04,  2.1536e-04,
         -1.6123e-03, -8.2756e-04,  1.8704e-03, -1.0027e-04,  1.7744e-03,
         -3.3411e-03,  1.6864e-03,  2.1572e-06,  3.0497e-03, -2.4699e-03,
          7.3946e-04, -4.3903e-04,  1.0626e-04,  8.0516e-05,  3.4062e-03,
         -5.7067e-05, -1.0145e-03,  1.8294e-03,  6.2365e-04,  9.1491e-04,
         -1.8945e-03, -4.9185e-04,  4.4651e-04, -1.6138e-03, -1.3853e-03,
         -7.6951e-04,  3.3067e-04, -4.1950e-03,  5.2291e-04,  1.1315e-03,
          2.3801e-03,  1.2425e-04,  1.1224e-05, -5.6427e-03,  2.5433e-04,
         -2.6209e-04, -6.8198e-04,  1.7500e-04, -6.1154e-04,  2.4463e-05,
         -4.8505e-03, -4.0335e-04, -8.7626e-05,  2.0370e-04, -4.9837e-04,
         -1.5529e-03, -1.0187e-03,  8.5025e-04, -1.7480e-03, -1.2640e-03,
         -1.6704e-03, -8.9972e-04,  1.3620e-03,  6.5271e-04, -3.7449e-03,
          1.2357e-03, -1.9938e-04, -3.8262e-03,  1.1352e-03, -1.1972e-05,
          4.2191e-04,  2.3739e-04, -7.1965e-04,  9.3694e-04, -8.2277e-04,
         -3.5245e-03, -5.7043e-04, -5.7328e-03,  2.2831e-03, -8.9360e-04,
          2.6658e-03,  1.8314e-03,  3.7063e-04,  1.2582e-03,  3.8602e-03,
         -1.5272e-05, -2.5839e-03,  1.0912e-03,  6.1542e-04, -1.5780e-03,
          6.7798e-05,  3.9191e-04],
        [-8.2125e-04, -2.2105e-04, -8.1463e-04,  1.5707e-03, -1.5760e-03,
          6.3940e-04,  1.5043e-03,  2.3514e-03,  1.1450e-03, -1.9135e-03,
          1.9012e-03,  1.0631e-03,  6.1168e-04, -4.7679e-04,  1.3804e-03,
         -2.5235e-03,  1.4387e-03,  2.7671e-04, -1.3145e-04, -4.3286e-04,
         -7.0219e-04,  2.3798e-03, -1.0000e-03, -5.3338e-04, -1.1738e-03,
         -4.2183e-04, -3.2292e-04, -3.1326e-04, -1.0600e-03, -5.4775e-05,
          1.7661e-04,  1.4911e-03, -4.9899e-04, -1.5770e-03, -1.6895e-03,
         -9.6446e-04, -1.7255e-03,  6.2756e-05, -4.7228e-04,  4.6335e-04,
         -1.8966e-03,  1.0243e-03,  3.6272e-03,  8.5175e-04,  1.6369e-04,
         -1.6615e-03, -8.7319e-04, -1.1510e-03,  1.8042e-03, -3.9727e-04,
         -1.3218e-03,  1.5843e-03, -6.4549e-04, -5.1942e-04,  9.1603e-05,
          1.0387e-03,  1.3540e-03, -5.7079e-04, -1.6421e-03,  1.1394e-03,
          8.1664e-04,  1.6770e-03,  1.3998e-03,  2.1850e-03,  2.2648e-03,
         -4.0369e-04, -7.6749e-04, -8.8213e-04, -2.2180e-04, -2.5409e-05,
          2.2388e-03,  2.2190e-03, -1.8565e-03,  4.5124e-04, -6.7679e-04,
          1.3061e-04,  1.7083e-03,  3.8163e-03, -3.7326e-04,  9.3285e-04,
         -3.1077e-03, -1.0019e-03, -8.6663e-04,  2.2375e-04,  1.2183e-03,
          1.1841e-04, -7.0276e-04, -1.6176e-03, -1.5722e-03,  8.5619e-04,
          2.4022e-03, -3.7461e-04,  1.4280e-03, -2.3940e-04,  1.5252e-04,
         -4.7601e-04,  1.0518e-03, -1.4216e-03, -4.5133e-04, -4.6257e-04,
         -1.8123e-04, -4.1115e-04, -2.0966e-04,  6.8831e-04,  3.2442e-04,
         -9.2471e-05,  8.2699e-04,  2.2228e-03,  1.9665e-04,  1.1089e-03,
          3.2812e-04,  6.2025e-04, -4.0058e-04, -1.4330e-04, -7.5807e-04,
          2.0763e-03, -2.6787e-03, -8.1981e-04, -4.2535e-04, -7.5331e-04,
         -7.9343e-04, -1.5739e-03, -1.2919e-03, -1.5318e-04,  8.5661e-04,
         -1.9102e-03,  3.0520e-03, -1.2728e-04,  2.5002e-04, -5.7737e-05,
          5.2436e-04,  6.4927e-04,  5.3545e-04, -3.8169e-04,  3.7140e-04,
         -2.8623e-04, -1.4695e-03,  1.7430e-03, -2.0888e-03,  1.4070e-03,
         -1.9864e-03, -3.5681e-03, -1.1568e-05, -1.8563e-03,  4.8750e-04,
          3.4061e-04,  3.2512e-03, -3.2221e-04, -6.4319e-04, -1.4600e-03,
         -8.2413e-04,  1.4063e-03,  1.7390e-03,  1.1100e-03,  7.3397e-04,
         -7.1534e-04, -9.8169e-04,  1.2700e-03, -3.4828e-04, -2.9872e-04,
         -1.3998e-04,  8.3463e-04,  2.4550e-04,  3.1653e-04, -2.2232e-03,
          2.0817e-03, -8.3742e-04, -3.7554e-04, -3.1106e-05,  1.3186e-03,
          3.1390e-04,  8.9223e-04, -2.1453e-04, -6.7831e-04, -9.0385e-05,
          6.0035e-05, -8.0020e-04, -3.6752e-04, -1.3340e-04,  1.0114e-03,
          3.9426e-04,  2.0156e-03,  2.9986e-04, -1.4410e-03,  2.6225e-03,
          1.4308e-03,  2.3365e-03, -1.2070e-03, -3.1006e-04,  2.1094e-03,
          1.0522e-03, -1.1353e-03]], device='cuda:0')
==> name fc2.bias torch.Size([2]) tensor([-0.0002,  0.0002], device='cuda:0')
Iter:    100,  Train Loss:  0.24,  Train Acc: 56.25%,  Val Loss:  0.22,  Val Acc: 49.42%,  Time: 0:00:04 ,  LR: 0.2966316784620994
Epoch [2/30]
Traceback (most recent call last):
  File "/home/huyiwen/CV/bilstm/distill.py", line 71, in <module>
    student_train(T_model, S_model, cfg, train_loader, test_loader)
  File "/home/huyiwen/CV/bilstm/student.py", line 128, in student_train
    loss.backward()
  File "/home/huyiwen/miniconda3/envs/kd/lib/python3.10/site-packages/torch/_tensor.py", line 492, in backward
    torch.autograd.backward(
  File "/home/huyiwen/miniconda3/envs/kd/lib/python3.10/site-packages/torch/autograd/__init__.py", line 251, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt