加载数据...
['a stirring , funny and finally transporting re-imagining of beauty and the beast and 1930s horror films', 'apparently reassembled from the cutting-room floor of any given daytime soap .', "they presume their audience wo n't sit still for a sociology lesson , however entertainingly presented , so they trot out the conventional science-fiction elements of bug-eyed monsters and futuristic women in skimpy clothes .", 'this is a visually stunning rumination on love , memory , history and the war between art and commerce .', "jonathan parker 's bartleby should have been the be-all-end-all of the modern-office anomie films ."]
[1, 0, 0, 1, 1]
Time usage: 0:00:18
Some weights of the model checkpoint at /home/huyiwen/pretrained/bert-base-uncased-SST-2 were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
BERT_Model(
  (bert): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0-11): 12 x BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (fc): Linear(in_features=768, out_features=192, bias=True)
  (fc1): Linear(in_features=192, out_features=2, bias=True)
)
Epoch [1/1]
Iter:      0,  Train Loss:  0.73,  Train Acc: 51.56%,  Val Loss:  0.37,  Val Acc: 93.08%,  Time: 0:00:22 *
Iter:     10,  Train Loss: 0.0015,  Train Acc: 100.00%,  Val Loss:  0.31,  Val Acc: 92.59%,  Time: 0:00:40 *
Iter:     20,  Train Loss:  0.11,  Train Acc: 98.44%,  Val Loss:  0.35,  Val Acc: 92.53%,  Time: 0:00:51
Iter:     30,  Train Loss:  0.09,  Train Acc: 98.44%,  Val Loss:  0.33,  Val Acc: 92.64%,  Time: 0:00:58
Iter:     40,  Train Loss:  0.11,  Train Acc: 96.88%,  Val Loss:  0.28,  Val Acc: 92.70%,  Time: 0:01:16 *
Iter:     50,  Train Loss: 0.065,  Train Acc: 98.44%,  Val Loss:  0.22,  Val Acc: 92.48%,  Time: 0:01:33 *
Iter:     60,  Train Loss: 0.038,  Train Acc: 98.44%,  Val Loss:  0.25,  Val Acc: 92.70%,  Time: 0:01:45
Iter:     70,  Train Loss: 0.0025,  Train Acc: 100.00%,  Val Loss:  0.24,  Val Acc: 92.59%,  Time: 0:01:52
Iter:     80,  Train Loss:  0.12,  Train Acc: 93.75%,  Val Loss:   0.2,  Val Acc: 92.70%,  Time: 0:02:09 *
Iter:     90,  Train Loss: 0.065,  Train Acc: 98.44%,  Val Loss:  0.22,  Val Acc: 92.64%,  Time: 0:02:20
Iter:    100,  Train Loss: 0.031,  Train Acc: 98.44%,  Val Loss:  0.24,  Val Acc: 92.75%,  Time: 0:02:28
Test Loss:  0.25,  Test Acc: 92.86%
Precision, Recall and F1-Score...
              precision    recall  f1-score   support
           0     0.9433    0.9123    0.9275       912
           1     0.9148    0.9450    0.9297       909
    accuracy                         0.9286      1821
   macro avg     0.9291    0.9286    0.9286      1821
weighted avg     0.9291    0.9286    0.9286      1821
Confusion Matrix...
[[832  80]
 [ 50 859]]
Time usage: 0:00:09
cuda
biLSTM(
  (Embedding): Embedding(30522, 300)
  (lstm): LSTM(300, 300, batch_first=True, bidirectional=True)
  (fc1): Linear(in_features=600, out_features=192, bias=True)
  (fc2): Linear(in_features=192, out_features=2, bias=True)
)
10,717,178 total parameters.
Epoch [1/30]
Iter:      0,  Train Loss: 1.7e+01,  Train Acc: 45.31%,  Val Loss: 6.1e+03,  Val Acc: 50.08%,  Time: 0:00:03 *,  LR: 0.09972609476841367
Iter:     50,  Train Loss: 1.6e+01,  Train Acc: 50.00%,  Val Loss: 1.5e+01,  Val Acc: 50.03%,  Time: 0:00:07 *,  LR: 0.07938926261462524
Iter:    100,  Train Loss: 1.7e+01,  Train Acc: 51.56%,  Val Loss: 1.5e+01,  Val Acc: 49.92%,  Time: 0:00:11 *,  LR: 0.02966316784620994
Epoch [2/30]
Iter:    150,  Train Loss: 1.7e+01,  Train Acc: 46.88%,  Val Loss: 1.4e+01,  Val Acc: 49.75%,  Time: 0:00:15 *,  LR: 0.0002739052315863355
Iter:    200,  Train Loss: 1.7e+01,  Train Acc: 60.94%,  Val Loss: 1.4e+01,  Val Acc: 49.53%,  Time: 0:00:19 *,  LR: 0.020610737385377154
Epoch [3/30]
Iter:    250,  Train Loss: 1.6e+01,  Train Acc: 50.00%,  Val Loss: 1.4e+01,  Val Acc: 50.03%,  Time: 0:00:23 ,  LR: 0.0703368321537913
Iter:    300,  Train Loss: 1.6e+01,  Train Acc: 40.62%,  Val Loss: 1.5e+01,  Val Acc: 50.03%,  Time: 0:00:26 ,  LR: 0.09972609476842181
Epoch [4/30]
Iter:    350,  Train Loss: 1.5e+01,  Train Acc: 51.56%,  Val Loss: 1.4e+01,  Val Acc: 50.19%,  Time: 0:00:28 ,  LR: 0.07938926261463011
Iter:    400,  Train Loss: 1.6e+01,  Train Acc: 43.75%,  Val Loss: 1.4e+01,  Val Acc: 50.96%,  Time: 0:00:32 *,  LR: 0.029663167846208528
Epoch [5/30]
Iter:    450,  Train Loss: 1.6e+01,  Train Acc: 42.19%,  Val Loss: 1.4e+01,  Val Acc: 50.58%,  Time: 0:00:35 ,  LR: 0.0002739052315863355
Iter:    500,  Train Loss: 1.6e+01,  Train Acc: 43.75%,  Val Loss: 1.4e+01,  Val Acc: 49.97%,  Time: 0:00:40 *,  LR: 0.020610737385375662
Epoch [6/30]
Iter:    550,  Train Loss: 1.6e+01,  Train Acc: 50.00%,  Val Loss: 1.4e+01,  Val Acc: 49.92%,  Time: 0:00:43 ,  LR: 0.07033683215379732
Iter:    600,  Train Loss: 1.7e+01,  Train Acc: 45.31%,  Val Loss: 1.4e+01,  Val Acc: 50.03%,  Time: 0:00:47 *,  LR: 0.09972609476842378
Iter:    650,  Train Loss: 1.5e+01,  Train Acc: 54.69%,  Val Loss: 1.4e+01,  Val Acc: 49.97%,  Time: 0:00:49 ,  LR: 0.07938926261462201
Epoch [7/30]
Iter:    700,  Train Loss: 1.7e+01,  Train Acc: 51.56%,  Val Loss: 1.4e+01,  Val Acc: 50.08%,  Time: 0:00:52 ,  LR: 0.029663167846213603
Iter:    750,  Train Loss: 1.6e+01,  Train Acc: 59.38%,  Val Loss: 1.4e+01,  Val Acc: 50.08%,  Time: 0:00:55 ,  LR: 0.0002739052315863355
Epoch [8/30]
Iter:    800,  Train Loss: 1.6e+01,  Train Acc: 51.56%,  Val Loss: 1.4e+01,  Val Acc: 50.03%,  Time: 0:00:57 ,  LR: 0.02061073738538169
Iter:    850,  Train Loss: 1.5e+01,  Train Acc: 59.38%,  Val Loss: 1.4e+01,  Val Acc: 50.19%,  Time: 0:00:59 ,  LR: 0.07033683215379839
Epoch [9/30]
Iter:    900,  Train Loss: 1.7e+01,  Train Acc: 57.81%,  Val Loss: 1.4e+01,  Val Acc: 50.03%,  Time: 0:01:02 ,  LR: 0.09972609476841374
Iter:    950,  Train Loss: 1.6e+01,  Train Acc: 51.56%,  Val Loss: 1.4e+01,  Val Acc: 50.03%,  Time: 0:01:05 ,  LR: 0.07938926261461202
Epoch [10/30]
Iter:   1000,  Train Loss: 1.7e+01,  Train Acc: 51.56%,  Val Loss: 1.4e+01,  Val Acc: 50.03%,  Time: 0:01:09 ,  LR: 0.029663167846210266
Iter:   1050,  Train Loss: 1.6e+01,  Train Acc: 50.00%,  Val Loss: 1.4e+01,  Val Acc: 50.03%,  Time: 0:01:12 ,  LR: 0.0002739052315863355
Epoch [11/30]
Iter:   1100,  Train Loss: 1.6e+01,  Train Acc: 39.06%,  Val Loss: 1.4e+01,  Val Acc: 50.08%,  Time: 0:01:15 ,  LR: 0.02061073738537954
Iter:   1150,  Train Loss: 1.7e+01,  Train Acc: 46.88%,  Val Loss: 1.4e+01,  Val Acc: 50.08%,  Time: 0:01:18 ,  LR: 0.07033683215379172
Epoch [12/30]
Iter:   1200,  Train Loss: 1.5e+01,  Train Acc: 48.44%,  Val Loss: 1.4e+01,  Val Acc: 50.08%,  Time: 0:01:20 ,  LR: 0.09972609476842985
Iter:   1250,  Train Loss: 1.7e+01,  Train Acc: 46.88%,  Val Loss: 1.4e+01,  Val Acc: 50.08%,  Time: 0:01:24 ,  LR: 0.07938926261462459
Iter:   1300,  Train Loss: 1.8e+01,  Train Acc: 51.56%,  Val Loss: 1.4e+01,  Val Acc: 50.03%,  Time: 0:01:27 ,  LR: 0.02966316784620752
Epoch [13/30]
Iter:   1350,  Train Loss: 1.6e+01,  Train Acc: 51.56%,  Val Loss: 1.4e+01,  Val Acc: 50.03%,  Time: 0:01:29 ,  LR: 0.0002739052315863355
Iter:   1400,  Train Loss: 1.5e+01,  Train Acc: 57.81%,  Val Loss: 1.4e+01,  Val Acc: 50.08%,  Time: 0:01:33 ,  LR: 0.020610737385383188
Epoch [14/30]
Iter:   1450,  Train Loss: 1.6e+01,  Train Acc: 51.56%,  Val Loss: 1.4e+01,  Val Acc: 50.14%,  Time: 0:01:36 ,  LR: 0.07033683215380346
Iter:   1500,  Train Loss: 1.6e+01,  Train Acc: 42.19%,  Val Loss: 1.4e+01,  Val Acc: 50.14%,  Time: 0:01:38 ,  LR: 0.09972609476841775
Epoch [15/30]
Iter:   1550,  Train Loss: 1.7e+01,  Train Acc: 54.69%,  Val Loss: 1.4e+01,  Val Acc: 50.14%,  Time: 0:01:40 ,  LR: 0.07938926261461793
Iter:   1600,  Train Loss: 1.6e+01,  Train Acc: 42.19%,  Val Loss: 1.4e+01,  Val Acc: 50.14%,  Time: 0:01:42 ,  LR: 0.029663167846219137
Epoch [16/30]
Iter:   1650,  Train Loss: 1.7e+01,  Train Acc: 50.00%,  Val Loss: 1.4e+01,  Val Acc: 50.14%,  Time: 0:01:46 ,  LR: 0.0002739052315863355
Iter:   1700,  Train Loss: 1.8e+01,  Train Acc: 42.19%,  Val Loss: 1.4e+01,  Val Acc: 50.03%,  Time: 0:01:49 ,  LR: 0.020610737385380863
Epoch [17/30]
Iter:   1750,  Train Loss: 1.6e+01,  Train Acc: 48.44%,  Val Loss: 1.4e+01,  Val Acc: 50.14%,  Time: 0:01:52 ,  LR: 0.07033683215383317
Iter:   1800,  Train Loss: 1.6e+01,  Train Acc: 39.06%,  Val Loss: 1.4e+01,  Val Acc: 49.97%,  Time: 0:01:55 ,  LR: 0.09972609476840764
Iter:   1850,  Train Loss: 1.6e+01,  Train Acc: 43.75%,  Val Loss: 1.4e+01,  Val Acc: 50.14%,  Time: 0:01:57 ,  LR: 0.07938926261460733
Epoch [18/30]
Iter:   1900,  Train Loss: 1.6e+01,  Train Acc: 45.31%,  Val Loss: 1.4e+01,  Val Acc: 50.14%,  Time: 0:02:00 ,  LR: 0.02966316784621448
Iter:   1950,  Train Loss: 1.7e+01,  Train Acc: 54.69%,  Val Loss: 1.4e+01,  Val Acc: 50.08%,  Time: 0:02:03 ,  LR: 0.0002739052315863355
Epoch [19/30]
Iter:   2000,  Train Loss: 1.6e+01,  Train Acc: 42.19%,  Val Loss: 1.4e+01,  Val Acc: 50.14%,  Time: 0:02:05 ,  LR: 0.020610737385378122
Iter:   2050,  Train Loss: 1.6e+01,  Train Acc: 35.94%,  Val Loss: 1.4e+01,  Val Acc: 50.14%,  Time: 0:02:07 ,  LR: 0.0703368321538243
Epoch [20/30]
Iter:   2100,  Train Loss: 1.7e+01,  Train Acc: 56.25%,  Val Loss: 1.4e+01,  Val Acc: 50.14%,  Time: 0:02:10 ,  LR: 0.09972609476839542
Iter:   2150,  Train Loss: 1.6e+01,  Train Acc: 51.56%,  Val Loss: 1.4e+01,  Val Acc: 50.14%,  Time: 0:02:12 ,  LR: 0.07938926261464135
Epoch [21/30]
Iter:   2200,  Train Loss: 1.8e+01,  Train Acc: 39.06%,  Val Loss: 1.4e+01,  Val Acc: 50.14%,  Time: 0:02:14 ,  LR: 0.029663167846211754
Iter:   2250,  Train Loss: 1.6e+01,  Train Acc: 48.44%,  Val Loss: 1.4e+01,  Val Acc: 50.03%,  Time: 0:02:16 ,  LR: 0.0002739052315863355
Epoch [22/30]
Iter:   2300,  Train Loss: 1.7e+01,  Train Acc: 56.25%,  Val Loss: 1.4e+01,  Val Acc: 50.14%,  Time: 0:02:18 ,  LR: 0.020610737385387812
Iter:   2350,  Train Loss: 1.6e+01,  Train Acc: 50.00%,  Val Loss: 1.4e+01,  Val Acc: 49.97%,  Time: 0:02:21 ,  LR: 0.07033683215381692
Epoch [23/30]
Iter:   2400,  Train Loss: 1.7e+01,  Train Acc: 51.56%,  Val Loss: 1.4e+01,  Val Acc: 50.14%,  Time: 0:02:24 ,  LR: 0.09972609476843784
Iter:   2450,  Train Loss: 1.5e+01,  Train Acc: 46.88%,  Val Loss: 1.4e+01,  Val Acc: 50.14%,  Time: 0:02:26 ,  LR: 0.07938926261463357
Iter:   2500,  Train Loss: 1.8e+01,  Train Acc: 46.88%,  Val Loss: 1.4e+01,  Val Acc: 50.14%,  Time: 0:02:29 ,  LR: 0.02966316784622334
Epoch [24/30]
Iter:   2550,  Train Loss: 1.7e+01,  Train Acc: 56.25%,  Val Loss: 1.4e+01,  Val Acc: 50.14%,  Time: 0:02:33 ,  LR: 0.0002739052315863355
Iter:   2600,  Train Loss: 1.7e+01,  Train Acc: 59.38%,  Val Loss: 1.4e+01,  Val Acc: 50.03%,  Time: 0:02:36 ,  LR: 0.02061073738537306
Epoch [25/30]
Iter:   2650,  Train Loss: 1.6e+01,  Train Acc: 57.81%,  Val Loss: 1.4e+01,  Val Acc: 50.14%,  Time: 0:02:40 ,  LR: 0.07033683215381073
Iter:   2700,  Train Loss: 1.6e+01,  Train Acc: 37.50%,  Val Loss: 1.4e+01,  Val Acc: 50.14%,  Time: 0:02:44 ,  LR: 0.09972609476837344
Epoch [26/30]
Iter:   2750,  Train Loss: 1.6e+01,  Train Acc: 51.56%,  Val Loss: 1.4e+01,  Val Acc: 50.14%,  Time: 0:02:47 ,  LR: 0.07938926261462183
Iter:   2800,  Train Loss: 1.7e+01,  Train Acc: 37.50%,  Val Loss: 1.4e+01,  Val Acc: 50.14%,  Time: 0:02:50 ,  LR: 0.02966316784622062
Epoch [27/30]
Iter:   2850,  Train Loss: 1.8e+01,  Train Acc: 50.00%,  Val Loss: 1.4e+01,  Val Acc: 50.14%,  Time: 0:02:53 ,  LR: 0.0002739052315863355
Iter:   2900,  Train Loss: 1.4e+01,  Train Acc: 54.69%,  Val Loss: 1.4e+01,  Val Acc: 49.97%,  Time: 0:02:57 ,  LR: 0.02061073738539516
Epoch [28/30]
Iter:   2950,  Train Loss: 1.7e+01,  Train Acc: 46.88%,  Val Loss: 1.4e+01,  Val Acc: 50.14%,  Time: 0:02:59 ,  LR: 0.0703368321538007
Iter:   3000,  Train Loss: 1.8e+01,  Train Acc: 50.00%,  Val Loss: 1.4e+01,  Val Acc: 49.92%,  Time: 0:03:02 ,  LR: 0.0997260947684702
Iter:   3050,  Train Loss: 1.6e+01,  Train Acc: 60.94%,  Val Loss: 1.4e+01,  Val Acc: 50.14%,  Time: 0:03:05 ,  LR: 0.07938926261470164
Epoch [29/30]
Iter:   3100,  Train Loss: 1.6e+01,  Train Acc: 53.12%,  Val Loss: 1.4e+01,  Val Acc: 50.14%,  Time: 0:03:07 ,  LR: 0.029663167846188002
Iter:   3150,  Train Loss: 1.6e+01,  Train Acc: 60.94%,  Val Loss: 1.4e+01,  Val Acc: 50.03%,  Time: 0:03:10 ,  LR: 0.0002739052315863355
Epoch [30/30]
Iter:   3200,  Train Loss: 1.7e+01,  Train Acc: 48.44%,  Val Loss: 1.4e+01,  Val Acc: 50.14%,  Time: 0:03:13 ,  LR: 0.020610737385367995
Iter:   3250,  Train Loss: 1.6e+01,  Train Acc: 45.31%,  Val Loss: 1.4e+01,  Val Acc: 50.14%,  Time: 0:03:16 ,  LR: 0.07033683215379445