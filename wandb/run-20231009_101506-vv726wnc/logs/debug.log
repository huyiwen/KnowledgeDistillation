2023-10-09 10:15:06,454 INFO    MainThread:1579662 [wandb_setup.py:_flush():76] Current SDK version is 0.15.10
2023-10-09 10:15:06,455 INFO    MainThread:1579662 [wandb_setup.py:_flush():76] Configure stats pid to 1579662
2023-10-09 10:15:06,455 INFO    MainThread:1579662 [wandb_setup.py:_flush():76] Loading settings from /home/huyiwen/.config/wandb/settings
2023-10-09 10:15:06,455 INFO    MainThread:1579662 [wandb_setup.py:_flush():76] Loading settings from /home/huyiwen/NLP/bilstm/wandb/settings
2023-10-09 10:15:06,455 INFO    MainThread:1579662 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2023-10-09 10:15:06,455 INFO    MainThread:1579662 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-10-09 10:15:06,455 INFO    MainThread:1579662 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'distill.py', 'program': '/home/huyiwen/NLP/bilstm/distill.py'}
2023-10-09 10:15:06,455 INFO    MainThread:1579662 [wandb_init.py:_log_setup():524] Logging user logs to /home/huyiwen/NLP/bilstm/wandb/run-20231009_101506-vv726wnc/logs/debug.log
2023-10-09 10:15:06,455 INFO    MainThread:1579662 [wandb_init.py:_log_setup():525] Logging internal logs to /home/huyiwen/NLP/bilstm/wandb/run-20231009_101506-vv726wnc/logs/debug-internal.log
2023-10-09 10:15:06,455 INFO    MainThread:1579662 [wandb_init.py:init():564] calling init triggers
2023-10-09 10:15:06,456 INFO    MainThread:1579662 [wandb_init.py:init():571] wandb.init called with sweep_config: {}
config: {'class_list': ('0', '1'), 'teacher_save_path': 'saved_dict/new_teacher_base1_sst2.ckpt', 'student_save_path': 'saved_dict/student.ckpt', 'data': '/home/huyiwen/datasets/sst2', 'seed': 42, 'device': device(type='cuda'), 'train_teacher': 0, 'train_student': 1, 'require_improvement': 1000, 'num_classes': 2, 'teacher_num_epochs': 1, 'student_num_epochs': 30, 'finetune_optimizer': 'AdamW', 'distill_optimizer': 'AdamW', 'finetune_batch_size': 64, 'distill_batch_size': 64, 'max_seq_length': 128, 'finetune_lr': 0.0005, 'distill_lr': 0.0002, 'bert_path': '/home/huyiwen/pretrained/bert-base-uncased-SST-2', 'tokenizer': PreTrainedTokenizer(name_or_path='/home/huyiwen/pretrained/bert-base-uncased-SST-2', vocab_size=30522, model_max_len=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}), 'bert_hidden_size': 768, 'LSTM_embedding_dim': 300, 'LSTM_hidden_dim': 300, 'LSTM_bias': True, 'LSTM_peephole': False, 'FC_dim': 192, 'use_mpo': False, 'custom_bilstm': False, 'mpo_type': ['embedding'], 'truncate_num': 10000, 'embedding_input_shape': [19, 4, 2, 7, 20], 'embedding_output_shape': [10, 3, 1, 1, 10], 'fc1_input_shape': [10, 2, 1, 3, 10], 'fc1_output_shape': [6, 2, 1, 2, 8], 'fc2_input_shape': [6, 2, 1, 2, 8], 'fc2_output_shape': [2, 1, 1, 1, 1], 'xh_input_shape': (), 'xh_output_shape': (), 'hh_input_shape': (), 'hh_output_shape': (), 'loss_align': False, 'loss_weight': 0.5, 'loss_func': 'CosineEmbeddingLoss', 'tfc_input_shape': (), 'tfc_output_shape': (), 'tfc1_input_shape': (), 'tfc1_output_shape': ()}
2023-10-09 10:15:06,456 INFO    MainThread:1579662 [wandb_init.py:init():614] starting backend
2023-10-09 10:15:06,456 INFO    MainThread:1579662 [wandb_init.py:init():618] setting up manager
2023-10-09 10:15:06,458 INFO    MainThread:1579662 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-10-09 10:15:06,459 INFO    MainThread:1579662 [wandb_init.py:init():624] backend started and connected
2023-10-09 10:15:06,462 INFO    MainThread:1579662 [wandb_init.py:init():715] updated telemetry
2023-10-09 10:15:06,468 INFO    MainThread:1579662 [wandb_init.py:init():748] communicating run to backend with 90.0 second timeout
2023-10-09 10:15:08,936 INFO    MainThread:1579662 [wandb_run.py:_on_init():2220] communicating current version
2023-10-09 10:15:09,444 INFO    MainThread:1579662 [wandb_run.py:_on_init():2229] got version response upgrade_message: "wandb version 0.15.12 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-10-09 10:15:09,444 INFO    MainThread:1579662 [wandb_init.py:init():799] starting run threads in backend
2023-10-09 10:15:19,759 INFO    MainThread:1579662 [wandb_run.py:_console_start():2199] atexit reg
2023-10-09 10:15:19,759 INFO    MainThread:1579662 [wandb_run.py:_redirect():2054] redirect: wrap_raw
2023-10-09 10:15:19,759 INFO    MainThread:1579662 [wandb_run.py:_redirect():2119] Wrapping output streams.
2023-10-09 10:15:19,760 INFO    MainThread:1579662 [wandb_run.py:_redirect():2144] Redirects installed.
2023-10-09 10:15:19,760 INFO    MainThread:1579662 [wandb_init.py:init():840] run started, returning control to user process
2023-10-09 10:17:12,372 WARNING MsgRouterThr:1579662 [router.py:message_loop():77] message_loop has been closed
