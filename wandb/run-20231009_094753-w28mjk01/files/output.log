加载数据...
tensor([[  101,  4205,  5472,  ...,     0,     0,     0],
        [  101,  2019,  4024,  ...,     0,     0,     0],
        [  101,  2045,  1005,  ...,     0,     0,     0],
        ...,
        [  101,  2035,  1996,  ...,     0,     0,     0],
        [  101, 11552,  2135,  ...,     0,     0,     0],
        [  101,  1037,  4121,  ...,     0,     0,     0]])
Time usage: 0:00:05
BERT_Model(
  (bert): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0-11): 12 x BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (fc): Linear(in_features=768, out_features=192, bias=True)
  (fc1): Linear(in_features=192, out_features=2, bias=True)
)
cuda
biLSTM(
  (Embedding): Embedding(30522, 300)
  (lstm): LSTM(300, 300, batch_first=True, bidirectional=True)
  (fc1): Linear(in_features=600, out_features=192, bias=True)
  (fc2): Linear(in_features=192, out_features=2, bias=True)
)
Some weights of the model checkpoint at /home/huyiwen/pretrained/bert-base-uncased-SST-2 were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
10,717,178 total parameters.
Epoch [1/30]
s_logits tensor([[0.4773, 0.5227],
        [0.4840, 0.5160],
        [0.4748, 0.5252],
        [0.4847, 0.5153],
        [0.4798, 0.5202],
        [0.4893, 0.5107],
        [0.4852, 0.5148],
        [0.4929, 0.5071],
        [0.4747, 0.5253],
        [0.4861, 0.5139],
        [0.4815, 0.5185],
        [0.5015, 0.4985],
        [0.4974, 0.5026],
        [0.4883, 0.5117],
        [0.4966, 0.5034],
        [0.4848, 0.5152],
        [0.4911, 0.5089],
        [0.4943, 0.5057],
        [0.4831, 0.5169],
        [0.4812, 0.5188],
        [0.4877, 0.5123],
        [0.4851, 0.5149],
        [0.4872, 0.5128],
        [0.4819, 0.5181],
        [0.4877, 0.5123],
        [0.4821, 0.5179],
        [0.5041, 0.4959],
        [0.4794, 0.5206],
        [0.4903, 0.5097],
        [0.4899, 0.5101],
        [0.4875, 0.5125],
        [0.4926, 0.5074],
        [0.4905, 0.5095],
        [0.4951, 0.5049],
        [0.4869, 0.5131],
        [0.4880, 0.5120],
        [0.4870, 0.5130],
        [0.4922, 0.5078],
        [0.4858, 0.5142],
        [0.4865, 0.5135],
        [0.4834, 0.5166],
        [0.4867, 0.5133],
        [0.4930, 0.5070],
        [0.4832, 0.5168],
        [0.4877, 0.5123],
        [0.4843, 0.5157],
        [0.4855, 0.5145],
        [0.4865, 0.5135],
        [0.4893, 0.5107],
        [0.4866, 0.5134],
        [0.4911, 0.5089],
        [0.4856, 0.5144],
        [0.4889, 0.5111],
        [0.4826, 0.5174],
        [0.4836, 0.5164],
        [0.4897, 0.5103],
        [0.4882, 0.5118],
        [0.4888, 0.5112],
        [0.4863, 0.5137],
        [0.4895, 0.5105],
        [0.4830, 0.5170],
        [0.4989, 0.5011],
        [0.4815, 0.5185],
        [0.4785, 0.5215]], device='cuda:0', grad_fn=<SoftmaxBackward0>) label tensor([0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,
        0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0,
        1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1], device='cuda:0')
t_logits tensor([[9.9947e-01, 5.3368e-04],
        [1.2205e-02, 9.8779e-01],
        [9.9808e-01, 1.9192e-03],
        [9.9885e-01, 1.1547e-03],
        [3.9347e-03, 9.9607e-01],
        [5.3743e-03, 9.9463e-01],
        [9.5874e-01, 4.1255e-02],
        [3.5135e-03, 9.9649e-01],
        [9.2223e-01, 7.7773e-02],
        [4.1820e-03, 9.9582e-01],
        [9.9900e-01, 9.9894e-04],
        [9.9904e-01, 9.6125e-04],
        [9.1609e-01, 8.3912e-02],
        [3.0861e-03, 9.9691e-01],
        [4.1088e-03, 9.9589e-01],
        [9.9472e-01, 5.2836e-03],
        [1.4192e-02, 9.8581e-01],
        [1.5545e-02, 9.8446e-01],
        [4.5848e-02, 9.5415e-01],
        [5.4886e-03, 9.9451e-01],
        [9.9874e-01, 1.2551e-03],
        [9.9950e-01, 5.0455e-04],
        [9.9912e-01, 8.7586e-04],
        [9.9855e-01, 1.4496e-03],
        [3.8550e-03, 9.9615e-01],
        [3.0349e-03, 9.9697e-01],
        [9.9906e-01, 9.3514e-04],
        [9.9930e-01, 7.0369e-04],
        [4.0615e-03, 9.9594e-01],
        [4.2186e-03, 9.9578e-01],
        [4.2164e-03, 9.9578e-01],
        [9.9280e-01, 7.2048e-03],
        [9.9821e-01, 1.7895e-03],
        [9.9936e-01, 6.4397e-04],
        [3.5035e-03, 9.9650e-01],
        [9.9912e-01, 8.8046e-04],
        [9.9697e-01, 3.0259e-03],
        [9.9921e-01, 7.8953e-04],
        [9.9807e-01, 1.9271e-03],
        [9.9935e-01, 6.5100e-04],
        [4.0775e-03, 9.9592e-01],
        [9.7800e-01, 2.1997e-02],
        [9.1303e-03, 9.9087e-01],
        [2.9660e-03, 9.9703e-01],
        [7.3085e-03, 9.9269e-01],
        [9.9474e-01, 5.2644e-03],
        [9.6431e-01, 3.5686e-02],
        [9.9511e-01, 4.8911e-03],
        [9.9947e-01, 5.2820e-04],
        [9.9789e-01, 2.1140e-03],
        [9.9562e-01, 4.3801e-03],
        [9.9917e-01, 8.3110e-04],
        [5.5824e-03, 9.9442e-01],
        [3.1015e-03, 9.9690e-01],
        [5.6073e-03, 9.9439e-01],
        [9.6293e-01, 3.7073e-02],
        [1.6173e-02, 9.8383e-01],
        [1.1644e-02, 9.8836e-01],
        [7.2993e-03, 9.9270e-01],
        [9.9913e-01, 8.7073e-04],
        [4.8140e-03, 9.9519e-01],
        [9.9937e-01, 6.2513e-04],
        [5.6990e-03, 9.9430e-01],
        [5.8538e-03, 9.9415e-01]], device='cuda:0')
base_loss tensor(0.6930, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(0.2418, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor([  101,  2009,  3084,  2033,  2514,  6881,  1032,  1013,  3241,  2055,
         2035,  1996,  2919,  2477,  1999,  1996,  2088,  1032,  1013,  2066,
        26781, 13046,  2007,  3714,  3456,  1032,  1013,  1998, 15023,  2008,
         3280,  1032,  1013,  1998,  5691,  4626,  3769,  8603,   102,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0],
       device='cuda:0')
==> name Embedding.weight torch.Size([30522, 300]) tensor([[-2.9262e-05,  3.3261e-06, -1.2510e-05,  ...,  2.6411e-05,
          9.3781e-06, -2.2252e-05],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]], device='cuda:0')
==> name lstm.weight_ih_l0 torch.Size([1200, 300]) tensor([[-1.6675e-05, -1.2395e-04,  1.2947e-05,  ...,  2.6398e-05,
         -7.8243e-05, -3.9246e-06],
        [ 1.7894e-05,  2.1899e-05, -1.7055e-05,  ..., -1.9407e-06,
          2.9978e-05,  7.4290e-06],
        [-1.9433e-05, -4.1803e-05, -7.2696e-07,  ...,  1.3892e-05,
          1.0950e-06, -7.2214e-07],
        ...,
        [-1.1859e-05, -2.4304e-05, -4.5703e-06,  ...,  3.4159e-05,
         -4.0184e-05,  1.7461e-05],
        [ 3.7486e-05,  9.1287e-06, -3.0394e-05,  ...,  4.5073e-05,
          1.5995e-05,  2.1748e-05],
        [ 7.7779e-06,  1.6416e-05,  8.6093e-07,  ..., -8.8693e-08,
          4.1222e-06, -2.4020e-05]], device='cuda:0')
==> name lstm.weight_hh_l0 torch.Size([1200, 300]) tensor([[-3.7336e-06, -2.0494e-06,  4.5468e-06,  ..., -2.3412e-06,
          5.6244e-06,  6.9529e-06],
        [-2.5878e-06,  1.2885e-06, -5.6715e-06,  ..., -3.1671e-06,
         -3.8238e-06,  7.0945e-07],
        [ 8.8602e-07, -1.7575e-06,  3.7479e-07,  ..., -1.8463e-06,
         -8.4626e-07, -2.3475e-06],
        ...,
        [-5.9021e-06, -5.6931e-07, -4.9867e-06,  ..., -1.9351e-06,
          4.2306e-06, -1.9776e-06],
        [-2.2010e-06,  3.1025e-06,  7.8324e-08,  ...,  5.9722e-07,
          2.1278e-06,  3.9274e-06],
        [ 3.6668e-07,  3.8130e-06, -1.2545e-06,  ...,  3.4301e-06,
          4.1163e-06, -9.4094e-06]], device='cuda:0')
==> name lstm.bias_ih_l0 torch.Size([1200]) tensor([-3.3297e-05, -4.2846e-05, -1.7954e-06,  ..., -5.3846e-06,
        -1.3373e-05,  4.4864e-05], device='cuda:0')
==> name lstm.bias_hh_l0 torch.Size([1200]) tensor([-3.3297e-05, -4.2846e-05, -1.7954e-06,  ..., -5.3846e-06,
        -1.3373e-05,  4.4864e-05], device='cuda:0')
==> name lstm.weight_ih_l0_reverse torch.Size([1200, 300]) tensor([[ 2.7366e-05, -3.3096e-05,  7.1395e-06,  ...,  2.5695e-05,
          1.9459e-06, -1.1778e-05],
        [ 4.0687e-06,  7.5088e-05,  8.8975e-05,  ..., -7.3885e-05,
         -5.3952e-05, -3.6013e-05],
        [-3.8625e-06, -3.2122e-05, -3.6415e-05,  ...,  4.8187e-05,
         -3.0782e-05,  1.7536e-05],
        ...,
        [ 5.5659e-06, -2.1730e-05, -6.3470e-06,  ...,  2.4458e-05,
         -1.5605e-05, -8.4151e-06],
        [ 3.1863e-05,  8.4200e-06,  6.1444e-06,  ...,  1.9935e-05,
          1.7056e-05,  1.8474e-05],
        [ 1.8698e-05, -1.2767e-05, -2.4974e-05,  ..., -3.4304e-05,
         -5.9073e-05,  3.4120e-05]], device='cuda:0')
==> name lstm.weight_hh_l0_reverse torch.Size([1200, 300]) tensor([[-1.3184e-06,  3.5331e-06, -3.3625e-06,  ...,  2.1929e-06,
          1.5977e-06, -1.1688e-07],
        [-6.2862e-06, -5.6571e-06,  4.4191e-07,  ..., -9.4331e-06,
         -6.9160e-07,  1.1785e-06],
        [-1.2721e-06,  6.7328e-07,  1.4128e-06,  ..., -1.5895e-07,
         -3.1779e-07,  1.2732e-05],
        ...,
        [ 1.7936e-06,  1.9392e-06,  2.5891e-06,  ...,  2.0255e-06,
         -9.3464e-09, -3.8600e-06],
        [-2.9443e-06,  2.3512e-06, -2.4960e-07,  ...,  3.1394e-06,
          2.5342e-06, -3.4491e-06],
        [ 4.4323e-06, -5.3956e-06, -3.9798e-06,  ..., -1.3551e-06,
          9.7803e-06,  1.3611e-05]], device='cuda:0')
==> name lstm.bias_ih_l0_reverse torch.Size([1200]) tensor([-2.8508e-05,  1.6215e-05, -5.2606e-06,  ..., -5.0651e-06,
         1.9243e-05, -3.4533e-05], device='cuda:0')
==> name lstm.bias_hh_l0_reverse torch.Size([1200]) tensor([-2.8508e-05,  1.6215e-05, -5.2606e-06,  ..., -5.0651e-06,
         1.9243e-05, -3.4533e-05], device='cuda:0')
==> name fc1.weight torch.Size([192, 600]) tensor([[-6.1222e-04, -1.2122e-04, -2.4883e-04,  ..., -9.7706e-05,
         -1.1009e-04,  1.4417e-04],
        [-7.6041e-04, -1.8912e-04, -1.3293e-04,  ..., -7.7427e-05,
          1.9338e-04,  3.7533e-04],
        [ 2.4233e-05,  3.9308e-04, -3.0887e-04,  ...,  3.8933e-06,
         -6.0404e-05,  4.6579e-05],
        ...,
        [ 2.2092e-04,  1.7718e-04, -1.2586e-04,  ...,  1.0850e-04,
         -3.4027e-05,  1.1426e-05],
        [-7.8210e-05, -2.3422e-04, -1.1100e-04,  ...,  1.0322e-04,
          9.4698e-05,  2.3552e-04],
        [-2.9087e-04, -4.5295e-04,  2.4391e-05,  ...,  6.6775e-05,
          4.8996e-05,  5.0734e-05]], device='cuda:0')
==> name fc1.bias torch.Size([192]) tensor([ 5.6226e-04, -8.3838e-04,  2.1182e-03, -2.2384e-04, -6.7815e-04,
         2.1834e-04, -1.0497e-03,  1.5927e-04,  3.5988e-04,  1.2712e-03,
         3.1422e-03,  1.8132e-04,  7.2148e-04, -1.2059e-03, -3.1657e-04,
        -9.2604e-04,  6.8268e-04, -3.3557e-04, -9.3199e-05, -1.7811e-03,
        -7.5199e-04,  1.0350e-03,  1.6216e-03, -3.6291e-04,  5.6178e-04,
        -6.8055e-04,  1.7480e-03, -4.0759e-04,  2.9809e-04, -6.4658e-04,
        -1.3758e-04,  1.7868e-03, -2.5742e-03,  1.5758e-03, -9.4705e-04,
         5.6664e-04, -3.7312e-04,  8.2918e-04,  1.6207e-03, -4.7709e-04,
        -6.0320e-04,  6.7917e-04, -9.2833e-04,  2.0032e-04, -1.5557e-04,
         3.3028e-03, -2.9500e-04,  2.3483e-04, -6.9188e-04, -1.5995e-03,
         2.3309e-04,  3.3670e-03, -9.5246e-04,  9.9878e-04,  2.0571e-03,
         2.4971e-04, -2.5101e-03, -1.9184e-03, -3.7852e-04,  2.1922e-03,
        -1.4773e-04,  6.1039e-04, -1.7346e-04,  3.5857e-05, -5.3284e-04,
         1.7087e-03, -1.2520e-03, -9.6073e-04,  1.1754e-05, -8.6337e-04,
         1.2090e-04, -7.1399e-04, -1.0485e-03, -1.0953e-03, -1.7877e-03,
         1.5292e-03, -5.2487e-04, -9.6671e-04,  3.6639e-06, -2.8813e-04,
         2.1270e-03,  2.3279e-04, -1.4480e-04,  2.2699e-04,  2.2739e-04,
         2.1705e-04,  4.3080e-05, -5.3212e-04, -9.9161e-04, -1.8334e-04,
         1.8800e-03, -5.2364e-04, -1.5536e-03,  4.8151e-04, -1.3552e-03,
         4.1212e-04, -1.4631e-03,  2.8984e-04, -9.5717e-04, -1.2059e-04,
        -9.0790e-04, -1.1553e-03,  1.6405e-04,  8.3838e-04,  4.8298e-04,
        -7.7702e-04,  1.5311e-03,  2.2114e-03, -5.0622e-04, -8.4281e-04,
         9.9350e-05,  2.2083e-04, -2.7688e-04,  5.8869e-05,  5.6864e-04,
         8.0735e-04, -3.5500e-04, -8.0482e-04, -2.8249e-03,  2.6637e-04,
         4.7386e-04,  4.3225e-04,  3.7250e-04,  1.5984e-03,  9.0510e-05,
         2.5155e-03,  2.0997e-03, -1.6328e-04, -3.7548e-04,  1.5611e-07,
        -7.3706e-04,  3.7850e-04, -1.8924e-06, -2.4401e-04,  6.6921e-04,
        -1.0575e-03, -8.8469e-04,  1.7223e-03,  1.6766e-03,  4.1782e-04,
         7.7968e-05,  1.4380e-03, -4.0099e-04,  9.0340e-04,  9.5663e-04,
         9.0456e-04,  1.7577e-03, -2.9195e-04,  1.4660e-04,  9.6813e-04,
        -5.9849e-04, -2.3997e-04,  1.0621e-03,  1.3919e-03,  2.0983e-04,
        -1.6358e-05, -8.8070e-04, -1.0369e-03, -5.6056e-04,  1.0839e-03,
        -1.9759e-04, -1.1272e-03, -1.7065e-03, -5.6697e-04, -3.4022e-03,
        -1.1707e-04, -5.4513e-05, -2.2927e-03,  2.6006e-03, -9.4482e-04,
        -3.3527e-04,  1.3174e-04,  1.8242e-03, -2.6258e-04, -7.6088e-04,
        -7.5749e-06,  6.0920e-04, -2.2731e-03, -5.0994e-04, -1.0497e-03,
         5.7521e-06, -9.7125e-05,  1.7239e-03,  3.2278e-04,  1.9563e-04,
         6.1977e-04, -1.8846e-04,  1.6054e-03, -4.0660e-04,  4.7450e-04,
        -1.1165e-03, -2.5992e-03], device='cuda:0')
==> name fc2.weight torch.Size([2, 192]) tensor([[ 1.7879e-03, -4.1202e-04, -2.1791e-04, -7.3727e-04,  1.7946e-04,
          4.8238e-04, -2.0071e-03,  6.7500e-04, -5.3779e-04, -4.0945e-04,
         -2.6392e-03,  2.0022e-04,  2.3794e-03, -2.1262e-03, -7.5070e-04,
         -5.5976e-04, -1.3993e-03,  6.6398e-04, -2.8159e-03, -1.5120e-03,
         -4.9779e-04,  4.2740e-05,  9.9930e-04, -1.2094e-03, -2.0129e-03,
         -8.8216e-04, -1.6633e-03, -2.8212e-03,  6.3889e-04, -7.2198e-04,
          1.0110e-03, -1.2019e-04,  4.5017e-04,  2.5039e-04,  1.9362e-04,
         -4.7815e-06, -6.1127e-04, -2.5583e-03,  3.6804e-03, -1.1078e-03,
         -9.1065e-05,  8.0682e-05, -3.7936e-04, -1.0781e-03, -1.6828e-03,
         -1.1605e-03, -1.4576e-03, -8.6264e-04, -2.2924e-03, -1.1118e-03,
         -4.3894e-04, -1.2199e-03, -6.7209e-04,  2.8635e-03,  6.8026e-04,
         -1.8984e-03, -1.7025e-03, -7.6391e-04, -2.3677e-03, -1.5905e-03,
          1.6667e-03,  8.7365e-04, -6.4790e-04, -1.7849e-03, -7.8167e-04,
         -6.5100e-05, -1.7521e-03, -1.8528e-03,  2.0941e-03, -1.1530e-03,
         -7.2064e-04,  5.3780e-04, -1.0912e-03, -3.4117e-03,  9.3167e-04,
         -1.0794e-03, -3.1996e-03,  4.8885e-04, -1.3619e-03,  9.8990e-05,
          2.7476e-03, -9.3050e-06,  1.3290e-04,  2.6470e-04,  1.6701e-03,
          1.5050e-03, -1.0331e-03, -3.7589e-04, -2.1216e-03,  1.4595e-03,
          4.5562e-04, -8.7872e-05,  9.8735e-04,  9.0171e-04, -1.0505e-03,
         -1.0863e-03, -1.1471e-03,  6.2910e-05,  1.2930e-03, -2.2724e-05,
         -2.3723e-03, -2.8043e-03,  3.5108e-04, -2.2102e-03, -4.9466e-04,
          2.3494e-04, -1.2089e-03, -3.1345e-04, -3.2074e-04,  1.5090e-03,
          1.6277e-03, -1.1097e-03, -4.8228e-04, -1.4633e-05, -1.0873e-03,
         -1.0418e-03, -5.9683e-04,  4.3621e-05, -2.4141e-03,  9.2349e-04,
         -8.5254e-04, -6.2169e-04, -1.3683e-03, -1.1531e-03,  6.7771e-04,
          7.9125e-04, -9.7131e-04,  8.6021e-04, -1.7339e-03, -4.6574e-05,
         -2.7080e-03,  5.9197e-04, -1.2788e-04,  1.2279e-03, -1.2319e-03,
         -2.1349e-03, -2.7079e-03, -1.8478e-03, -1.7191e-03,  8.7790e-04,
          8.0337e-04, -3.1977e-03, -3.4166e-04,  1.8053e-03, -1.7161e-03,
         -1.3710e-03,  1.9466e-03, -2.1500e-03, -2.0574e-03, -1.8873e-03,
         -1.2536e-03, -1.4355e-03, -1.3824e-03, -3.3010e-04, -3.2285e-04,
          9.3988e-04,  9.5269e-04, -1.7340e-03,  6.0726e-04, -7.4714e-04,
          1.2354e-03, -9.8766e-04, -1.8522e-03, -1.3854e-03, -1.8945e-03,
          2.0072e-03, -2.6406e-04, -2.2931e-03,  2.0499e-03,  2.4298e-03,
          1.0827e-03,  2.1119e-04, -3.8032e-04, -1.2249e-03, -2.0009e-03,
          1.3886e-04, -1.6770e-04, -3.3605e-03,  4.7470e-04,  8.0897e-05,
         -6.8334e-04, -1.0976e-03, -3.0774e-04,  4.9955e-04, -3.1148e-03,
         -8.6201e-04, -1.4547e-03, -1.4840e-03,  1.5398e-03, -9.7668e-04,
         -4.7168e-03, -3.0252e-03],
        [-3.3862e-04, -2.4798e-03, -9.4974e-05,  3.5939e-03, -3.0549e-03,
         -9.6501e-04,  5.1605e-05, -4.8926e-04,  1.3200e-03,  2.0482e-03,
         -1.0741e-03,  1.7753e-03,  1.1571e-03,  2.1757e-03,  5.0867e-04,
          4.8363e-03,  1.2775e-03,  5.7188e-05,  4.3019e-04, -2.4323e-04,
         -7.6616e-04, -2.3951e-05,  3.1663e-03,  2.1331e-03,  1.2858e-03,
          2.8639e-03,  2.8198e-03,  7.0588e-04, -4.6493e-04, -1.0054e-03,
          2.1212e-04, -2.8470e-03,  3.2434e-03,  1.4555e-03,  1.2798e-03,
          1.8817e-03,  3.0302e-03,  3.0902e-03, -3.6872e-04,  6.2014e-04,
          1.5085e-03,  1.4414e-03,  2.8513e-03,  3.1408e-04,  1.5240e-03,
         -2.4643e-03, -1.5020e-04, -6.9982e-04,  1.7137e-03,  1.4804e-03,
         -1.7083e-04,  4.8464e-03, -6.1548e-03,  3.4118e-03, -1.9598e-03,
          9.9112e-04,  3.1902e-03,  2.7243e-03, -2.3882e-03,  5.1984e-03,
          6.4509e-04,  1.4631e-03,  1.0678e-03,  1.9861e-03, -1.7998e-03,
         -5.8933e-04,  2.3875e-03,  1.1027e-03,  5.3787e-05,  1.6540e-03,
          5.0364e-04,  1.4069e-03,  2.7224e-03, -1.0771e-03,  2.4728e-04,
          9.1989e-04,  2.4299e-03, -1.4258e-03,  4.0731e-03, -2.7414e-05,
          1.0029e-03, -1.1740e-03, -8.5796e-04,  2.3453e-04, -3.4133e-03,
         -7.3866e-04, -8.8398e-04, -2.3376e-04,  1.1347e-03,  1.0237e-03,
          2.7168e-03,  6.7578e-04,  2.7405e-03,  2.3939e-03,  1.9553e-03,
          8.7024e-04, -4.5636e-03, -1.3422e-03,  1.4116e-03,  1.6244e-03,
         -5.4993e-04, -5.4802e-05, -1.0632e-03,  1.2193e-03, -4.5191e-04,
         -3.0772e-04,  1.7902e-04,  4.5121e-03,  1.2392e-03,  4.0483e-04,
         -2.4519e-04,  6.5639e-04,  1.9619e-03,  9.0869e-04, -1.0817e-03,
          6.1588e-04,  3.3961e-03, -2.5266e-03,  7.9908e-04, -1.6668e-03,
          6.1220e-05, -1.1881e-03, -1.2198e-03,  1.5439e-03, -1.0079e-03,
          3.0711e-03,  3.1618e-03, -4.1840e-04,  2.7750e-06,  2.9047e-03,
          1.8240e-03,  1.2155e-03, -1.5911e-03, -2.3541e-03,  1.9289e-03,
          9.5083e-04,  3.2583e-03,  3.4183e-03, -1.2775e-03,  1.3142e-03,
          2.6831e-04, -6.9520e-04, -3.9194e-04,  2.7112e-03,  1.1826e-04,
          5.5439e-05,  1.5069e-03,  2.2979e-03,  1.5182e-03,  2.4701e-03,
          1.0646e-03, -5.6630e-05,  2.1681e-03,  3.6227e-03,  3.6477e-04,
          6.5558e-04,  1.1570e-03, -1.6519e-03,  1.3268e-03,  9.8197e-04,
          2.0600e-03,  1.4937e-03,  7.8636e-04,  5.3136e-04,  3.3823e-03,
         -1.6268e-03,  1.1460e-03,  1.7367e-03,  4.5674e-03,  1.9005e-03,
          1.3297e-03,  8.4268e-04,  2.3400e-03,  4.4879e-04,  1.7891e-03,
          2.5367e-04,  1.9117e-03,  5.4626e-04,  4.0413e-04,  3.0111e-04,
          1.4644e-03,  3.0637e-04,  1.5539e-03,  1.2403e-03,  1.3062e-03,
         -2.0083e-03,  3.9305e-04, -1.1966e-03,  1.0769e-03,  3.5024e-03,
          1.2179e-03,  8.3861e-04]], device='cuda:0')
==> name fc2.bias torch.Size([2]) tensor([-0.0211,  0.0211], device='cuda:0')
Iter:      0,  Train Loss:  0.24,  Train Acc: 48.44%,  Val Loss:  0.22,  Val Acc: 49.92%,  Time: 0:00:01 *,  LR: 0.00019945218953682734
s_logits tensor([[0.4468, 0.5532],
        [0.4493, 0.5507],
        [0.4744, 0.5256],
        [0.4696, 0.5304],
        [0.4460, 0.5540],
        [0.4526, 0.5474],
        [0.4510, 0.5490],
        [0.4725, 0.5275],
        [0.4563, 0.5437],
        [0.4455, 0.5545],
        [0.4546, 0.5454],
        [0.4661, 0.5339],
        [0.4475, 0.5525],
        [0.4612, 0.5388],
        [0.4428, 0.5572],
        [0.4559, 0.5441],
        [0.4654, 0.5346],
        [0.4665, 0.5335],
        [0.4419, 0.5581],
        [0.4629, 0.5371],
        [0.4404, 0.5596],
        [0.4577, 0.5423],
        [0.4691, 0.5309],
        [0.4622, 0.5378],
        [0.4514, 0.5486],
        [0.4738, 0.5262],
        [0.4468, 0.5532],
        [0.4765, 0.5235],
        [0.4646, 0.5354],
        [0.4670, 0.5330],
        [0.4696, 0.5304],
        [0.4474, 0.5526],
        [0.4436, 0.5564],
        [0.4551, 0.5449],
        [0.4806, 0.5194],
        [0.4538, 0.5462],
        [0.4409, 0.5591],
        [0.4525, 0.5475],
        [0.4432, 0.5568],
        [0.4516, 0.5484],
        [0.4535, 0.5465],
        [0.4662, 0.5338],
        [0.4509, 0.5491],
        [0.4646, 0.5354],
        [0.4471, 0.5529],
        [0.4687, 0.5313],
        [0.4763, 0.5237],
        [0.4561, 0.5439],
        [0.4405, 0.5595],
        [0.4425, 0.5575],
        [0.4459, 0.5541],
        [0.4699, 0.5301],
        [0.4446, 0.5554],
        [0.4487, 0.5513],
        [0.4641, 0.5359],
        [0.4577, 0.5423],
        [0.4683, 0.5317],
        [0.4484, 0.5516],
        [0.4432, 0.5568],
        [0.4518, 0.5482],
        [0.4510, 0.5490],
        [0.4765, 0.5235],
        [0.4712, 0.5288],
        [0.4657, 0.5343]], device='cuda:0', grad_fn=<SoftmaxBackward0>) label tensor([0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1,
        1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0,
        1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1], device='cuda:0')
t_logits tensor([[3.6535e-03, 9.9635e-01],
        [8.5200e-02, 9.1480e-01],
        [9.9759e-01, 2.4075e-03],
        [9.8347e-01, 1.6529e-02],
        [9.9656e-01, 3.4396e-03],
        [9.9897e-01, 1.0284e-03],
        [9.9876e-01, 1.2386e-03],
        [8.9474e-01, 1.0526e-01],
        [1.7154e-02, 9.8285e-01],
        [7.8416e-03, 9.9216e-01],
        [9.9947e-01, 5.3270e-04],
        [9.9902e-01, 9.7864e-04],
        [9.9658e-01, 3.4199e-03],
        [7.4760e-03, 9.9252e-01],
        [5.5121e-03, 9.9449e-01],
        [9.9818e-01, 1.8217e-03],
        [9.9763e-01, 2.3679e-03],
        [9.9828e-01, 1.7159e-03],
        [9.9196e-01, 8.0375e-03],
        [9.8732e-01, 1.2684e-02],
        [9.9913e-01, 8.7289e-04],
        [9.9762e-01, 2.3799e-03],
        [2.9597e-03, 9.9704e-01],
        [9.9868e-01, 1.3227e-03],
        [9.8777e-01, 1.2229e-02],
        [3.2997e-02, 9.6700e-01],
        [4.0559e-03, 9.9594e-01],
        [1.0727e-02, 9.8927e-01],
        [1.6889e-02, 9.8311e-01],
        [9.9938e-01, 6.1934e-04],
        [3.1060e-03, 9.9689e-01],
        [9.9907e-01, 9.3411e-04],
        [9.9672e-01, 3.2779e-03],
        [4.5648e-03, 9.9544e-01],
        [3.7807e-02, 9.6219e-01],
        [5.6310e-03, 9.9437e-01],
        [9.8587e-01, 1.4132e-02],
        [9.8950e-01, 1.0499e-02],
        [3.9312e-03, 9.9607e-01],
        [4.4445e-03, 9.9556e-01],
        [9.9902e-01, 9.7928e-04],
        [9.9541e-01, 4.5851e-03],
        [9.9492e-01, 5.0788e-03],
        [9.9911e-01, 8.9490e-04],
        [4.4977e-03, 9.9550e-01],
        [5.4439e-03, 9.9456e-01],
        [9.9627e-01, 3.7299e-03],
        [4.3933e-03, 9.9561e-01],
        [9.9934e-01, 6.6125e-04],
        [9.9890e-01, 1.0952e-03],
        [3.5763e-03, 9.9642e-01],
        [3.7101e-03, 9.9629e-01],
        [3.5931e-03, 9.9641e-01],
        [5.6526e-03, 9.9435e-01],
        [9.9926e-01, 7.4279e-04],
        [3.3738e-03, 9.9663e-01],
        [9.9906e-01, 9.4135e-04],
        [9.7151e-01, 2.8491e-02],
        [9.8060e-02, 9.0194e-01],
        [9.9738e-01, 2.6226e-03],
        [4.0014e-03, 9.9600e-01],
        [9.9899e-01, 1.0121e-03],
        [9.9566e-01, 4.3449e-03],
        [2.7041e-03, 9.9730e-01]], device='cuda:0')
base_loss tensor(0.6958, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(0.2475, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor([  101,  2007,  2062,  2839,  2458,  2023,  2453,  2031,  2042,  2019,
        18823, 10874,  1025,  2007,  2488,  3477, 27475,  1010,  2009,  2071,
         2031,  2042,  1037,  3241,  2158,  1005,  1055,  6071,  3185,  1012,
          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0],
       device='cuda:0')
==> name Embedding.weight torch.Size([30522, 300]) tensor([[ 1.8585e-04,  5.0069e-05,  1.2979e-04,  ...,  5.2596e-06,
          1.1595e-04, -5.0886e-05],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]], device='cuda:0')
==> name lstm.weight_ih_l0 torch.Size([1200, 300]) tensor([[-3.1556e-05,  4.8128e-05, -1.1141e-05,  ..., -4.9137e-06,
          1.6787e-06, -2.2879e-05],
        [-2.9824e-05,  2.8113e-05,  6.4111e-06,  ...,  4.6948e-05,
          3.2114e-05,  1.9681e-05],
        [-4.2729e-06,  2.5495e-06,  1.5235e-05,  ...,  2.8748e-06,
         -4.8675e-06, -1.8494e-05],
        ...,
        [-1.2084e-05,  1.5207e-05,  2.3525e-05,  ...,  2.8660e-05,
         -8.0321e-05, -3.0086e-05],
        [-4.9347e-05,  1.6702e-05, -1.0687e-06,  ...,  2.2459e-05,
         -2.8715e-05, -1.3753e-05],
        [-1.8723e-05, -9.3390e-06, -2.3723e-05,  ..., -1.0058e-05,
          2.2157e-05,  1.8584e-05]], device='cuda:0')
==> name lstm.weight_hh_l0 torch.Size([1200, 300]) tensor([[ 2.8458e-06, -4.4557e-06, -6.8370e-07,  ..., -3.3741e-06,
         -3.6104e-06,  7.0828e-07],
        [ 2.3266e-06, -5.8981e-07,  4.3880e-07,  ...,  7.5365e-07,
         -4.2160e-06, -8.5639e-06],
        [ 3.2566e-06,  2.9229e-06,  1.1918e-06,  ..., -6.4489e-06,
         -2.7657e-06,  2.5152e-06],
        ...,
        [ 2.8986e-06, -4.2199e-06, -4.3624e-07,  ..., -1.3866e-05,
         -5.9519e-06,  3.3630e-06],
        [-9.1752e-07, -2.3933e-06,  3.0951e-06,  ..., -1.9824e-06,
         -3.0414e-06, -1.7565e-06],
        [-3.9912e-07, -1.1880e-07,  2.5218e-06,  ...,  1.9189e-06,
          1.0032e-06, -1.0221e-07]], device='cuda:0')
==> name lstm.bias_ih_l0 torch.Size([1200]) tensor([-2.2267e-05,  5.8388e-06, -1.5989e-05,  ..., -7.0332e-05,
        -3.8352e-05, -9.5590e-06], device='cuda:0')
==> name lstm.bias_hh_l0 torch.Size([1200]) tensor([-2.2267e-05,  5.8388e-06, -1.5989e-05,  ..., -7.0332e-05,
        -3.8352e-05, -9.5590e-06], device='cuda:0')
==> name lstm.weight_ih_l0_reverse torch.Size([1200, 300]) tensor([[-2.1009e-05, -9.1276e-06,  1.2823e-05,  ...,  7.5781e-06,
          6.6076e-06, -7.2918e-07],
        [-4.3847e-05,  4.6784e-05, -5.2562e-05,  ..., -2.4637e-06,
          7.1140e-05,  4.0314e-05],
        [ 1.9914e-06, -4.8924e-05, -1.0282e-05,  ..., -3.3681e-05,
          2.0801e-05, -1.9544e-05],
        ...,
        [-5.2487e-05,  6.7773e-05,  3.5962e-06,  ...,  3.4014e-05,
          1.7545e-05,  1.6700e-05],
        [ 1.4410e-05, -5.4098e-07,  1.3806e-05,  ..., -3.9811e-06,
         -6.0746e-06, -2.1375e-05],
        [ 2.6373e-07,  6.5539e-07, -3.2778e-05,  ...,  6.7724e-06,
          1.6335e-05,  2.1139e-05]], device='cuda:0')
==> name lstm.weight_hh_l0_reverse torch.Size([1200, 300]) tensor([[-1.5941e-06,  7.1464e-07, -6.9315e-06,  ..., -3.7947e-07,
         -3.1632e-06, -8.1802e-08],
        [ 6.8489e-06, -1.0771e-05,  2.6833e-05,  ..., -4.2769e-06,
          2.7571e-06, -3.6875e-06],
        [ 6.6771e-06, -5.1524e-06,  1.0036e-05,  ..., -4.8143e-07,
          2.9211e-06,  3.3817e-07],
        ...,
        [-1.6594e-06,  1.4496e-06, -9.0400e-07,  ..., -6.0295e-06,
         -3.0452e-06,  4.4551e-06],
        [-7.2838e-07,  2.7467e-06, -6.9223e-06,  ...,  1.6489e-06,
          2.2405e-07, -3.1720e-06],
        [ 5.8960e-06, -7.5881e-06,  1.0920e-05,  ..., -6.0163e-06,
          6.4852e-06,  7.1930e-06]], device='cuda:0')
==> name lstm.bias_ih_l0_reverse torch.Size([1200]) tensor([-5.7480e-06,  4.8582e-05,  8.1651e-07,  ..., -2.0819e-05,
        -1.3804e-05, -5.3273e-07], device='cuda:0')
==> name lstm.bias_hh_l0_reverse torch.Size([1200]) tensor([-5.7480e-06,  4.8582e-05,  8.1651e-07,  ..., -2.0819e-05,
        -1.3804e-05, -5.3273e-07], device='cuda:0')
==> name fc1.weight torch.Size([192, 600]) tensor([[-1.4134e-04, -4.9463e-04, -1.9366e-04,  ..., -1.5609e-04,
         -5.3499e-04,  1.6041e-04],
        [-3.1725e-04, -1.8180e-04, -1.6906e-04,  ..., -7.4116e-05,
         -7.0277e-04,  1.9246e-04],
        [-7.4898e-06, -2.5895e-06, -1.0774e-05,  ..., -1.3301e-05,
         -9.1895e-06,  9.6948e-06],
        ...,
        [-1.6369e-04,  3.5298e-04, -4.5264e-05,  ..., -1.4785e-04,
          1.8007e-04, -8.3460e-05],
        [ 1.0584e-04,  1.4830e-04,  4.0766e-05,  ...,  3.1775e-04,
         -1.1396e-04, -9.2776e-05],
        [-4.0623e-04,  1.8770e-05, -2.8859e-04,  ..., -3.3224e-04,
         -4.9010e-04,  1.9554e-04]], device='cuda:0')
==> name fc1.bias torch.Size([192]) tensor([-3.6203e-03, -2.0710e-03, -7.5104e-05, -1.7119e-03,  1.5702e-04,
        -1.9294e-03, -5.7035e-04, -1.4126e-04, -1.0720e-04, -2.8873e-04,
        -1.1863e-03,  1.7361e-03, -7.4263e-04, -9.5566e-04, -5.3060e-04,
        -3.5612e-04,  2.2537e-03,  1.8618e-04, -1.1134e-03, -3.2161e-03,
        -6.9087e-04,  5.3155e-03,  1.8050e-03, -4.3464e-04, -4.3959e-04,
         1.4164e-03,  2.2871e-05, -1.2604e-03, -1.5023e-03,  2.0640e-04,
        -5.2292e-04, -1.5929e-04,  3.7735e-04, -2.7254e-04, -1.0374e-04,
        -5.3243e-04, -1.2119e-03,  7.2999e-04, -4.9881e-05, -4.5617e-04,
        -9.8697e-04, -5.5967e-05, -4.9282e-04, -9.3404e-05,  4.4221e-05,
         1.3462e-03, -1.2941e-03, -4.2107e-04, -4.0676e-04, -1.4619e-03,
         1.1000e-03,  5.3516e-03, -1.8011e-06,  2.1812e-03, -1.3389e-03,
         4.2662e-04, -2.6100e-04, -3.0247e-03,  3.9177e-05, -2.2723e-04,
         4.0104e-04,  1.4393e-03, -1.4372e-03, -3.8618e-04, -8.1089e-04,
         7.3970e-05, -5.9701e-05, -3.2909e-03, -5.0427e-04, -5.9124e-04,
         3.2844e-03, -1.2894e-06,  1.0200e-04, -1.1460e-03, -3.6688e-03,
        -1.8266e-04, -1.0256e-04, -1.3405e-04,  1.7392e-03, -3.9158e-04,
        -4.2967e-04,  9.6153e-06, -1.1048e-03, -1.8386e-04,  3.0177e-03,
        -1.7334e-04, -1.8376e-04,  1.9344e-04,  1.9647e-04, -7.6746e-04,
         1.1107e-03,  2.5333e-03, -5.6895e-04,  2.9004e-04, -1.6548e-03,
         9.2292e-04,  2.5256e-03, -2.4096e-03, -2.9062e-04,  9.0399e-05,
        -2.5782e-03, -1.3733e-03, -3.0750e-05, -1.9632e-03, -1.3340e-03,
         2.5546e-03,  2.8089e-03,  5.0291e-04,  8.4117e-04,  4.2874e-03,
        -2.8520e-03,  5.0405e-04, -1.3200e-03,  5.4661e-04,  1.3130e-04,
        -2.2980e-04, -5.3791e-04,  7.0758e-04, -1.4659e-03,  5.8271e-05,
        -3.0736e-03,  8.6887e-06, -1.8242e-04,  1.1165e-03,  1.6859e-03,
         2.5623e-04,  1.0909e-03, -4.4202e-03, -7.5349e-04,  1.1432e-04,
        -4.3059e-04,  1.6364e-04, -9.7172e-04,  3.0494e-04, -1.2170e-03,
        -2.4802e-03, -2.5324e-03,  1.6900e-04,  1.7072e-03,  5.1229e-03,
         3.1706e-03,  5.1423e-03, -2.4135e-04, -1.1855e-03,  8.2547e-04,
         6.3194e-04, -6.0434e-05, -1.7708e-03, -1.6076e-03,  1.4386e-03,
        -5.4521e-04,  2.3479e-05, -1.3477e-04,  2.4005e-03,  1.5975e-03,
        -1.4750e-04, -1.9902e-03, -3.1531e-03, -3.6889e-04, -3.5432e-04,
        -2.1403e-03,  9.0060e-06, -1.7882e-03, -2.9896e-03, -1.3638e-03,
        -1.6027e-04,  2.4974e-03, -1.3930e-03,  2.6144e-03,  5.1343e-03,
        -2.0028e-04, -3.9071e-04,  4.5443e-04, -2.9873e-04,  2.2333e-03,
         4.1524e-04,  9.7001e-04, -1.9633e-03, -2.2437e-03, -1.3475e-03,
         1.1122e-03,  4.0719e-04,  1.4258e-03,  6.6877e-04, -4.8293e-04,
        -3.7328e-05,  2.9593e-03,  7.9253e-04, -2.1937e-03,  1.7298e-03,
        -2.3301e-04, -2.1170e-03], device='cuda:0')
==> name fc2.weight torch.Size([2, 192]) tensor([[-3.8547e-03, -2.3388e-03, -1.8368e-03, -3.1727e-03,  1.0537e-03,
         -1.6083e-04,  4.4095e-04, -1.7636e-05, -1.2530e-04,  3.0054e-04,
         -3.1521e-03, -9.3742e-04, -2.6707e-03, -1.4181e-03, -1.4139e-02,
          9.0617e-06, -5.3793e-03, -5.6601e-04, -3.2756e-03, -4.3542e-03,
         -4.7566e-03, -4.9189e-03,  2.7095e-04, -3.6080e-03, -3.2166e-03,
         -3.3917e-03, -6.2897e-04, -5.5165e-03, -1.7469e-03, -8.3515e-04,
         -2.1930e-04, -1.6391e-03, -3.6858e-03,  2.4591e-04, -3.4335e-04,
         -3.5637e-04, -2.3717e-03, -1.0157e-03,  2.0655e-04, -2.8803e-03,
          1.1491e-03, -1.0840e-03, -3.7795e-03, -6.4570e-04,  3.7551e-05,
         -9.3928e-04, -1.6989e-03, -1.4070e-03, -9.8895e-05, -4.2855e-03,
         -2.6792e-03, -4.4926e-03, -6.6091e-03, -2.1091e-04, -3.7704e-03,
          2.9581e-04,  1.1105e-03, -3.4101e-03,  2.9975e-04, -7.8336e-03,
         -2.0063e-03, -1.1307e-03, -6.5475e-03, -2.4037e-03, -4.1380e-03,
          1.0249e-04,  6.5654e-04, -8.0234e-03,  1.9957e-04, -2.2697e-03,
          6.4281e-04, -3.0942e-05, -2.0935e-03, -1.7502e-03, -4.2419e-04,
         -9.2686e-04,  3.9617e-04, -8.2176e-04, -3.5593e-03,  1.0698e-03,
          8.8711e-04,  6.0399e-04,  2.1980e-05, -6.1234e-04, -2.9117e-03,
         -1.5931e-04, -5.4008e-03, -1.7071e-04, -4.1320e-03, -1.8263e-03,
         -1.3485e-03, -1.4781e-03, -1.4047e-03, -3.4034e-04, -1.3811e-03,
         -2.1133e-03, -2.0664e-03, -2.9830e-03,  1.8040e-04, -2.5333e-04,
         -1.0622e-02, -8.5991e-03,  1.6051e-04,  7.6653e-04, -3.6017e-04,
         -2.1610e-03, -4.5267e-03, -5.2539e-03, -1.8209e-03, -8.5076e-04,
          5.1191e-04, -3.0724e-04,  1.4266e-03, -1.7844e-03,  2.0324e-04,
         -5.3415e-04, -6.0329e-03, -5.7059e-03, -3.1945e-03,  3.6216e-05,
         -7.9447e-03, -2.4596e-04, -5.1567e-03, -7.2081e-04, -5.0179e-03,
         -7.3310e-04, -2.6425e-03, -6.1807e-03, -1.2168e-03, -2.4820e-03,
         -1.2592e-03, -5.5455e-05, -2.6005e-03, -4.4515e-04, -3.3949e-03,
         -3.8655e-03, -6.0190e-03, -5.1471e-04, -3.9113e-05, -6.3351e-03,
         -1.0705e-04, -3.7320e-03,  1.1257e-03, -5.8671e-03, -2.8241e-03,
         -8.9594e-04,  1.3198e-04, -4.7567e-03, -1.4468e-04, -2.0368e-03,
         -1.7412e-03,  4.2130e-04,  1.6128e-03, -4.1480e-03, -5.4066e-04,
          4.4595e-04, -4.8840e-03, -1.5511e-03,  1.1700e-03,  4.9207e-04,
         -9.2071e-04, -1.5030e-04,  5.7480e-04, -4.7508e-03, -6.3385e-03,
         -5.0050e-03, -3.3955e-03,  4.8837e-04, -7.1767e-03, -7.8763e-04,
         -4.4166e-04, -1.6455e-03, -3.5021e-04, -9.5497e-04, -9.4473e-03,
         -1.4194e-03, -2.5438e-03, -8.3838e-03, -5.4017e-03, -5.3750e-04,
         -1.7689e-03, -2.1069e-03, -7.5724e-04, -2.4790e-03, -1.1174e-05,
          6.5396e-04, -1.1413e-03, -4.0451e-04,  1.8872e-04,  1.0001e-03,
         -1.1180e-03, -7.7637e-03],
        [ 6.1836e-03,  0.0000e+00,  0.0000e+00,  1.8155e-03,  1.5643e-05,
          2.3192e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          5.4735e-03,  1.2217e-02,  0.0000e+00,  2.5342e-03,  4.6905e-03,
          0.0000e+00,  5.2521e-03,  0.0000e+00,  2.1605e-03,  1.7221e-04,
          0.0000e+00,  1.3460e-02,  6.3917e-03,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  4.0134e-03,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  8.0076e-04,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  4.8159e-04,
          0.0000e+00,  0.0000e+00,  3.0067e-03,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  8.3883e-07,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          2.0914e-03,  8.8806e-03,  6.7439e-03,  1.0448e-02,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  5.8782e-03,
          4.2738e-03,  1.2097e-02,  4.3755e-03,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  2.0084e-03,  1.9917e-03,  1.1531e-04,  0.0000e+00,
          8.1027e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.1194e-03,
         -1.1209e-05,  0.0000e+00,  0.0000e+00,  1.4738e-02,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  6.2241e-03,
          5.0973e-03,  4.2083e-03,  0.0000e+00,  0.0000e+00,  6.8993e-03,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  2.7406e-03,  0.0000e+00,
          0.0000e+00,  1.0569e-02,  0.0000e+00,  5.7250e-03,  0.0000e+00,
          4.2581e-03,  6.3417e-03,  0.0000e+00,  1.1847e-03,  8.9864e-05,
          1.0092e-02,  1.2748e-02,  4.1618e-03,  0.0000e+00,  8.2156e-03,
          9.2694e-04,  0.0000e+00,  0.0000e+00,  1.4266e-03,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  1.0456e-02,  0.0000e+00,  0.0000e+00,
          8.9157e-05,  0.0000e+00,  6.5127e-04,  0.0000e+00,  1.8121e-02,
          0.0000e+00,  0.0000e+00,  9.9423e-04,  0.0000e+00,  2.3261e-03,
          3.8670e-06,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.8982e-03,
          2.7498e-05,  2.6089e-03,  0.0000e+00,  3.9211e-03,  1.6409e-02,
          6.3487e-03,  6.1629e-03,  0.0000e+00,  0.0000e+00,  5.8584e-03,
          2.0506e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,  4.0517e-03,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0902e-02,  3.4663e-05,
          0.0000e+00, -8.8952e-06,  0.0000e+00,  0.0000e+00,  2.0122e-03,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  7.3844e-03,  0.0000e+00,
          0.0000e+00,  1.1064e-02,  0.0000e+00,  6.9589e-03,  1.4874e-02,
          2.6474e-05,  8.3128e-05,  0.0000e+00,  1.5704e-04,  0.0000e+00,
          4.9995e-06,  4.2894e-03,  4.2763e-03,  2.3111e-03,  3.3636e-03,
          9.4838e-03,  4.0452e-03,  0.0000e+00,  1.5381e-03,  0.0000e+00,
          0.0000e+00,  8.8045e-03,  0.0000e+00,  3.4859e-03,  1.2302e-02,
          0.0000e+00,  0.0000e+00]], device='cuda:0')
==> name fc2.bias torch.Size([2]) tensor([-0.0533,  0.0533], device='cuda:0')
Iter:     50,  Train Loss:  0.25,  Train Acc: 46.88%,  Val Loss:  0.23,  Val Acc: 49.92%,  Time: 0:00:02 ,  LR: 0.00015877852522925052
s_logits tensor([[0.4606, 0.5394],
        [0.4583, 0.5417],
        [0.4593, 0.5407],
        [0.4596, 0.5404],
        [0.4614, 0.5386],
        [0.4586, 0.5414],
        [0.4592, 0.5408],
        [0.4574, 0.5426],
        [0.4607, 0.5393],
        [0.4587, 0.5413],
        [0.4801, 0.5199],
        [0.4605, 0.5395],
        [0.4588, 0.5412],
        [0.4607, 0.5393],
        [0.4576, 0.5424],
        [0.4597, 0.5403],
        [0.4598, 0.5402],
        [0.4578, 0.5422],
        [0.4623, 0.5377],
        [0.4589, 0.5411],
        [0.4601, 0.5399],
        [0.4606, 0.5394],
        [0.4590, 0.5410],
        [0.4584, 0.5416],
        [0.4603, 0.5397],
        [0.4598, 0.5402],
        [0.4663, 0.5337],
        [0.4532, 0.5468],
        [0.4612, 0.5388],
        [0.4565, 0.5435],
        [0.4593, 0.5407],
        [0.4614, 0.5386],
        [0.4649, 0.5351],
        [0.4607, 0.5393],
        [0.4571, 0.5429],
        [0.4586, 0.5414],
        [0.4589, 0.5411],
        [0.4606, 0.5394],
        [0.4689, 0.5311],
        [0.4597, 0.5403],
        [0.4595, 0.5405],
        [0.4648, 0.5352],
        [0.4587, 0.5413],
        [0.4614, 0.5386],
        [0.4619, 0.5381],
        [0.4604, 0.5396],
        [0.4594, 0.5406],
        [0.4597, 0.5403],
        [0.4595, 0.5405],
        [0.4604, 0.5396],
        [0.4707, 0.5293],
        [0.4593, 0.5407],
        [0.4664, 0.5336],
        [0.4604, 0.5396],
        [0.4602, 0.5398],
        [0.4590, 0.5410],
        [0.4592, 0.5408],
        [0.4613, 0.5387],
        [0.4600, 0.5400],
        [0.4594, 0.5406],
        [0.4617, 0.5383],
        [0.4611, 0.5389],
        [0.4622, 0.5378],
        [0.4621, 0.5379]], device='cuda:0', grad_fn=<SoftmaxBackward0>) label tensor([1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1,
        0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1,
        0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0], device='cuda:0')
t_logits tensor([[4.1866e-03, 9.9581e-01],
        [9.9868e-01, 1.3215e-03],
        [3.6225e-03, 9.9638e-01],
        [3.5698e-03, 9.9643e-01],
        [9.9670e-01, 3.3039e-03],
        [2.1083e-02, 9.7892e-01],
        [9.9898e-01, 1.0237e-03],
        [2.1109e-02, 9.7889e-01],
        [9.7855e-01, 2.1445e-02],
        [9.9921e-01, 7.8884e-04],
        [4.6751e-03, 9.9532e-01],
        [9.9860e-01, 1.4011e-03],
        [9.8929e-01, 1.0715e-02],
        [9.9938e-01, 6.2266e-04],
        [9.9847e-01, 1.5339e-03],
        [3.1471e-03, 9.9685e-01],
        [1.9165e-02, 9.8084e-01],
        [2.8864e-03, 9.9711e-01],
        [5.1817e-03, 9.9482e-01],
        [2.3603e-02, 9.7640e-01],
        [9.7834e-01, 2.1663e-02],
        [8.8333e-01, 1.1667e-01],
        [3.4750e-02, 9.6525e-01],
        [7.0595e-03, 9.9294e-01],
        [9.9798e-01, 2.0227e-03],
        [2.2463e-02, 9.7754e-01],
        [3.3341e-02, 9.6666e-01],
        [2.9219e-03, 9.9708e-01],
        [9.8258e-01, 1.7421e-02],
        [9.9854e-01, 1.4592e-03],
        [6.1427e-03, 9.9386e-01],
        [9.9786e-01, 2.1403e-03],
        [7.5784e-03, 9.9242e-01],
        [9.9852e-01, 1.4781e-03],
        [7.6970e-03, 9.9230e-01],
        [6.6992e-03, 9.9330e-01],
        [9.9635e-01, 3.6517e-03],
        [5.7133e-03, 9.9429e-01],
        [9.9774e-01, 2.2599e-03],
        [9.9835e-01, 1.6478e-03],
        [9.9441e-01, 5.5863e-03],
        [9.9693e-01, 3.0675e-03],
        [9.9935e-01, 6.5311e-04],
        [7.7251e-03, 9.9227e-01],
        [1.8652e-02, 9.8135e-01],
        [1.5162e-02, 9.8484e-01],
        [9.8231e-01, 1.7693e-02],
        [9.9216e-01, 7.8383e-03],
        [3.7974e-03, 9.9620e-01],
        [9.9828e-01, 1.7155e-03],
        [9.9938e-01, 6.2141e-04],
        [5.5357e-02, 9.4464e-01],
        [4.0416e-03, 9.9596e-01],
        [9.9898e-01, 1.0150e-03],
        [9.3802e-03, 9.9062e-01],
        [2.8860e-02, 9.7114e-01],
        [7.6876e-02, 9.2312e-01],
        [4.5977e-03, 9.9540e-01],
        [9.9938e-01, 6.1742e-04],
        [7.1329e-03, 9.9287e-01],
        [9.9548e-01, 4.5206e-03],
        [3.4936e-03, 9.9651e-01],
        [9.9664e-01, 3.3613e-03],
        [3.8869e-03, 9.9611e-01]], device='cuda:0')
base_loss tensor(0.6893, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(0.2382, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor([  101,  2009,  1005,  1055, 24256, 12479,  1010,  2367,  2084,  2505,
         2008,  1005,  1055,  2042,  2589,  2077,  1998, 29350,  3144,  1999,
         3408,  1997,  2054,  2009,  1005,  1055,  2667,  2000,  2079,  1012,
          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0],
       device='cuda:0')
==> name Embedding.weight torch.Size([30522, 300]) tensor([[ 1.0643e-05, -4.5381e-06, -6.6287e-06,  ..., -5.2203e-06,
         -8.7257e-06,  2.1785e-07],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]], device='cuda:0')
==> name lstm.weight_ih_l0 torch.Size([1200, 300]) tensor([[-4.0199e-07,  3.6555e-06,  3.0867e-06,  ...,  2.7883e-07,
         -6.2843e-06, -1.2227e-06],
        [-1.1812e-06,  8.3038e-07,  1.0734e-06,  ...,  1.3674e-06,
         -3.5220e-07, -2.3420e-06],
        [ 6.5235e-06,  8.9958e-06, -3.1578e-06,  ...,  2.3513e-07,
          4.0462e-07, -1.0990e-07],
        ...,
        [-4.0540e-06,  4.3459e-07,  2.0603e-06,  ..., -1.6159e-06,
         -5.2308e-06, -7.0814e-07],
        [ 1.0144e-05,  1.2887e-05, -3.5093e-06,  ...,  3.5967e-06,
          5.2396e-06,  3.0503e-06],
        [-2.6410e-06, -3.6733e-06, -4.0523e-06,  ...,  9.7887e-07,
         -2.8695e-06,  1.5296e-06]], device='cuda:0')
==> name lstm.weight_hh_l0 torch.Size([1200, 300]) tensor([[-4.4884e-07, -2.1520e-07,  1.0946e-06,  ..., -2.3989e-07,
          1.0367e-08,  1.2340e-06],
        [-1.2445e-06,  1.9800e-08, -2.5833e-07,  ...,  4.0916e-07,
          4.8167e-07, -2.4021e-07],
        [ 4.5124e-08,  5.8070e-07, -5.3858e-07,  ...,  2.1386e-07,
          1.7645e-07,  5.5403e-07],
        ...,
        [ 1.4739e-06, -7.1512e-07, -1.8058e-06,  ..., -5.4578e-07,
         -1.4128e-06, -2.5490e-06],
        [-9.2802e-07,  1.4485e-06, -2.4368e-07,  ..., -5.8227e-07,
          2.2205e-06,  1.2732e-06],
        [ 1.2087e-06, -4.1383e-08,  1.6760e-06,  ..., -9.6556e-07,
         -2.0016e-06, -4.3508e-07]], device='cuda:0')
==> name lstm.bias_ih_l0 torch.Size([1200]) tensor([-2.2770e-06,  1.1498e-06, -4.6143e-07,  ...,  9.1532e-07,
         8.5811e-06, -4.6822e-06], device='cuda:0')
==> name lstm.bias_hh_l0 torch.Size([1200]) tensor([-2.2770e-06,  1.1498e-06, -4.6143e-07,  ...,  9.1532e-07,
         8.5811e-06, -4.6822e-06], device='cuda:0')
==> name lstm.weight_ih_l0_reverse torch.Size([1200, 300]) tensor([[-1.2423e-06, -1.9602e-06,  9.2663e-07,  ..., -4.5426e-07,
         -1.8249e-06, -9.7118e-07],
        [ 2.9493e-06,  4.0195e-06, -1.6602e-06,  ...,  1.0842e-06,
          3.0400e-06,  1.7799e-06],
        [ 2.4893e-06,  1.0465e-08,  1.4774e-06,  ...,  9.4555e-07,
         -4.3280e-06, -1.3023e-06],
        ...,
        [ 3.1784e-06,  1.9636e-06,  2.2643e-07,  ...,  1.1897e-06,
         -1.5508e-06, -4.5559e-08],
        [ 4.2347e-06,  4.3962e-06, -1.2134e-06,  ...,  1.5690e-06,
          1.5621e-06,  1.4153e-06],
        [ 1.4161e-06,  1.5578e-06, -4.8037e-07,  ...,  5.2392e-07,
          7.0106e-07,  5.4599e-07]], device='cuda:0')
==> name lstm.weight_hh_l0_reverse torch.Size([1200, 300]) tensor([[ 3.9754e-08,  7.4641e-08, -6.8451e-07,  ..., -1.4736e-07,
         -2.4263e-08,  4.6601e-08],
        [-7.6519e-08, -1.4367e-07,  1.3175e-06,  ...,  2.8364e-07,
          4.6701e-08, -8.9698e-08],
        [ 3.0671e-08,  5.7587e-08, -5.2810e-07,  ..., -1.1369e-07,
         -1.8719e-08,  3.5954e-08],
        ...,
        [-1.5767e-08, -2.9603e-08,  2.7148e-07,  ...,  5.8444e-08,
          9.6228e-09, -1.8483e-08],
        [-7.1139e-08, -1.3357e-07,  1.2249e-06,  ...,  2.6370e-07,
          4.3418e-08, -8.3393e-08],
        [-2.6259e-08, -4.9302e-08,  4.5213e-07,  ...,  9.7334e-08,
          1.6026e-08, -3.0781e-08]], device='cuda:0')
==> name lstm.bias_ih_l0_reverse torch.Size([1200]) tensor([-1.8536e-06,  3.5720e-06, -1.4293e-06,  ...,  7.3363e-07,
         3.3201e-06,  1.2245e-06], device='cuda:0')
==> name lstm.bias_hh_l0_reverse torch.Size([1200]) tensor([-1.8536e-06,  3.5720e-06, -1.4293e-06,  ...,  7.3363e-07,
         3.3201e-06,  1.2245e-06], device='cuda:0')
==> name fc1.weight torch.Size([192, 600]) tensor([[ 7.8813e-05, -4.6242e-05, -2.7245e-05,  ...,  5.2339e-05,
         -3.3845e-05, -1.3615e-05],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 5.7994e-05, -3.4027e-05, -2.0049e-05,  ...,  3.8514e-05,
         -2.4905e-05, -1.0019e-05],
        [-4.0158e-06,  2.9692e-05,  1.7499e-05,  ..., -2.3084e-05,
          1.4928e-05,  6.0051e-06]], device='cuda:0')
==> name fc1.bias torch.Size([192]) tensor([-3.5956e-04,  0.0000e+00,  0.0000e+00, -1.7949e-04, -2.3544e-04,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
        -1.4519e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,  4.2159e-05,
         0.0000e+00,  0.0000e+00,  0.0000e+00, -2.4718e-04, -4.9625e-04,
         3.2637e-04,  0.0000e+00,  0.0000e+00, -1.7176e-06,  0.0000e+00,
         8.9283e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
        -1.1143e-04, -1.7510e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00, -4.5683e-05, -6.2386e-06,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.2741e-04, -5.0443e-04,
         3.0194e-04,  0.0000e+00,  0.0000e+00,  3.8864e-05, -2.1442e-03,
         0.0000e+00,  0.0000e+00,  2.2172e-03,  4.4016e-05,  7.0907e-05,
         0.0000e+00, -3.0215e-04, -1.0769e-04,  1.2027e-05,  2.0727e-04,
         0.0000e+00, -1.9647e-04, -3.4940e-04,  0.0000e+00, -5.0400e-04,
         5.1108e-04, -1.7043e-04,  0.0000e+00, -1.3429e-04, -4.8346e-04,
         4.4406e-04,  0.0000e+00,  0.0000e+00,  1.7151e-04,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  8.1469e-04,  0.0000e+00,  3.4643e-04,
        -1.1054e-04, -3.3777e-05,  1.4201e-04,  0.0000e+00,  8.7607e-06,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  2.4505e-04, -2.7791e-04,  0.0000e+00,  0.0000e+00,
        -1.5847e-04, -1.0395e-04, -1.0877e-04,  0.0000e+00, -1.7848e-04,
         2.1432e-04,  2.6267e-04, -3.0920e-05,  4.3344e-04,  4.7644e-05,
        -3.5403e-04,  0.0000e+00, -8.7480e-05,  1.5532e-04,  0.0000e+00,
         0.0000e+00,  2.1959e-04,  6.4666e-05,  4.9615e-04,  0.0000e+00,
        -6.1639e-04, -2.2294e-04,  0.0000e+00,  0.0000e+00,  1.3817e-04,
         0.0000e+00,  4.7592e-04,  0.0000e+00,  1.1066e-04,  0.0000e+00,
         0.0000e+00, -1.6599e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,
        -1.4528e-04, -2.5157e-04,  0.0000e+00,  0.0000e+00,  6.3067e-04,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00, -5.5440e-05,  7.1440e-05, -2.3612e-04,
         0.0000e+00,  0.0000e+00,  2.4918e-04,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
        -5.0421e-04,  0.0000e+00,  0.0000e+00, -3.2349e-04,  0.0000e+00,
         1.5027e-04,  2.8839e-04,  0.0000e+00,  2.8222e-04,  0.0000e+00,
         0.0000e+00,  1.0685e-04,  0.0000e+00, -6.8056e-05,  0.0000e+00,
         1.1887e-04,  1.4084e-04, -1.5848e-04,  7.9853e-04,  0.0000e+00,
         1.2048e-05,  1.3229e-05,  0.0000e+00,  0.0000e+00,  2.0033e-04,
         0.0000e+00, -1.2162e-04,  0.0000e+00,  1.5222e-04,  0.0000e+00,
        -2.6458e-04,  1.5858e-04], device='cuda:0')
==> name fc2.weight torch.Size([2, 192]) tensor([[-1.0049e-03,  0.0000e+00,  0.0000e+00, -1.4172e-03,  4.2324e-06,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         -8.4957e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00, -2.5336e-03,
          0.0000e+00,  0.0000e+00,  0.0000e+00, -2.5162e-03, -4.2182e-04,
          1.7087e-04,  0.0000e+00,  0.0000e+00, -1.5395e-04,  0.0000e+00,
          2.3293e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         -2.1369e-03, -6.1510e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  6.3003e-05, -4.9707e-04,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00, -2.3852e-03, -1.7770e-04,
         -1.0161e-03,  0.0000e+00,  0.0000e+00, -1.5565e-03, -2.1352e-04,
          0.0000e+00,  0.0000e+00,  3.8415e-04, -7.4016e-04, -2.0228e-03,
          0.0000e+00, -2.9485e-04,  1.9802e-04, -1.2104e-03, -3.0802e-03,
          0.0000e+00,  1.7522e-04, -1.1167e-03,  0.0000e+00, -8.5691e-04,
         -2.4099e-03, -2.0930e-04,  0.0000e+00, -1.2955e-03,  1.8839e-04,
         -1.5970e-03,  0.0000e+00,  0.0000e+00, -1.9203e-03,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  2.1235e-04,  0.0000e+00, -5.1774e-04,
         -7.6232e-04, -1.5909e-03,  6.0605e-04,  0.0000e+00, -7.2881e-04,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00, -1.0508e-03, -2.9472e-04,  0.0000e+00,  0.0000e+00,
         -7.2594e-04, -6.8626e-04,  2.1437e-05,  0.0000e+00, -3.1594e-04,
         -5.6519e-04, -8.6240e-04, -2.2008e-03, -6.0517e-05,  5.3080e-05,
         -5.5514e-04,  0.0000e+00, -4.4160e-05,  2.7786e-04,  0.0000e+00,
          0.0000e+00,  3.4409e-05, -1.0069e-03,  6.2300e-05,  0.0000e+00,
         -1.6112e-03,  1.1936e-07,  0.0000e+00,  0.0000e+00, -1.2584e-04,
          0.0000e+00, -2.0497e-03,  0.0000e+00, -1.6840e-03,  0.0000e+00,
          0.0000e+00,  1.4229e-06,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         -1.9754e-04, -1.7721e-03,  0.0000e+00,  0.0000e+00, -1.5970e-03,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00, -1.1956e-03, -1.7507e-03,  4.5170e-05,
          0.0000e+00,  0.0000e+00, -2.7878e-03,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         -1.1948e-03,  0.0000e+00,  0.0000e+00, -8.2833e-04,  0.0000e+00,
         -6.4865e-05, -1.4168e-03,  0.0000e+00, -1.3643e-03,  0.0000e+00,
          0.0000e+00,  2.7558e-05,  0.0000e+00, -1.2689e-05,  0.0000e+00,
         -1.0541e-03, -1.3671e-03, -3.1741e-04,  2.8370e-04,  0.0000e+00,
         -4.5832e-04, -9.2045e-06,  0.0000e+00,  0.0000e+00, -1.3296e-05,
          0.0000e+00,  1.2545e-04,  0.0000e+00,  1.6024e-04,  0.0000e+00,
         -9.3874e-04, -1.2172e-05],
        [ 1.0049e-03,  0.0000e+00,  0.0000e+00,  1.4172e-03, -4.2324e-06,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          8.4957e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.5336e-03,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  2.5162e-03,  4.2182e-04,
         -1.7087e-04,  0.0000e+00,  0.0000e+00,  1.5395e-04,  0.0000e+00,
         -2.3293e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          2.1369e-03,  6.1510e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00, -6.3003e-05,  4.9707e-04,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  2.3852e-03,  1.7770e-04,
          1.0161e-03,  0.0000e+00,  0.0000e+00,  1.5565e-03,  2.1352e-04,
          0.0000e+00,  0.0000e+00, -3.8415e-04,  7.4016e-04,  2.0228e-03,
          0.0000e+00,  2.9485e-04, -1.9802e-04,  1.2104e-03,  3.0802e-03,
          0.0000e+00, -1.7522e-04,  1.1167e-03,  0.0000e+00,  8.5691e-04,
          2.4099e-03,  2.0930e-04,  0.0000e+00,  1.2955e-03, -1.8839e-04,
          1.5970e-03,  0.0000e+00,  0.0000e+00,  1.9203e-03,  0.0000e+00,
          0.0000e+00,  0.0000e+00, -2.1235e-04,  0.0000e+00,  5.1774e-04,
          7.6232e-04,  1.5909e-03, -6.0605e-04,  0.0000e+00,  7.2881e-04,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  1.0508e-03,  2.9472e-04,  0.0000e+00,  0.0000e+00,
          7.2594e-04,  6.8626e-04, -2.1437e-05,  0.0000e+00,  3.1594e-04,
          5.6519e-04,  8.6240e-04,  2.2008e-03,  6.0516e-05, -5.3080e-05,
          5.5514e-04,  0.0000e+00,  4.4160e-05, -2.7786e-04,  0.0000e+00,
          0.0000e+00, -3.4409e-05,  1.0069e-03, -6.2300e-05,  0.0000e+00,
          1.6112e-03, -1.1936e-07,  0.0000e+00,  0.0000e+00,  1.2584e-04,
          0.0000e+00,  2.0497e-03,  0.0000e+00,  1.6840e-03,  0.0000e+00,
          0.0000e+00, -1.4229e-06,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          1.9754e-04,  1.7721e-03,  0.0000e+00,  0.0000e+00,  1.5970e-03,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  1.1956e-03,  1.7507e-03, -4.5170e-05,
          0.0000e+00,  0.0000e+00,  2.7878e-03,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          1.1948e-03,  0.0000e+00,  0.0000e+00,  8.2833e-04,  0.0000e+00,
          6.4865e-05,  1.4168e-03,  0.0000e+00,  1.3643e-03,  0.0000e+00,
          0.0000e+00, -2.7558e-05,  0.0000e+00,  1.2689e-05,  0.0000e+00,
          1.0541e-03,  1.3671e-03,  3.1741e-04, -2.8370e-04,  0.0000e+00,
          4.5832e-04,  9.2045e-06,  0.0000e+00,  0.0000e+00,  1.3296e-05,
          0.0000e+00, -1.2545e-04,  0.0000e+00, -1.6024e-04,  0.0000e+00,
          9.3874e-04,  1.2172e-05]], device='cuda:0')
==> name fc2.bias torch.Size([2]) tensor([-0.0058,  0.0058], device='cuda:0')
Iter:    100,  Train Loss:  0.24,  Train Acc: 56.25%,  Val Loss:  0.22,  Val Acc: 49.92%,  Time: 0:00:04 ,  LR: 5.932633569241989e-05
Epoch [2/30]
s_logits tensor([[0.4708, 0.5292],
        [0.4677, 0.5323],
        [0.4724, 0.5276],
        [0.4670, 0.5330],
        [0.4685, 0.5315],
        [0.4664, 0.5336],
        [0.4674, 0.5326],
        [0.4619, 0.5381],
        [0.4687, 0.5313],
        [0.4703, 0.5297],
        [0.4692, 0.5308],
        [0.4680, 0.5320],
        [0.4678, 0.5322],
        [0.4700, 0.5300],
        [0.4665, 0.5335],
        [0.4674, 0.5326],
        [0.4684, 0.5316],
        [0.4683, 0.5317],
        [0.4690, 0.5310],
        [0.4653, 0.5347],
        [0.4693, 0.5307],
        [0.4706, 0.5294],
        [0.4661, 0.5339],
        [0.4697, 0.5303],
        [0.4692, 0.5308],
        [0.4706, 0.5294],
        [0.4672, 0.5328],
        [0.4663, 0.5337],
        [0.4708, 0.5292],
        [0.4699, 0.5301],
        [0.4675, 0.5325],
        [0.4705, 0.5295],
        [0.4682, 0.5318],
        [0.4664, 0.5336],
        [0.4699, 0.5301],
        [0.4682, 0.5318],
        [0.4654, 0.5346],
        [0.4682, 0.5318],
        [0.4696, 0.5304],
        [0.4695, 0.5305],
        [0.4670, 0.5330],
        [0.4706, 0.5294],
        [0.4661, 0.5339],
        [0.4664, 0.5336],
        [0.4726, 0.5274],
        [0.4656, 0.5344],
        [0.4682, 0.5318],
        [0.4666, 0.5334],
        [0.4687, 0.5313],
        [0.4672, 0.5328],
        [0.4681, 0.5319],
        [0.4717, 0.5283],
        [0.4675, 0.5325],
        [0.4667, 0.5333],
        [0.4671, 0.5329],
        [0.4680, 0.5320],
        [0.4688, 0.5312],
        [0.4660, 0.5340],
        [0.4678, 0.5322],
        [0.4663, 0.5337],
        [0.4658, 0.5342],
        [0.4682, 0.5318],
        [0.4698, 0.5302],
        [0.4684, 0.5316]], device='cuda:0', grad_fn=<SoftmaxBackward0>) label tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1,
        1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1], device='cuda:0')
t_logits tensor([[8.1666e-03, 9.9183e-01],
        [9.9921e-01, 7.9013e-04],
        [3.3586e-01, 6.6414e-01],
        [9.9874e-01, 1.2649e-03],
        [9.9543e-01, 4.5695e-03],
        [6.5895e-03, 9.9341e-01],
        [5.1427e-03, 9.9486e-01],
        [3.1161e-03, 9.9688e-01],
        [5.5556e-03, 9.9444e-01],
        [3.5193e-03, 9.9648e-01],
        [2.9431e-02, 9.7057e-01],
        [9.9921e-01, 7.8535e-04],
        [3.0449e-03, 9.9696e-01],
        [9.9888e-01, 1.1170e-03],
        [4.0080e-03, 9.9599e-01],
        [1.0628e-02, 9.8937e-01],
        [1.1172e-02, 9.8883e-01],
        [9.9216e-01, 7.8411e-03],
        [6.1694e-03, 9.9383e-01],
        [7.4154e-03, 9.9258e-01],
        [9.8738e-01, 1.2616e-02],
        [9.9357e-01, 6.4350e-03],
        [9.9669e-01, 3.3058e-03],
        [2.0594e-02, 9.7941e-01],
        [9.9654e-01, 3.4634e-03],
        [9.9948e-01, 5.1982e-04],
        [9.9945e-01, 5.5318e-04],
        [2.1315e-02, 9.7868e-01],
        [4.0183e-03, 9.9598e-01],
        [1.5797e-02, 9.8420e-01],
        [1.5271e-02, 9.8473e-01],
        [9.9924e-01, 7.5767e-04],
        [6.5296e-03, 9.9347e-01],
        [9.9838e-01, 1.6195e-03],
        [4.2043e-03, 9.9580e-01],
        [9.9944e-01, 5.6369e-04],
        [6.0282e-03, 9.9397e-01],
        [9.9830e-01, 1.6955e-03],
        [9.9953e-01, 4.7178e-04],
        [3.1116e-02, 9.6888e-01],
        [9.9932e-01, 6.7784e-04],
        [9.9927e-01, 7.3154e-04],
        [3.5414e-02, 9.6459e-01],
        [9.9934e-01, 6.5629e-04],
        [9.9645e-01, 3.5453e-03],
        [6.2262e-03, 9.9377e-01],
        [4.8790e-03, 9.9512e-01],
        [5.6165e-03, 9.9438e-01],
        [5.0370e-03, 9.9496e-01],
        [5.3949e-03, 9.9461e-01],
        [3.6996e-03, 9.9630e-01],
        [9.9669e-01, 3.3065e-03],
        [9.9896e-01, 1.0432e-03],
        [9.9936e-01, 6.4149e-04],
        [2.8940e-01, 7.1060e-01],
        [3.3104e-03, 9.9669e-01],
        [9.9692e-01, 3.0811e-03],
        [9.9936e-01, 6.3563e-04],
        [9.9824e-01, 1.7643e-03],
        [2.5674e-02, 9.7433e-01],
        [9.9875e-01, 1.2533e-03],
        [8.3294e-03, 9.9167e-01],
        [9.9885e-01, 1.1472e-03],
        [9.9931e-01, 6.9159e-04]], device='cuda:0')
base_loss tensor(0.6925, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(0.2368, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor([  101,  2045,  1005,  1055,  3904,  1997,  1996, 11361,  1011,  2412,
         1011,  2044,  8487,  9354,  1997, 19183,  5030,  1999,  2397,  3510,
         1011,  1011,  1998,  2008,  1005,  1055,  2112,  1997,  2054,  3084,
        13985, 12849, 20939,  2232, 21661,  1005,  1055,  5151,  3444,  2834,
         2061, 16834,  1012,   102,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0],
       device='cuda:0')
==> name Embedding.weight torch.Size([30522, 300]) tensor([[ 1.2255e-05,  1.6533e-06,  1.0981e-05,  ...,  6.5073e-06,
         -1.0552e-06,  8.7159e-06],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]], device='cuda:0')
==> name lstm.weight_ih_l0 torch.Size([1200, 300]) tensor([[-9.5775e-07,  1.6129e-06,  6.2385e-06,  ..., -8.2151e-06,
         -3.8651e-06, -9.4710e-07],
        [ 6.1104e-06,  3.5627e-06, -8.7443e-06,  ...,  6.5752e-06,
         -9.6635e-06,  1.0912e-05],
        [ 2.2145e-06,  6.1317e-07, -2.7278e-06,  ...,  2.3630e-06,
         -2.8370e-06,  3.4875e-06],
        ...,
        [-2.1711e-05, -2.3282e-05,  5.3442e-06,  ..., -9.7060e-06,
         -6.5849e-06, -9.7363e-06],
        [ 1.1867e-05,  1.3097e-05, -2.0913e-06,  ...,  6.6573e-06,
          3.4539e-06,  5.1878e-06],
        [-4.8815e-06, -5.7613e-06, -5.2814e-07,  ..., -1.7189e-06,
         -5.3760e-06, -5.5217e-07]], device='cuda:0')
==> name lstm.weight_hh_l0 torch.Size([1200, 300]) tensor([[-7.3970e-07,  3.5170e-09,  6.3034e-07,  ...,  1.0915e-06,
         -9.2747e-07, -1.3070e-06],
        [-1.0086e-07, -1.0992e-06, -1.1455e-06,  ..., -1.4698e-06,
         -7.1865e-07, -6.1971e-07],
        [-2.0595e-07,  7.3716e-07, -3.8104e-07,  ...,  2.4417e-07,
         -2.3490e-07, -5.0329e-07],
        ...,
        [ 3.8338e-06,  4.6639e-07,  1.6414e-06,  ..., -3.1604e-07,
         -1.8689e-06,  4.1950e-06],
        [-2.2031e-06,  6.0381e-07, -1.7666e-06,  ...,  1.6825e-06,
          1.6701e-06, -2.1120e-06],
        [ 9.6448e-07,  2.9797e-07,  2.8818e-07,  ..., -1.1844e-06,
         -6.9962e-07,  5.7322e-07]], device='cuda:0')
==> name lstm.bias_ih_l0 torch.Size([1200]) tensor([-1.9614e-06, -9.9609e-06,  2.6630e-07,  ..., -1.5901e-05,
         7.6094e-06, -6.9162e-06], device='cuda:0')
==> name lstm.bias_hh_l0 torch.Size([1200]) tensor([-1.9614e-06, -9.9609e-06,  2.6630e-07,  ..., -1.5901e-05,
         7.6094e-06, -6.9162e-06], device='cuda:0')
==> name lstm.weight_ih_l0_reverse torch.Size([1200, 300]) tensor([[ 5.6695e-06,  1.1231e-05, -1.0285e-06,  ..., -3.0298e-06,
          3.9677e-07, -6.4768e-06],
        [-1.4056e-07, -1.4954e-06, -2.4871e-06,  ...,  8.9791e-07,
          2.0372e-07, -7.6819e-07],
        [-2.7205e-06,  9.3403e-07, -2.1663e-06,  ..., -3.3875e-06,
         -7.4736e-06, -4.3373e-06],
        ...,
        [ 2.6844e-06,  3.3491e-06, -3.4995e-06,  ...,  1.7805e-06,
          1.6402e-06,  4.2015e-06],
        [ 1.6271e-06,  1.5616e-06, -6.7518e-07,  ...,  5.4150e-07,
          5.4982e-07,  3.5959e-07],
        [ 1.2077e-05,  7.9551e-06, -4.5895e-06,  ..., -4.6392e-07,
         -1.7864e-05,  7.1108e-06]], device='cuda:0')
==> name lstm.weight_hh_l0_reverse torch.Size([1200, 300]) tensor([[-1.4447e-06,  5.2377e-07,  2.8673e-07,  ...,  2.5747e-07,
          5.9562e-07,  9.7040e-07],
        [ 3.4074e-07, -1.0611e-07, -1.3674e-07,  ..., -3.6227e-07,
          9.3848e-08, -3.1782e-08],
        [-1.7514e-06,  8.7804e-07, -1.8668e-06,  ...,  1.1616e-08,
          3.1786e-07,  9.5108e-07],
        ...,
        [ 1.1117e-06, -5.2002e-07,  1.4184e-06,  ...,  4.6920e-07,
          9.4815e-09,  5.8537e-08],
        [-2.8597e-08, -3.0623e-08,  3.6067e-07,  ...,  4.5483e-08,
          1.9083e-08, -3.0781e-08],
        [ 1.5819e-08, -2.0083e-06, -1.7745e-06,  ...,  5.9847e-07,
         -7.9283e-08, -2.1265e-07]], device='cuda:0')
==> name lstm.bias_ih_l0_reverse torch.Size([1200]) tensor([ 3.0259e-06, -2.3636e-06, -7.1490e-08,  ...,  6.6809e-07,
         1.1618e-06, -1.0581e-05], device='cuda:0')
==> name lstm.bias_hh_l0_reverse torch.Size([1200]) tensor([ 3.0259e-06, -2.3636e-06, -7.1490e-08,  ...,  6.6809e-07,
         1.1618e-06, -1.0581e-05], device='cuda:0')
==> name fc1.weight torch.Size([192, 600]) tensor([[ 4.1551e-05, -2.9979e-05,  1.3886e-05,  ...,  1.6807e-05,
         -5.8329e-06, -2.6646e-06],
        [-3.7342e-05, -1.1021e-04,  2.3610e-05,  ..., -4.3836e-05,
         -4.2932e-05,  7.1616e-05],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 1.9574e-05,  4.1047e-06, -1.2412e-05,  ...,  3.2115e-05,
         -1.3045e-05, -3.0616e-05],
        [ 1.2519e-05, -3.2496e-05,  1.3459e-05,  ...,  1.0795e-05,
         -1.3913e-06,  2.9956e-05],
        [-3.8615e-05, -1.5171e-05,  1.2562e-05,  ..., -1.4164e-05,
          9.7260e-06,  6.6923e-05]], device='cuda:0')
==> name fc1.bias torch.Size([192]) tensor([-1.1203e-04, -5.2817e-04,  0.0000e+00, -2.2109e-04,  5.9157e-04,
         8.7265e-05, -1.8286e-04,  2.2939e-04,  0.0000e+00,  0.0000e+00,
         0.0000e+00, -7.1445e-05, -3.5546e-04,  0.0000e+00,  3.1713e-04,
        -2.5674e-04,  0.0000e+00,  0.0000e+00, -7.3654e-05, -3.7093e-04,
        -1.4594e-04,  2.0853e-04, -2.6761e-04, -4.3833e-05, -7.6909e-05,
         2.6887e-04,  0.0000e+00,  0.0000e+00,  1.8682e-04,  3.5386e-05,
        -1.6141e-04, -8.1000e-05,  2.1047e-04,  0.0000e+00, -1.9270e-04,
         9.4976e-05, -9.3073e-05,  1.4267e-04, -1.2188e-04, -2.7051e-04,
        -2.0776e-05,  0.0000e+00, -2.5985e-04, -3.4594e-05, -3.1573e-04,
         2.6810e-04,  0.0000e+00, -5.7708e-05,  2.5181e-04, -6.1397e-04,
         2.1697e-04,  2.0813e-04, -2.3503e-04,  2.3721e-04, -2.2449e-04,
         1.1012e-04, -3.1781e-04, -5.0938e-04,  1.5090e-05,  8.4923e-05,
         0.0000e+00,  0.0000e+00, -1.4779e-04,  7.6049e-05,  2.4990e-04,
         1.7752e-05, -1.8577e-04, -2.0847e-04,  0.0000e+00, -6.1219e-04,
         5.1107e-04, -5.5436e-06,  1.3064e-05, -1.6262e-04, -3.3320e-04,
         5.2251e-04, -3.3689e-05,  0.0000e+00,  2.2751e-04,  2.6576e-04,
        -2.6351e-04, -1.8242e-05, -1.2817e-04, -4.0393e-05,  3.5287e-04,
        -1.2921e-04,  2.8072e-05,  4.5919e-04,  0.0000e+00, -1.4422e-04,
         0.0000e+00,  2.8177e-04, -3.2475e-04,  2.0783e-04, -2.4314e-04,
         1.3619e-04,  2.9962e-04, -3.1014e-04,  0.0000e+00,  7.9218e-05,
        -1.8645e-04, -1.0839e-06, -1.9041e-04,  0.0000e+00,  1.4221e-04,
         3.8877e-04,  3.9370e-04,  1.6094e-04,  2.6728e-04,  4.3327e-04,
        -4.1840e-04,  0.0000e+00, -6.5226e-04,  1.1918e-04,  0.0000e+00,
        -7.1747e-05, -9.9307e-05,  8.0538e-05, -5.5646e-04, -3.3013e-05,
        -5.3422e-04,  0.0000e+00, -8.6671e-05,  3.7369e-04,  1.8856e-05,
         0.0000e+00,  4.4844e-04, -2.7162e-04,  1.3055e-04,  0.0000e+00,
        -1.6981e-04,  2.1406e-05, -2.2678e-04,  0.0000e+00,  0.0000e+00,
        -2.3837e-04, -3.1071e-04,  0.0000e+00,  1.6807e-04,  5.8953e-04,
         0.0000e+00,  0.0000e+00, -2.0207e-04, -1.9485e-04,  0.0000e+00,
         0.0000e+00, -1.3307e-05,  6.3085e-05,  8.5203e-05,  1.6158e-04,
         0.0000e+00,  1.3754e-05,  3.9795e-04,  7.8668e-05,  0.0000e+00,
         0.0000e+00, -2.3823e-04, -4.6221e-04,  8.2055e-05,  0.0000e+00,
        -1.7836e-03, -1.5615e-05, -2.6594e-04, -3.9447e-04, -6.1332e-04,
         1.5204e-04,  2.7951e-04, -5.0434e-04,  3.4207e-04,  2.8707e-04,
         1.7589e-05,  9.0165e-05,  2.9068e-04, -1.2649e-04,  0.0000e+00,
         7.4268e-05,  1.3050e-04, -1.9573e-04, -4.2669e-04, -3.4350e-04,
         1.5426e-04,  1.1603e-05,  1.7511e-04,  1.2065e-04,  3.6491e-05,
         5.2069e-05, -1.3785e-04,  0.0000e+00, -2.9199e-04, -9.7495e-05,
        -2.1660e-04, -2.0101e-04], device='cuda:0')
==> name fc2.weight torch.Size([2, 192]) tensor([[ 7.8161e-06, -4.6193e-04,  0.0000e+00, -1.0577e-04, -1.0818e-04,
         -1.3715e-04, -2.4576e-04, -1.1751e-04,  0.0000e+00,  0.0000e+00,
          0.0000e+00, -5.7044e-04, -1.0996e-03,  0.0000e+00, -8.8138e-04,
         -1.1141e-03,  0.0000e+00,  0.0000e+00, -7.5296e-05, -1.1740e-03,
         -9.6660e-05, -5.1320e-05, -2.2164e-04, -1.6626e-04, -6.8397e-05,
         -1.2583e-04,  0.0000e+00,  0.0000e+00, -1.2893e-04, -3.1521e-04,
         -4.0645e-04, -9.5446e-04, -6.5335e-05,  0.0000e+00, -7.5948e-04,
         -8.2902e-04, -7.9376e-04, -3.9514e-04, -9.3357e-05, -5.2605e-04,
         -7.1790e-05,  0.0000e+00,  2.3978e-04, -2.8847e-05, -1.3993e-03,
         -6.9234e-05,  0.0000e+00, -8.9577e-05,  1.4326e-03, -7.7186e-04,
         -2.0537e-04, -5.4219e-04, -7.1468e-05, -5.4960e-05, -2.1073e-04,
         -8.5186e-05, -7.6222e-04, -1.0740e-03, -5.7727e-07, -7.5701e-04,
          0.0000e+00,  0.0000e+00, -4.6738e-04, -6.0134e-05,  3.8855e-05,
         -2.6294e-04, -6.1290e-04, -3.3090e-04,  0.0000e+00,  1.8545e-04,
          4.9131e-04, -5.3987e-04, -3.4958e-04, -7.0564e-04, -1.5627e-04,
          3.5073e-04, -2.7313e-04,  0.0000e+00, -2.1595e-04, -3.4862e-05,
         -9.6488e-04, -2.0825e-04, -1.4681e-04, -2.7400e-04,  5.7630e-04,
         -2.1001e-05,  5.6468e-04, -2.8438e-04,  0.0000e+00,  1.0407e-03,
          0.0000e+00, -1.7928e-04, -1.4936e-03, -4.2038e-05, -5.2930e-04,
         -2.2590e-04,  1.3610e-05, -3.0158e-04,  0.0000e+00, -3.0978e-04,
         -9.9681e-04, -1.5339e-03, -4.1217e-04,  0.0000e+00, -8.4242e-05,
          5.7263e-04, -4.8619e-04,  1.2698e-03,  2.5188e-04,  6.3826e-04,
          6.4300e-05,  0.0000e+00, -1.0161e-04, -1.5922e-04,  0.0000e+00,
         -2.5743e-05, -6.6994e-04, -6.3639e-04, -6.6186e-04, -1.5755e-04,
         -3.9477e-04,  0.0000e+00, -5.7981e-06, -3.9738e-04, -2.5116e-04,
          0.0000e+00,  1.5256e-04, -7.6213e-05,  6.4353e-04,  0.0000e+00,
         -8.1152e-04, -5.8605e-05, -4.5622e-04,  0.0000e+00,  0.0000e+00,
         -3.3819e-04, -8.1108e-04,  0.0000e+00, -6.4109e-05,  1.4722e-04,
          0.0000e+00,  0.0000e+00, -3.1837e-05, -7.7149e-04,  0.0000e+00,
          0.0000e+00, -4.6397e-05, -1.5852e-04, -7.9431e-04, -5.0168e-04,
          0.0000e+00, -4.7070e-04, -8.1911e-05, -1.8626e-04,  0.0000e+00,
          0.0000e+00, -5.6662e-04, -5.7761e-04, -1.6807e-04,  0.0000e+00,
         -1.6288e-03, -3.0229e-04, -7.8706e-04, -9.7107e-04, -7.6261e-04,
         -5.7353e-04, -8.3752e-04, -1.2931e-03,  3.0158e-04, -2.1716e-05,
         -3.5750e-05, -2.2427e-04, -2.0857e-04, -9.1123e-04,  0.0000e+00,
          9.9777e-05, -1.1943e-03, -6.6014e-04, -1.8828e-04, -5.0859e-05,
         -1.0684e-03,  1.5937e-04, -1.2476e-05, -1.0060e-04, -4.1842e-04,
         -5.4067e-04, -5.5009e-04,  0.0000e+00,  4.1379e-04, -8.9505e-05,
         -1.6853e-04, -3.5854e-04],
        [ 6.4160e-04,  0.0000e+00,  0.0000e+00,  3.4796e-04,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.3254e-03,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  1.5359e-03,  1.3664e-03,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  7.8410e-06,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          2.1290e-03,  1.2371e-03, -1.4942e-05,  0.0000e+00,  0.0000e+00,
          7.1790e-05,  0.0000e+00,  7.4194e-05,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  3.5476e-04,  9.4086e-04,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  9.8510e-04,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00, -1.1590e-04,  1.7010e-03,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  6.1220e-04,  1.0413e-03,
          0.0000e+00,  0.0000e+00,  4.7611e-04,  0.0000e+00,  7.0036e-04,
          1.2445e-03,  1.0916e-05,  0.0000e+00,  1.4796e-03,  8.1442e-04,
          8.4349e-04,  0.0000e+00,  0.0000e+00,  1.4817e-03,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.6494e-04,
          1.5277e-04,  2.5218e-04,  2.5692e-04,  0.0000e+00, -5.8872e-04,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  1.2874e-03,  1.1615e-05,  0.0000e+00,  0.0000e+00,
          9.5694e-04,  2.3050e-03, -2.7395e-05,  0.0000e+00,  0.0000e+00,
          4.6229e-04,  5.7212e-04,  1.0387e-03,  9.4566e-04,  1.9802e-03,
          6.0561e-04,  0.0000e+00,  4.3881e-04,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  1.5472e-03,  0.0000e+00,  0.0000e+00,
          1.3725e-03,  0.0000e+00,  5.7981e-06,  0.0000e+00,  2.5116e-04,
          0.0000e+00,  9.9727e-04,  0.0000e+00,  5.9373e-04,  0.0000e+00,
          0.0000e+00,  5.8605e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  1.6167e-03,  0.0000e+00,  0.0000e+00,  1.2305e-03,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  8.2532e-04,  1.4717e-03,  1.3260e-04,
          0.0000e+00,  0.0000e+00,  1.5657e-03,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          1.2068e-03,  0.0000e+00,  0.0000e+00,  2.5793e-04,  3.0544e-05,
          1.3799e-04,  1.5561e-03,  0.0000e+00,  1.0473e-03,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          5.5130e-04,  2.1191e-03,  1.2436e-03, -6.7079e-05,  7.9058e-05,
          1.6292e-03, -4.7142e-04,  0.0000e+00,  1.0060e-04,  4.9994e-04,
          0.0000e+00,  0.0000e+00,  0.0000e+00, -9.0650e-05, -3.6341e-06,
          3.5434e-04,  0.0000e+00]], device='cuda:0')
==> name fc2.bias torch.Size([2]) tensor([-0.0072,  0.0072], device='cuda:0')
Iter:    150,  Train Loss:  0.24,  Train Acc: 51.56%,  Val Loss:  0.22,  Val Acc: 49.92%,  Time: 0:00:05 ,  LR: 5.478104631726711e-07
s_logits tensor([[0.4588, 0.5412],
        [0.4578, 0.5422],
        [0.4581, 0.5419],
        [0.4603, 0.5397],
        [0.4612, 0.5388],
        [0.4586, 0.5414],
        [0.4605, 0.5395],
        [0.4740, 0.5260],
        [0.4635, 0.5365],
        [0.4580, 0.5420],
        [0.4591, 0.5409],
        [0.4583, 0.5417],
        [0.4569, 0.5431],
        [0.4607, 0.5393],
        [0.4596, 0.5404],
        [0.4605, 0.5395],
        [0.4595, 0.5405],
        [0.4594, 0.5406],
        [0.4609, 0.5391],
        [0.4634, 0.5366],
        [0.4575, 0.5425],
        [0.4608, 0.5392],
        [0.4607, 0.5393],
        [0.4567, 0.5433],
        [0.4583, 0.5417],
        [0.4587, 0.5413],
        [0.4560, 0.5440],
        [0.4573, 0.5427],
        [0.4704, 0.5296],
        [0.4560, 0.5440],
        [0.4595, 0.5405],
        [0.4609, 0.5391],
        [0.4592, 0.5408],
        [0.4567, 0.5433],
        [0.4599, 0.5401],
        [0.4599, 0.5401],
        [0.4587, 0.5413],
        [0.4561, 0.5439],
        [0.4588, 0.5412],
        [0.4569, 0.5431],
        [0.4586, 0.5414],
        [0.4562, 0.5438],
        [0.4585, 0.5415],
        [0.4585, 0.5415],
        [0.4598, 0.5402],
        [0.4578, 0.5422],
        [0.4551, 0.5449],
        [0.4571, 0.5429],
        [0.4578, 0.5422],
        [0.4599, 0.5401],
        [0.4617, 0.5383],
        [0.4603, 0.5397],
        [0.4564, 0.5436],
        [0.4583, 0.5417],
        [0.4603, 0.5397],
        [0.4597, 0.5403],
        [0.4568, 0.5432],
        [0.4505, 0.5495],
        [0.4600, 0.5400],
        [0.4581, 0.5419],
        [0.4609, 0.5391],
        [0.4566, 0.5434],
        [0.4602, 0.5398],
        [0.4583, 0.5417]], device='cuda:0', grad_fn=<SoftmaxBackward0>) label tensor([0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0,
        1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1,
        1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1], device='cuda:0')
t_logits tensor([[9.9604e-01, 3.9642e-03],
        [1.4215e-02, 9.8579e-01],
        [9.9251e-01, 7.4906e-03],
        [9.9527e-01, 4.7327e-03],
        [9.9704e-01, 2.9564e-03],
        [4.1125e-03, 9.9589e-01],
        [1.3164e-02, 9.8684e-01],
        [9.9590e-01, 4.0960e-03],
        [4.8314e-03, 9.9517e-01],
        [4.4303e-03, 9.9557e-01],
        [7.6228e-03, 9.9238e-01],
        [3.8239e-03, 9.9618e-01],
        [9.9585e-01, 4.1539e-03],
        [7.3053e-03, 9.9269e-01],
        [4.8976e-02, 9.5102e-01],
        [9.9389e-01, 6.1107e-03],
        [9.9936e-01, 6.3940e-04],
        [2.2047e-02, 9.7795e-01],
        [9.9090e-01, 9.0953e-03],
        [9.9894e-01, 1.0563e-03],
        [4.0593e-03, 9.9594e-01],
        [9.9935e-01, 6.5380e-04],
        [4.1495e-03, 9.9585e-01],
        [2.5150e-02, 9.7485e-01],
        [9.6469e-03, 9.9035e-01],
        [3.2422e-03, 9.9676e-01],
        [1.4051e-02, 9.8595e-01],
        [9.9932e-01, 6.7784e-04],
        [9.9881e-01, 1.1904e-03],
        [8.3301e-01, 1.6699e-01],
        [3.0071e-03, 9.9699e-01],
        [9.9911e-01, 8.9057e-04],
        [9.9692e-01, 3.0821e-03],
        [7.1033e-02, 9.2897e-01],
        [9.6024e-03, 9.9040e-01],
        [9.9786e-01, 2.1378e-03],
        [9.9228e-01, 7.7227e-03],
        [3.3628e-03, 9.9664e-01],
        [9.8947e-01, 1.0525e-02],
        [6.4100e-03, 9.9359e-01],
        [1.7977e-02, 9.8202e-01],
        [9.9883e-01, 1.1654e-03],
        [9.9887e-01, 1.1334e-03],
        [4.8222e-03, 9.9518e-01],
        [4.7747e-03, 9.9523e-01],
        [9.9735e-01, 2.6522e-03],
        [9.9406e-01, 5.9369e-03],
        [2.6466e-03, 9.9735e-01],
        [1.1491e-01, 8.8509e-01],
        [4.0616e-03, 9.9594e-01],
        [9.9589e-01, 4.1150e-03],
        [9.9916e-01, 8.4240e-04],
        [9.9951e-01, 4.8759e-04],
        [9.5185e-01, 4.8148e-02],
        [3.7953e-03, 9.9620e-01],
        [9.9898e-01, 1.0239e-03],
        [9.9910e-01, 9.0116e-04],
        [5.3491e-03, 9.9465e-01],
        [9.9739e-01, 2.6137e-03],
        [9.9741e-01, 2.5909e-03],
        [3.3857e-03, 9.9661e-01],
        [6.6975e-03, 9.9330e-01],
        [9.9902e-01, 9.8319e-04],
        [8.1249e-03, 9.9188e-01]], device='cuda:0')
base_loss tensor(0.6802, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(0.2400, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor([  101, 17037,  2545,  1999,  2074,  2107,  1037, 29328, 22090,  2008,
         2017,  1005,  1040,  8415,  2017,  2020,  3666, 17059, 27655,  2075,
         2037, 10768,  9623,  2012,  2017,  1012,   102,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0],
       device='cuda:0')
==> name Embedding.weight torch.Size([30522, 300]) tensor([[ 9.0855e-06,  1.5013e-05,  1.3435e-05,  ...,  5.4299e-06,
         -6.7779e-06, -1.4577e-05],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]], device='cuda:0')
==> name lstm.weight_ih_l0 torch.Size([1200, 300]) tensor([[-1.2979e-05,  8.5696e-06, -1.1370e-05,  ..., -9.5053e-06,
          1.2224e-05,  3.3017e-06],
        [ 1.1563e-05, -1.7043e-05, -4.7518e-06,  ..., -9.5910e-06,
          6.9130e-06, -1.0285e-05],
        [ 1.1535e-05,  2.0401e-05, -8.7566e-07,  ...,  4.7612e-06,
         -4.7163e-07,  2.7577e-06],
        ...,
        [-2.8829e-05, -2.3280e-05,  6.2507e-06,  ..., -1.0972e-05,
         -1.1784e-05, -1.2663e-05],
        [ 2.7430e-05,  3.6982e-05, -5.6486e-06,  ...,  9.0573e-06,
          8.0558e-06,  5.4923e-06],
        [ 6.1992e-07,  1.5378e-05, -2.5295e-06,  ...,  2.1496e-06,
          5.4538e-06,  9.9475e-07]], device='cuda:0')
==> name lstm.weight_hh_l0 torch.Size([1200, 300]) tensor([[-5.9147e-07, -7.7486e-08, -2.8739e-07,  ...,  8.4462e-07,
         -3.1813e-07,  6.4937e-08],
        [-2.8325e-07,  2.1479e-06,  2.0721e-06,  ...,  1.1474e-06,
          9.8622e-08, -2.2843e-06],
        [-1.1751e-07,  2.3897e-07, -2.0684e-06,  ...,  1.7167e-07,
          9.3566e-08, -1.7639e-06],
        ...,
        [ 6.7268e-06, -2.3985e-07,  1.5333e-06,  ...,  7.0672e-07,
         -2.5807e-06,  8.2481e-07],
        [-3.8069e-06,  7.1241e-07, -3.8522e-06,  ..., -1.1966e-06,
          3.1625e-06,  2.7676e-07],
        [ 8.0110e-08,  1.0208e-06, -1.3914e-06,  ...,  1.8135e-06,
         -1.3754e-06, -7.7668e-07]], device='cuda:0')
==> name lstm.bias_ih_l0 torch.Size([1200]) tensor([-8.1685e-07,  1.2841e-05,  2.5206e-06,  ..., -2.0252e-05,
         1.4296e-05,  8.1604e-07], device='cuda:0')
==> name lstm.bias_hh_l0 torch.Size([1200]) tensor([-8.1685e-07,  1.2841e-05,  2.5206e-06,  ..., -2.0252e-05,
         1.4296e-05,  8.1604e-07], device='cuda:0')
==> name lstm.weight_ih_l0_reverse torch.Size([1200, 300]) tensor([[ 5.3494e-06, -9.8026e-07,  5.3762e-06,  ..., -8.8484e-07,
          2.3359e-06, -3.4326e-06],
        [ 1.7867e-05,  8.4916e-06, -4.6809e-07,  ...,  7.7289e-06,
         -4.8127e-06,  1.9290e-06],
        [-7.4920e-06, -2.3633e-06, -4.4838e-06,  ..., -9.7312e-06,
          1.2405e-05,  9.2652e-06],
        ...,
        [ 7.6020e-06,  7.6453e-06,  1.0340e-06,  ...,  1.5683e-06,
          9.5992e-06, -1.7967e-06],
        [-3.1962e-07,  5.2147e-06,  1.2748e-06,  ..., -1.9861e-07,
          3.6482e-07, -1.1374e-06],
        [ 1.3953e-05,  8.3222e-06, -4.1516e-06,  ...,  1.8663e-06,
         -1.3722e-05,  5.2371e-06]], device='cuda:0')
==> name lstm.weight_hh_l0_reverse torch.Size([1200, 300]) tensor([[ 2.3775e-07, -3.9138e-06, -3.3564e-06,  ...,  1.6505e-06,
          2.4759e-06,  1.5911e-06],
        [-5.7419e-07,  5.8086e-07,  2.1587e-06,  ...,  1.0411e-06,
          7.5567e-07, -5.4165e-07],
        [-3.3796e-07,  3.5839e-07,  2.3837e-06,  ..., -2.6125e-07,
          2.0330e-07,  1.3242e-06],
        ...,
        [ 7.3993e-07,  1.1281e-07,  4.2022e-06,  ...,  5.1216e-07,
         -5.2803e-07, -4.2386e-07],
        [ 3.9142e-07, -1.6336e-07, -9.2141e-08,  ...,  1.8171e-07,
          2.9314e-07,  3.2373e-07],
        [ 3.0856e-07, -2.3180e-06,  1.1445e-06,  ...,  8.3465e-07,
          2.6158e-06,  3.0037e-06]], device='cuda:0')
==> name lstm.bias_ih_l0_reverse torch.Size([1200]) tensor([-1.7040e-05,  5.9077e-06,  1.1681e-05,  ...,  1.3442e-05,
        -4.7276e-06, -5.8549e-06], device='cuda:0')
==> name lstm.bias_hh_l0_reverse torch.Size([1200]) tensor([-1.7040e-05,  5.9077e-06,  1.1681e-05,  ...,  1.3442e-05,
        -4.7276e-06, -5.8549e-06], device='cuda:0')
==> name fc1.weight torch.Size([192, 600]) tensor([[ 8.7928e-05, -5.2226e-05, -1.1580e-04,  ...,  1.7892e-04,
         -2.3289e-05, -1.6145e-05],
        [ 1.7846e-05,  6.0570e-05, -2.3672e-05,  ...,  3.7779e-05,
          5.5746e-05,  5.8958e-05],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [-9.8446e-06,  1.4150e-06,  2.1603e-05,  ...,  1.4927e-05,
          1.6172e-05, -3.3915e-05],
        [ 8.3117e-05, -5.7582e-05, -9.5222e-05,  ...,  1.3159e-04,
         -1.0045e-07,  1.8981e-05],
        [-2.6473e-05,  4.2191e-05, -4.1106e-05,  ..., -5.2205e-05,
          1.7430e-05,  1.2505e-05]], device='cuda:0')
==> name fc1.bias torch.Size([192]) tensor([-1.4414e-03,  3.3205e-04,  0.0000e+00, -7.0972e-04, -2.3965e-04,
        -1.5024e-04, -1.6340e-04,  2.2920e-04,  0.0000e+00, -1.9325e-04,
         4.3016e-04, -2.1940e-04,  9.9714e-05, -5.5068e-04,  1.5237e-04,
        -1.0941e-04, -2.5841e-05,  0.0000e+00, -8.6982e-04, -1.7289e-03,
        -1.6248e-04,  0.0000e+00, -3.7959e-04,  9.8990e-05,  6.1568e-05,
         3.4968e-05, -3.0808e-04,  2.8180e-04, -3.7995e-04, -3.1833e-05,
        -3.3481e-05, -2.2331e-04,  2.0751e-04,  2.1293e-04, -2.1755e-04,
        -1.2002e-05, -5.8924e-04,  2.1035e-04,  1.9629e-04,  5.7855e-05,
         0.0000e+00, -2.2875e-04, -1.6736e-04,  2.5890e-05, -7.8803e-05,
         2.6685e-04,  8.3977e-05,  4.9807e-05,  4.5394e-04, -2.0358e-03,
         2.8885e-05, -3.5781e-04, -2.7917e-04, -4.2655e-05, -8.2409e-05,
         2.8788e-05,  1.3341e-04, -6.6588e-05,  3.8515e-05,  1.9999e-04,
         4.2723e-05,  0.0000e+00,  2.5458e-04,  8.1789e-05,  6.9645e-04,
        -3.6452e-04, -2.7842e-05, -1.4763e-03,  0.0000e+00, -2.2040e-03,
         1.8272e-03,  1.0675e-04, -1.1304e-05, -4.0038e-04, -1.7240e-03,
         2.0814e-03,  1.5112e-04, -3.7198e-04,  4.5582e-04, -6.9779e-04,
         2.2792e-04, -2.3332e-04,  2.3702e-04, -2.2434e-04,  1.1784e-03,
        -4.9125e-04, -5.0191e-06,  0.0000e+00,  1.4384e-04, -4.8751e-05,
        -3.2967e-04, -2.8454e-05,  1.1894e-04, -5.6144e-06, -6.3448e-05,
         2.4254e-06,  8.8051e-04, -7.3392e-04, -2.1023e-04,  9.6547e-06,
        -4.9654e-04, -2.4955e-04, -3.9152e-04,  4.9051e-06,  4.4983e-04,
         7.1212e-04,  9.8539e-04,  4.6189e-05,  1.8832e-03,  2.1858e-03,
        -1.4093e-03, -3.3617e-04,  4.0819e-04,  1.5886e-05, -3.5188e-05,
        -2.6743e-04, -1.3022e-05,  2.3839e-04, -3.1316e-04, -4.3903e-06,
        -2.5979e-03,  1.6380e-04, -7.3499e-05, -4.6720e-04,  4.2454e-04,
        -4.1613e-04,  2.1330e-03, -3.6254e-05,  3.8341e-04,  2.1701e-04,
        -1.3048e-04,  7.7243e-05, -1.4412e-05, -1.0876e-04,  0.0000e+00,
        -2.6735e-04, -1.0529e-03, -2.6124e-04,  2.1839e-05,  2.2635e-03,
        -1.3327e-04, -3.1742e-04, -2.2759e-04,  1.1667e-05,  1.6318e-05,
        -1.0456e-04, -1.8801e-04, -1.5487e-04,  2.5082e-04, -2.2821e-04,
         2.1494e-04,  7.3741e-05,  1.3924e-03,  1.0294e-03,  0.0000e+00,
        -3.2164e-05,  1.5703e-04, -2.5885e-04,  0.0000e+00,  0.0000e+00,
         7.6358e-05, -1.2947e-04, -3.5432e-05, -1.2754e-03,  5.6650e-04,
         1.3937e-04,  9.5508e-04,  1.5610e-04,  1.3470e-03, -2.4768e-04,
         1.7384e-05, -2.0075e-04, -5.9103e-05,  6.0863e-05,  7.4291e-05,
         4.2913e-04,  4.4984e-04, -8.2257e-04, -1.7553e-04,  3.7934e-04,
        -6.4069e-05,  3.9975e-05, -5.6039e-04,  9.7302e-05, -4.0948e-04,
         1.3509e-04, -1.8146e-05,  0.0000e+00, -3.1707e-04, -2.5274e-04,
        -9.6393e-04, -2.2612e-04], device='cuda:0')
==> name fc2.weight torch.Size([2, 192]) tensor([[-8.7974e-04, -5.9710e-05,  0.0000e+00, -2.6012e-03,  1.2788e-04,
          3.6386e-04, -1.8775e-04, -2.1909e-04,  0.0000e+00,  1.0053e-04,
          0.0000e+00,  5.4419e-05,  3.6813e-04, -1.1422e-03, -7.4307e-03,
          4.1223e-04,  0.0000e+00,  0.0000e+00, -4.8520e-03, -1.5135e-03,
         -3.5750e-04,  0.0000e+00,  3.1819e-05,  3.3147e-04,  1.8628e-05,
          1.4432e-04,  0.0000e+00,  0.0000e+00,  9.2915e-05,  6.0398e-05,
          4.9404e-04,  2.8541e-04,  0.0000e+00, -9.0133e-05, -5.8243e-04,
         -4.5338e-03, -9.0907e-04,  8.0536e-05, -6.0349e-05,  5.3356e-06,
          0.0000e+00, -4.7574e-04, -1.0651e-03, -3.7304e-04,  2.0195e-05,
         -1.7580e-04,  0.0000e+00,  1.5875e-04, -5.8425e-03, -1.3735e-03,
          2.0492e-04,  3.3112e-04,  0.0000e+00, -3.9997e-03, -1.1681e-04,
          1.5339e-04, -6.7831e-05,  4.4981e-04, -4.6493e-04, -3.9289e-03,
         -1.0505e-04,  0.0000e+00,  4.4808e-04, -6.1874e-04, -4.8130e-03,
         -4.2307e-04, -5.6619e-04, -2.0497e-03,  0.0000e+00, -4.1857e-03,
         -4.2192e-03, -3.6914e-05,  4.7477e-04, -3.1507e-03, -3.5113e-04,
         -4.2724e-03,  2.1952e-05,  0.0000e+00, -4.3308e-03,  1.9769e-04,
          8.6749e-04,  0.0000e+00,  8.4082e-05,  2.9615e-04, -3.5231e-03,
         -4.8804e-04, -2.3829e-03,  0.0000e+00,  1.1298e-04, -1.4796e-03,
          0.0000e+00, -1.3630e-04,  6.0824e-04,  0.0000e+00,  6.6637e-04,
         -1.0856e-04, -4.9077e-03, -1.3235e-03,  1.1444e-04,  1.5982e-04,
         -2.3314e-03, -2.3934e-03, -1.6579e-04, -1.0877e-04, -3.5625e-04,
         -1.8681e-03, -6.6293e-04, -5.8987e-03, -3.5289e-03, -5.3582e-03,
         -4.4476e-04, -2.8013e-05, -5.8147e-05, -8.1805e-06,  5.3665e-05,
          1.1114e-04, -4.6745e-04, -4.7527e-03, -7.0228e-04,  2.4978e-04,
         -3.0374e-03, -4.3972e-05, -6.7153e-05,  5.0684e-04, -3.0637e-04,
          0.0000e+00, -3.2879e-03, -4.6392e-05, -3.7505e-03, -6.5294e-05,
          2.1321e-04,  0.0000e+00, -3.2415e-06,  0.0000e+00,  0.0000e+00,
          7.2322e-05, -2.9241e-03, -1.6073e-04, -3.7615e-05, -4.1572e-03,
         -3.3372e-04,  0.0000e+00, -2.6913e-04,  5.0621e-04,  6.1865e-05,
         -4.3723e-05,  0.0000e+00, -1.0258e-03, -3.1110e-03,  2.3123e-04,
          1.4706e-04,  3.4749e-04, -3.0601e-03, -2.5000e-03,  0.0000e+00,
          0.0000e+00,  4.5958e-04, -4.7503e-05,  0.0000e+00,  0.0000e+00,
          5.7439e-04, -2.0628e-04,  2.4015e-04, -1.3746e-03,  5.6683e-04,
          5.8287e-05, -2.1831e-03,  2.8891e-04, -3.1709e-03,  2.3046e-04,
         -4.0477e-04,  1.8785e-04,  9.1807e-06,  5.6014e-04, -8.1086e-05,
         -2.2179e-03, -4.0567e-03, -3.6693e-03,  3.9398e-05, -1.9149e-05,
         -9.7148e-04, -1.4723e-03,  1.5211e-05, -2.5061e-05, -3.5305e-05,
          8.8920e-05,  2.5000e-04,  0.0000e+00,  2.5833e-04,  5.0499e-05,
         -2.1634e-03, -7.9947e-04],
        [ 9.9698e-04, -9.1191e-04,  0.0000e+00,  1.8578e-03,  7.6719e-05,
          0.0000e+00, -2.8776e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         -7.9125e-04, -4.5082e-04, -5.8175e-05,  0.0000e+00,  7.4656e-03,
          2.3558e-04, -1.7009e-04,  0.0000e+00,  5.2222e-03,  1.8390e-03,
          0.0000e+00,  0.0000e+00, -5.1820e-04, -6.7598e-04,  9.9857e-05,
          0.0000e+00, -6.2688e-04, -2.1270e-04, -2.9606e-04,  0.0000e+00,
          7.0123e-05, -1.2856e-05, -8.7913e-06,  0.0000e+00,  0.0000e+00,
          5.7315e-03,  1.1533e-03, -3.6973e-04, -1.5955e-04, -3.9134e-04,
          0.0000e+00, -7.0678e-04,  1.4280e-03,  0.0000e+00, -1.0664e-04,
          0.0000e+00, -3.6909e-06,  0.0000e+00,  4.8129e-03,  2.2694e-03,
          0.0000e+00,  0.0000e+00, -4.7180e-04,  3.9988e-03, -2.0502e-04,
          0.0000e+00, -1.2398e-04,  0.0000e+00, -3.0172e-04,  5.0204e-03,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0069e-03,  5.0686e-03,
         -6.0036e-04, -9.0227e-05,  2.6702e-03,  0.0000e+00,  4.9960e-03,
          5.1052e-03, -6.6741e-06,  0.0000e+00,  3.4689e-03,  6.9470e-04,
          5.1245e-03, -2.7543e-04, -1.0223e-03,  5.3794e-03,  3.0165e-04,
          0.0000e+00, -2.9744e-05, -1.4293e-05, -1.4036e-03,  3.3324e-03,
          4.3544e-04,  2.8597e-03,  0.0000e+00,  2.2972e-04,  1.6448e-03,
         -1.8390e-04,  3.8068e-05,  0.0000e+00, -8.0199e-05,  0.0000e+00,
         -3.6061e-04,  3.6094e-03,  1.0584e-03,  4.6534e-05,  0.0000e+00,
          3.0335e-03,  3.4985e-03, -2.2510e-04, -1.0050e-04, -5.4593e-06,
          1.2439e-03,  4.9788e-04,  6.7584e-03,  3.7755e-03,  6.1184e-03,
          1.3982e-03, -9.3757e-04, -2.9080e-05,  0.0000e+00, -1.7148e-04,
         -1.1546e-03,  0.0000e+00,  4.8333e-03,  0.0000e+00,  0.0000e+00,
          3.5549e-03,  0.0000e+00,  9.5832e-05, -6.1248e-04,  8.0188e-05,
         -1.1262e-03,  4.0988e-03,  0.0000e+00,  4.2402e-03, -3.7468e-04,
          2.5927e-05,  2.1105e-04,  0.0000e+00, -1.0334e-03,  0.0000e+00,
          0.0000e+00,  3.1174e-03, -2.1741e-04, -1.0258e-03,  4.1485e-03,
         -7.2198e-04, -1.5314e-03,  0.0000e+00,  2.6091e-04,  5.0843e-05,
          4.9423e-05,  6.4786e-05,  1.4670e-03,  2.9106e-03,  0.0000e+00,
         -5.0808e-05, -4.8859e-05,  5.5159e-03,  3.4700e-03,  0.0000e+00,
         -2.0051e-04, -6.1587e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         -4.4444e-05,  3.8591e-04,  0.0000e+00,  1.9337e-03, -9.5352e-05,
         -3.6419e-04,  2.8537e-03, -6.0334e-04,  4.5013e-03,  0.0000e+00,
          0.0000e+00,  5.2879e-05,  3.4434e-04, -3.3103e-05, -1.7261e-04,
          2.8184e-03,  4.8889e-03,  3.4135e-03,  1.1593e-04, -1.4534e-04,
          8.0332e-04,  9.1126e-04, -1.6861e-03, -3.4156e-04, -5.6958e-04,
         -4.6374e-04,  0.0000e+00,  0.0000e+00,  5.0662e-06, -1.0879e-03,
          1.8748e-03,  0.0000e+00]], device='cuda:0')
==> name fc2.bias torch.Size([2]) tensor([-0.0215,  0.0215], device='cuda:0')
Iter:    200,  Train Loss:  0.24,  Train Acc: 67.19%,  Val Loss:  0.22,  Val Acc: 49.92%,  Time: 0:00:06 ,  LR: 4.122147477075428e-05
Traceback (most recent call last):
  File "/home/huyiwen/NLP/bilstm/distill.py", line 71, in <module>
    student_train(T_model, S_model, cfg, train_loader, test_loader)
  File "/home/huyiwen/NLP/bilstm/student.py", line 142, in student_train
    dev_loss, dev_acc = student_evaluate(S_model, config, t_test_outputs, test_loader)
  File "/home/huyiwen/NLP/bilstm/student.py", line 169, in student_evaluate
    s_outputs = S_model(texts)
  File "/home/huyiwen/miniconda3/envs/kd2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/huyiwen/miniconda3/envs/kd2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/huyiwen/NLP/bilstm/models/lstm_mpo.py", line 201, in forward
    lstm_out, hidden = self.lstm(x, hidden)
  File "/home/huyiwen/miniconda3/envs/kd2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/huyiwen/miniconda3/envs/kd2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/huyiwen/miniconda3/envs/kd2/lib/python3.10/site-packages/torch/nn/modules/rnn.py", line 879, in forward
    result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
KeyboardInterrupt
Epoch [3/30]
s_logits tensor([[0.4644, 0.5356],
        [0.4769, 0.5231],
        [0.4767, 0.5233],
        [0.4581, 0.5419],
        [0.4765, 0.5235],
        [0.4773, 0.5227],
        [0.4993, 0.5007],
        [0.4723, 0.5277],
        [0.4745, 0.5255],
        [0.4759, 0.5241],
        [0.4743, 0.5257],
        [0.4751, 0.5249],
        [0.4764, 0.5236],
        [0.4747, 0.5253],
        [0.4758, 0.5242],
        [0.4738, 0.5262],
        [0.4732, 0.5268],
        [0.4744, 0.5256],
        [0.4771, 0.5229],
        [0.4734, 0.5266],
        [0.4755, 0.5245],
        [0.4762, 0.5238],
        [0.4729, 0.5271],
        [0.4760, 0.5240],
        [0.4763, 0.5237],
        [0.4755, 0.5245],
        [0.4742, 0.5258],
        [0.4516, 0.5484],
        [0.4737, 0.5263],
        [0.4742, 0.5258],
        [0.4732, 0.5268],
        [0.4758, 0.5242],
        [0.4745, 0.5255],
        [0.4738, 0.5262],
        [0.4767, 0.5233],
        [0.4769, 0.5231],
        [0.4771, 0.5229],
        [0.4760, 0.5240],
        [0.4733, 0.5267],
        [0.4800, 0.5200],
        [0.4751, 0.5249],
        [0.5002, 0.4998],
        [0.4737, 0.5263],
        [0.4784, 0.5216],
        [0.4749, 0.5251],
        [0.4743, 0.5257],
        [0.5015, 0.4985],
        [0.4635, 0.5365],
        [0.4759, 0.5241],
        [0.4753, 0.5247],
        [0.4742, 0.5258],
        [0.4734, 0.5266],
        [0.4748, 0.5252],
        [0.4740, 0.5260],
        [0.4724, 0.5276],
        [0.4745, 0.5255],
        [0.4522, 0.5478],
        [0.4765, 0.5235],
        [0.4763, 0.5237],
        [0.4740, 0.5260],
        [0.4772, 0.5228],
        [0.4723, 0.5277],
        [0.4744, 0.5256],
        [0.4755, 0.5245]], device='cuda:0', grad_fn=<SoftmaxBackward0>) label tensor([0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1,
        1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,
        0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0], device='cuda:0')
t_logits tensor([[9.9774e-01, 2.2594e-03],
        [9.9774e-01, 2.2613e-03],
        [3.6453e-03, 9.9635e-01],
        [4.4081e-03, 9.9559e-01],
        [3.8665e-03, 9.9613e-01],
        [9.9926e-01, 7.3872e-04],
        [3.1168e-03, 9.9688e-01],
        [3.2015e-03, 9.9680e-01],
        [1.2024e-02, 9.8798e-01],
        [4.5399e-03, 9.9546e-01],
        [8.6821e-02, 9.1318e-01],
        [9.7021e-01, 2.9792e-02],
        [5.1196e-03, 9.9488e-01],
        [9.3191e-03, 9.9068e-01],
        [9.9899e-01, 1.0100e-03],
        [9.9869e-01, 1.3105e-03],
        [2.1046e-02, 9.7895e-01],
        [4.3322e-03, 9.9567e-01],
        [5.4638e-01, 4.5362e-01],
        [7.3390e-03, 9.9266e-01],
        [4.9193e-03, 9.9508e-01],
        [4.0281e-03, 9.9597e-01],
        [3.8835e-03, 9.9612e-01],
        [3.4578e-03, 9.9654e-01],
        [8.2929e-03, 9.9171e-01],
        [9.9394e-01, 6.0625e-03],
        [7.1975e-01, 2.8025e-01],
        [6.2530e-03, 9.9375e-01],
        [3.9217e-03, 9.9608e-01],
        [9.7849e-01, 2.1509e-02],
        [9.9845e-01, 1.5480e-03],
        [9.9931e-01, 6.9499e-04],
        [9.9542e-01, 4.5824e-03],
        [9.9899e-01, 1.0124e-03],
        [9.9922e-01, 7.7954e-04],
        [5.7522e-02, 9.4248e-01],
        [7.9799e-03, 9.9202e-01],
        [2.6827e-01, 7.3173e-01],
        [9.9921e-01, 7.9021e-04],
        [6.3301e-03, 9.9367e-01],
        [9.9593e-01, 4.0717e-03],
        [9.9837e-01, 1.6319e-03],
        [9.9903e-01, 9.6742e-04],
        [9.9908e-01, 9.1840e-04],
        [3.9714e-03, 9.9603e-01],
        [3.9137e-03, 9.9609e-01],
        [9.9233e-01, 7.6735e-03],
        [5.7003e-03, 9.9430e-01],
        [9.1294e-01, 8.7059e-02],
        [5.0047e-03, 9.9500e-01],
        [1.4152e-02, 9.8585e-01],
        [3.4750e-03, 9.9652e-01],
        [9.9820e-01, 1.7984e-03],
        [9.9827e-01, 1.7261e-03],
        [9.8092e-01, 1.9083e-02],
        [9.8320e-01, 1.6805e-02],
        [9.9895e-01, 1.0479e-03],
        [9.9052e-01, 9.4836e-03],
        [4.8463e-03, 9.9515e-01],
        [3.3855e-03, 9.9661e-01],
        [2.3236e-02, 9.7676e-01],
        [3.8519e-03, 9.9615e-01],
        [3.7308e-03, 9.9627e-01],
        [9.9872e-01, 1.2816e-03]], device='cuda:0')
base_loss tensor(0.6931, device='cuda:0', grad_fn=<NllLossBackward0>) distillation_loss tensor(0.2286, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor([  101,  1037,  2025,  1011,  2061,  1011,  7746,  7800,  1997,  1996,
         8038,  1011,  8038,  2905,  9021,  2007,  1037,  2002,  6199,  2100,
         5094,  1997,  2128,  1011, 13017,  2665, 12851,  1012,   102,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0],
       device='cuda:0')
==> name Embedding.weight torch.Size([30522, 300]) tensor([[ 4.9770e-06,  1.3403e-06, -7.2533e-07,  ..., -1.5328e-06,
          8.8237e-06, -2.0973e-06],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]], device='cuda:0')
==> name lstm.weight_ih_l0 torch.Size([1200, 300]) tensor([[-4.8054e-06,  5.5417e-06, -2.9757e-06,  ..., -3.4790e-07,
          5.5125e-07, -6.1054e-06],
        [-8.7800e-07,  1.2995e-06,  1.5304e-05,  ..., -4.7232e-07,
         -3.3318e-07, -7.6776e-06],
        [-5.5815e-07,  6.2318e-08,  6.0959e-06,  ..., -7.2430e-06,
         -3.0705e-07, -8.4754e-06],
        ...,
        [ 2.8767e-05,  4.5859e-05, -8.8564e-06,  ...,  1.2999e-05,
          1.8320e-05,  1.0476e-05],
        [-8.3334e-07,  2.3998e-06,  1.5831e-05,  ...,  3.2457e-06,
          2.3812e-06, -1.6861e-05],
        [-8.2987e-06,  1.4636e-05, -2.8199e-06,  ...,  2.0176e-06,
          6.9782e-06, -2.2891e-07]], device='cuda:0')
==> name lstm.weight_hh_l0 torch.Size([1200, 300]) tensor([[-1.0472e-06, -1.0548e-07, -2.5552e-06,  ..., -1.4003e-06,
         -5.4701e-07,  4.9081e-07],
        [ 8.1018e-07,  5.9007e-07,  3.9944e-07,  ..., -7.3141e-07,
         -9.0676e-07, -1.5983e-06],
        [ 1.0627e-06,  1.7697e-06, -1.0159e-07,  ...,  7.0148e-07,
         -9.7029e-07,  3.0309e-07],
        ...,
        [-2.9054e-06,  1.1129e-06, -4.1754e-06,  ...,  1.5156e-06,
          3.3566e-06,  7.1280e-07],
        [ 7.4697e-07,  1.7629e-06,  3.6959e-07,  ..., -1.0855e-06,
         -3.3566e-06, -4.4785e-07],
        [-1.2989e-09,  2.1540e-07, -1.6255e-06,  ..., -9.7869e-07,
         -1.0995e-06,  5.2078e-07]], device='cuda:0')
==> name lstm.bias_ih_l0 torch.Size([1200]) tensor([-6.3193e-06,  4.8207e-07, -9.8589e-06,  ...,  1.7938e-05,
        -1.7423e-05, -4.7159e-06], device='cuda:0')
==> name lstm.bias_hh_l0 torch.Size([1200]) tensor([-6.3193e-06,  4.8207e-07, -9.8589e-06,  ...,  1.7938e-05,
        -1.7423e-05, -4.7159e-06], device='cuda:0')
==> name lstm.weight_ih_l0_reverse torch.Size([1200, 300]) tensor([[-2.2164e-06,  2.3507e-06,  6.1803e-07,  ...,  6.4272e-07,
         -1.6955e-06,  2.4959e-07],
        [-2.1080e-07, -8.9591e-06,  1.2724e-05,  ..., -1.2850e-05,
         -1.0358e-05, -1.4447e-05],
        [ 8.0155e-06,  3.5953e-06,  7.2714e-06,  ...,  1.5554e-06,
         -1.1778e-05,  4.9018e-06],
        ...,
        [-7.3877e-06,  9.3112e-06, -6.1258e-07,  ...,  1.6414e-06,
          2.4858e-07, -2.2124e-06],
        [ 1.5420e-06, -3.7690e-06,  1.1124e-06,  ..., -2.8836e-06,
         -2.7200e-06, -2.5112e-06],
        [-2.3984e-06,  1.0616e-06,  6.2000e-07,  ..., -3.7304e-06,
         -5.2132e-06, -6.5554e-06]], device='cuda:0')
==> name lstm.weight_hh_l0_reverse torch.Size([1200, 300]) tensor([[-9.2551e-07, -1.9265e-06,  5.6556e-07,  ...,  3.1139e-07,
          4.6847e-07, -1.4819e-06],
        [ 1.4927e-07, -1.4972e-06,  3.0258e-06,  ...,  5.0051e-07,
         -3.6820e-07, -4.4559e-07],
        [-3.5802e-07, -1.7170e-06, -1.4744e-06,  ..., -1.3408e-06,
         -5.7995e-07,  1.4864e-06],
        ...,
        [-9.2804e-07,  1.0822e-06, -1.1235e-06,  ...,  6.4253e-07,
         -1.3898e-07, -1.2810e-07],
        [ 2.3796e-07,  1.3229e-07,  6.2098e-07,  ..., -1.5422e-08,
          5.2366e-07, -2.0429e-07],
        [-2.3725e-07,  1.1361e-06,  4.2870e-07,  ...,  1.6184e-06,
          8.6844e-07, -1.1359e-06]], device='cuda:0')
==> name lstm.bias_ih_l0_reverse torch.Size([1200]) tensor([ 3.5099e-06,  1.8241e-06,  9.6287e-06,  ..., -8.5793e-06,
        -6.3497e-07, -7.2114e-06], device='cuda:0')
==> name lstm.bias_hh_l0_reverse torch.Size([1200]) tensor([ 3.5099e-06,  1.8241e-06,  9.6287e-06,  ..., -8.5793e-06,
        -6.3497e-07, -7.2114e-06], device='cuda:0')
==> name fc1.weight torch.Size([192, 600]) tensor([[ 3.4051e-05,  2.7462e-05,  3.6071e-06,  ..., -4.0824e-05,
         -1.7496e-05,  1.4267e-05],
        [ 5.8820e-05, -3.1162e-05, -6.4276e-05,  ..., -1.2116e-04,
         -3.1792e-05,  5.3494e-05],
        [-8.2569e-07, -9.5654e-08, -9.0237e-07,  ..., -1.0159e-07,
          4.2235e-07, -2.7601e-07],
        ...,
        [-3.2849e-05,  3.0007e-05,  2.4790e-05,  ...,  5.8566e-05,
          2.7908e-05, -4.9226e-05],
        [-7.4058e-06,  4.4434e-05, -8.7807e-06,  ..., -7.2610e-05,
         -6.2389e-06,  2.2759e-05],
        [-5.7292e-06,  3.6253e-05, -9.1962e-05,  ..., -1.3675e-04,
         -4.3109e-05,  4.4971e-05]], device='cuda:0')
==> name fc1.bias torch.Size([192]) tensor([ 7.4983e-04,  6.1259e-04,  8.7827e-08,  3.5831e-04, -4.5542e-04,
        -3.4082e-04,  3.5847e-04,  3.5467e-05,  0.0000e+00, -1.9896e-04,
         2.9834e-04,  4.8041e-05, -1.3319e-04, -1.0599e-05, -3.2634e-04,
         1.4457e-04,  2.7223e-04, -1.8101e-04,  5.7037e-04,  1.0473e-03,
        -6.1754e-06, -1.8683e-04, -3.1800e-04,  6.0854e-05, -3.2663e-06,
         1.6739e-05, -3.0730e-04,  9.7450e-05,  1.7925e-04,  0.0000e+00,
         0.0000e+00, -3.7456e-05,  1.9857e-04,  2.0136e-04, -1.8493e-04,
         2.6301e-04,  2.7005e-04, -3.4366e-04,  3.2990e-04,  8.3227e-05,
         0.0000e+00, -2.1294e-04, -1.7540e-04, -3.5382e-05,  9.8770e-05,
        -2.3794e-04,  1.6771e-04, -2.1411e-04, -4.5723e-04,  8.8733e-04,
        -1.9422e-04, -3.7092e-04, -4.7886e-05,  1.1242e-04,  2.0552e-04,
        -4.2746e-07,  3.1095e-04,  3.9560e-04,  5.1317e-05,  6.3814e-04,
         1.8118e-06,  0.0000e+00,  1.3223e-04,  9.3416e-05, -4.5332e-04,
        -3.9230e-04,  5.6356e-04,  7.8652e-04,  5.0542e-05,  7.1174e-04,
        -1.0444e-03, -3.4102e-05,  1.6793e-04,  1.8564e-04,  1.6363e-03,
        -5.0776e-04,  1.0633e-04, -3.3130e-04, -1.6241e-04,  0.0000e+00,
         4.6273e-04, -2.1526e-04,  3.7320e-04, -2.9181e-04, -7.6322e-04,
         1.5152e-04,  7.1632e-05, -5.2052e-05,  2.6785e-04, -7.7278e-05,
        -2.0697e-04, -3.2460e-04, -4.9948e-04, -1.9549e-04,  4.3238e-04,
         1.0961e-04, -6.0729e-04,  3.2295e-04,  8.2979e-06, -7.0892e-05,
         2.5748e-04,  3.9473e-04, -7.2595e-04, -2.5539e-04,  1.3205e-04,
        -3.8918e-04, -3.0115e-06, -1.3007e-04, -5.9994e-04, -1.3832e-03,
         3.7759e-04, -5.9557e-04,  4.7073e-05, -1.0682e-04,  3.8117e-04,
        -1.9488e-04, -4.6452e-05, -1.4136e-04,  1.9847e-04,  2.9510e-05,
         1.2445e-03,  0.0000e+00, -1.4245e-05,  3.9247e-05, -3.4880e-04,
        -3.6394e-04, -5.6424e-04, -1.0573e-04, -2.3150e-04,  9.4392e-05,
         6.5529e-05,  0.0000e+00,  1.0131e-04, -9.9032e-05,  1.9268e-04,
         2.0439e-04,  5.8624e-04,  7.9708e-05, -4.4341e-04, -5.2296e-04,
        -1.3655e-04, -8.3057e-05, -7.7417e-06, -1.8497e-04,  8.0130e-05,
        -1.7382e-04, -4.2181e-04, -1.1074e-04, -4.0787e-04, -2.2594e-04,
         2.0778e-04,  8.5493e-05, -7.4120e-05, -6.8485e-04, -1.4975e-04,
        -1.5053e-05, -5.0670e-06,  3.4122e-04, -1.4706e-04,  0.0000e+00,
        -3.0002e-05, -4.7705e-05,  2.2675e-04,  3.9804e-04,  1.0542e-04,
        -1.4798e-04, -6.2382e-04,  4.2641e-04, -4.5380e-04,  0.0000e+00,
         6.8188e-07,  0.0000e+00,  4.9581e-05,  1.6331e-05, -4.9263e-04,
        -9.4218e-05, -2.9366e-04,  3.5898e-04,  1.5509e-04,  2.3884e-04,
        -1.5099e-04,  1.3488e-04, -4.0821e-04, -8.2871e-05, -5.0160e-04,
         1.0851e-04,  5.9422e-05,  0.0000e+00,  1.5246e-04, -1.7921e-04,
         3.6406e-04,  1.7224e-04], device='cuda:0')
==> name fc2.weight torch.Size([2, 192]) tensor([[ 1.4333e-03,  5.5547e-04,  3.1026e-06,  1.3521e-03,  3.3224e-04,
          2.2703e-04,  3.0077e-04, -1.9329e-04,  0.0000e+00,  4.7371e-05,
          3.9050e-04,  7.4505e-04,  1.5768e-04, -7.1173e-04,  3.0555e-03,
          7.2279e-04, -2.0139e-04,  1.6719e-04,  1.5905e-03,  3.9655e-04,
         -3.2826e-05,  1.5676e-04, -4.8996e-04,  2.6665e-05, -3.0531e-04,
         -3.5873e-04,  1.7541e-05, -1.9722e-04, -1.5570e-04,  0.0000e+00,
          0.0000e+00, -1.4095e-04, -6.2457e-05, -2.1573e-04, -6.5622e-04,
          9.7137e-04,  1.5244e-04,  3.3691e-04,  1.8503e-04,  6.1877e-06,
          0.0000e+00, -4.4335e-06,  1.1137e-03, -3.8907e-04,  1.2189e-03,
          2.1744e-04,  0.0000e+00,  0.0000e+00,  1.9751e-03,  1.7377e-03,
          3.0863e-04,  4.1178e-04,  2.9679e-04,  1.5051e-03,  1.4079e-05,
         -2.1113e-04, -2.0067e-04,  6.0523e-04,  5.7696e-04,  1.7027e-03,
          3.5909e-05,  0.0000e+00,  2.7072e-04,  2.2824e-04,  1.9286e-03,
         -1.2692e-05,  4.7903e-04,  1.7004e-03,  3.0180e-04,  9.8898e-04,
          2.3739e-03,  9.8082e-05,  0.0000e+00, -2.3280e-05, -3.9106e-04,
          2.3927e-03,  8.9462e-04,  4.5018e-04,  1.6757e-03,  0.0000e+00,
          3.0789e-04,  1.5275e-04, -2.4942e-04,  0.0000e+00, -4.8042e-05,
         -3.0246e-04,  1.4520e-03,  4.5639e-04, -5.1302e-05,  3.0196e-04,
         -9.6624e-05,  6.2343e-05,  7.6530e-04,  2.5322e-04,  7.4650e-04,
         -5.3412e-05,  1.7537e-03,  1.7526e-04,  0.0000e+00,  8.2509e-04,
          6.5945e-04,  1.9809e-03,  5.7990e-04,  2.0060e-04, -1.2122e-04,
          9.8195e-04,  1.4548e-06,  2.0495e-03,  8.1952e-04,  2.3528e-03,
          8.6113e-04,  1.0280e-05,  1.4648e-04,  1.1452e-05,  3.5831e-04,
          2.9409e-04, -7.2862e-04,  8.3426e-04, -5.7133e-04,  3.0421e-05,
          2.3940e-03,  0.0000e+00,  0.0000e+00, -4.9162e-05,  5.6000e-04,
         -4.5085e-04,  1.4079e-03,  2.5891e-05,  1.8973e-03,  0.0000e+00,
          3.0456e-04,  0.0000e+00,  2.4118e-04,  9.7414e-05, -1.0555e-04,
          5.5422e-04,  1.9397e-03, -1.5544e-04,  2.6331e-04,  1.4944e-04,
         -4.3108e-05,  6.5370e-05,  1.8715e-04,  7.1812e-04,  0.0000e+00,
          7.8511e-06,  0.0000e+00,  2.2187e-04,  1.1509e-03,  3.1122e-04,
          2.8350e-04, -6.3405e-05,  2.6811e-03,  1.0668e-03,  9.0475e-05,
          0.0000e+00,  3.3263e-04,  3.4989e-04,  5.3704e-04,  0.0000e+00,
          2.5615e-05,  0.0000e+00,  5.3941e-04,  1.0302e-03,  1.0770e-03,
         -8.6568e-05,  4.9697e-04,  2.9035e-04,  1.5427e-03,  0.0000e+00,
         -1.8351e-04,  0.0000e+00,  0.0000e+00,  2.2578e-04,  1.5354e-04,
          3.6243e-04,  2.9144e-03,  2.4436e-04,  2.6897e-05,  4.4140e-05,
          4.5902e-04,  1.1939e-03,  0.0000e+00,  4.8813e-05,  4.3142e-04,
          1.5048e-04,  4.0637e-04,  0.0000e+00,  0.0000e+00,  1.1403e-04,
          4.4552e-04, -1.9674e-04],
        [-1.5968e-03, -4.7538e-04,  0.0000e+00, -1.0723e-03, -7.9042e-04,
          4.0493e-05,  3.9025e-04, -8.0832e-05,  0.0000e+00,  0.0000e+00,
         -3.6785e-04,  2.3376e-04, -2.4137e-04,  0.0000e+00, -3.7513e-03,
         -1.2637e-03, -1.5396e-03,  0.0000e+00, -9.2121e-04, -2.9862e-04,
          0.0000e+00,  0.0000e+00, -2.5054e-04, -5.9695e-04,  0.0000e+00,
          8.5488e-07, -3.5501e-04,  3.3271e-05, -8.8305e-05,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         -5.7957e-04, -4.4559e-04, -7.9118e-04,  0.0000e+00, -6.3194e-04,
          0.0000e+00, -4.7742e-04, -5.0210e-04,  0.0000e+00, -3.0738e-04,
          0.0000e+00, -3.3355e-04,  2.6336e-05, -2.4053e-03, -1.4716e-03,
          0.0000e+00,  0.0000e+00, -8.5472e-04, -5.7661e-04, -2.7976e-05,
          6.7890e-05, -6.9887e-04,  2.3938e-04, -8.4181e-04, -7.3293e-04,
          0.0000e+00,  0.0000e+00,  0.0000e+00, -8.1478e-05, -2.2203e-03,
         -5.3734e-04, -2.8758e-04, -6.8739e-04,  0.0000e+00, -1.0971e-03,
         -9.7068e-04,  0.0000e+00,  3.8593e-05, -7.3503e-04,  1.9615e-04,
         -1.1884e-03, -2.1493e-05, -6.9407e-04, -9.2333e-04,  0.0000e+00,
          9.5480e-05, -2.3106e-03, -7.2555e-05, -1.6333e-03, -1.1250e-03,
          4.6385e-05, -4.8881e-04, -1.3741e-05, -8.1046e-05, -9.0984e-04,
          1.4463e-04,  1.1671e-04,  7.5535e-05,  6.4434e-04,  0.0000e+00,
         -1.0930e-04, -1.8449e-03, -8.5876e-04, -1.2720e-05,  0.0000e+00,
         -4.4729e-04, -1.5085e-03, -9.2103e-04,  2.3432e-04,  0.0000e+00,
         -2.2946e-04,  0.0000e+00, -2.2028e-03, -9.2054e-04, -1.7638e-03,
         -3.2339e-04, -1.0651e-03, -2.1550e-04,  0.0000e+00, -6.7002e-04,
         -5.6077e-04, -1.6674e-04, -1.0014e-03, -9.4148e-05,  0.0000e+00,
         -1.4341e-03,  0.0000e+00,  7.6961e-05, -1.0490e-04,  7.1286e-05,
         -6.1398e-04, -1.2355e-03,  4.4552e-05, -1.5284e-03, -1.6684e-04,
          8.3627e-05,  0.0000e+00,  0.0000e+00, -1.2812e-03,  0.0000e+00,
          0.0000e+00, -9.8064e-04, -3.7240e-04, -1.5927e-03, -8.0256e-04,
         -8.1579e-04, -1.6126e-03,  0.0000e+00, -6.2726e-04, -1.3984e-04,
          3.1832e-04, -3.0049e-04, -9.0558e-04, -1.1518e-03,  0.0000e+00,
          1.2733e-04, -2.0584e-04, -1.8738e-03, -4.9599e-04,  0.0000e+00,
          1.8535e-04,  0.0000e+00,  5.9985e-05,  0.0000e+00,  0.0000e+00,
         -9.9802e-05,  5.9446e-05,  0.0000e+00, -2.9776e-04,  0.0000e+00,
         -3.4524e-04, -1.5296e-03, -7.7894e-04, -1.2507e-03,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  7.2963e-06, -2.1752e-04,  4.0662e-05,
         -5.6975e-04, -2.4542e-03, -1.3732e-03, -6.2072e-06, -2.4325e-04,
         -1.4165e-03, -3.7100e-04, -1.6581e-03, -4.2700e-04, -1.0241e-03,
         -7.0933e-04,  0.0000e+00,  0.0000e+00, -4.2286e-05, -1.7641e-04,
          2.7356e-06,  0.0000e+00]], device='cuda:0')
==> name fc2.bias torch.Size([2]) tensor([ 0.0135, -0.0135], device='cuda:0')